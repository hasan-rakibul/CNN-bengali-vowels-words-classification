{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from code import *\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH=\"./data_init/\"\n",
    "def get_labels(path=DATA_PATH):\n",
    "\tlabels=os.listdir(path)\n",
    "\tlabel_indices=np.arange(0,len(labels))\n",
    "\treturn labels, label_indices, to_categorical(label_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def speech2mfcc(file_path,max_len=11):\n",
    "\twave, sr= librosa.load(file_path, mono=True, sr=None)\n",
    "\twave=wave[::5]\n",
    "\tmfcc=librosa.feature.mfcc(wave,sr=sr)\n",
    "#\tprint(mfcc)\n",
    "\tif (max_len > mfcc.shape[1]): #.shape[1], 1-->column\n",
    "\t\tpad_width=max_len-mfcc.shape[1]\n",
    "\t\tmfcc=np.pad(mfcc,pad_width=((0,0),(0,pad_width)),mode='constant')\n",
    "\n",
    "\telse:\n",
    "\t\tmfcc=mfcc[:,:max_len]\n",
    "#\tprint(mfcc.shape)\n",
    "\treturn mfcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data_to_array(path=DATA_PATH, max_len=11):\n",
    "\tlabels,_,_=get_labels(path)\n",
    "\n",
    "\tfor label in labels:\n",
    "\t\tmfcc_vectors=[]\n",
    "\n",
    "\t\tspeechfiles=[path + label + '/' + speech for speech in os.listdir(path+'/'+label)]\n",
    "\t\tfor speech in tqdm(speechfiles,\"Saving vectors to label -'{}'\".format(label)):\n",
    "\t\t\tmfcc=speech2mfcc(speech,max_len=max_len)\n",
    "\t\t\tprint(mfcc.shape)\n",
    "\t\t\tmfcc_vectors.append(mfcc)\n",
    "#\t\tprint(mfcc_vectors)\n",
    "\t\tnp.save(label+'.npy',mfcc_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test(split_ratio=0.8,random_state=42):\n",
    "\tlabels,indices,_=get_labels(DATA_PATH)\n",
    "\n",
    "\tX=np.load(labels[0]+'.npy')\n",
    "\ty=np.zeros(X.shape[0])\n",
    "\t\n",
    "\tfor i,label in enumerate(labels[1:]):\n",
    "\t\tx=np.load(label+'.npy')\n",
    "\t\tX=np.vstack((X,x))\n",
    "\t\ty=np.append(y,np.full(x.shape[0],fill_value=(i+1)))\n",
    "\tassert X.shape[0] == len(y)\n",
    "#\tprint(X.shape)\n",
    "#\tprint(y)\n",
    "\treturn train_test_split(X,y,test_size=(1-split_ratio),random_state=random_state,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving vectors to label -'1':  85%|████████▍ | 22/26 [00:00<00:00, 97.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving vectors to label -'1': 100%|██████████| 26/26 [00:00<00:00, 104.98it/s]\n",
      "Saving vectors to label -'10':   8%|▊         | 2/26 [00:00<00:01, 17.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving vectors to label -'10':  35%|███▍      | 9/26 [00:00<00:00, 22.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving vectors to label -'10':  69%|██████▉   | 18/26 [00:00<00:00, 28.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving vectors to label -'10': 100%|██████████| 26/26 [00:00<00:00, 31.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving vectors to label -'2':  31%|███       | 8/26 [00:00<00:00, 31.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Saving vectors to label -'2':  46%|████▌     | 12/26 [00:00<00:00, 32.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving vectors to label -'2':  85%|████████▍ | 22/26 [00:00<00:00, 36.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving vectors to label -'2': 100%|██████████| 26/26 [00:00<00:00, 30.03it/s]\n",
      "Saving vectors to label -'3':  12%|█▏        | 3/26 [00:00<00:00, 28.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving vectors to label -'3':  38%|███▊      | 10/26 [00:00<00:00, 31.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving vectors to label -'3':  69%|██████▉   | 18/26 [00:00<00:00, 33.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Saving vectors to label -'3':  81%|████████  | 21/26 [00:00<00:00, 24.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving vectors to label -'3': 100%|██████████| 26/26 [00:00<00:00, 26.35it/s]\n",
      "Saving vectors to label -'4':   0%|          | 0/26 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving vectors to label -'4':  23%|██▎       | 6/26 [00:00<00:00, 25.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving vectors to label -'4':  65%|██████▌   | 17/26 [00:00<00:00, 32.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Saving vectors to label -'4':  81%|████████  | 21/26 [00:00<00:00, 33.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving vectors to label -'4': 100%|██████████| 26/26 [00:00<00:00, 36.31it/s]\n",
      "Saving vectors to label -'5':  12%|█▏        | 3/26 [00:00<00:01, 22.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving vectors to label -'5':  38%|███▊      | 10/26 [00:00<00:00, 26.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving vectors to label -'5':  73%|███████▎  | 19/26 [00:00<00:00, 31.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving vectors to label -'5': 100%|██████████| 26/26 [00:00<00:00, 34.82it/s]\n",
      "Saving vectors to label -'6':   0%|          | 0/26 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving vectors to label -'6':  35%|███▍      | 9/26 [00:00<00:00, 31.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Saving vectors to label -'6':  58%|█████▊    | 15/26 [00:00<00:00, 33.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving vectors to label -'6':  92%|█████████▏| 24/26 [00:00<00:00, 33.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving vectors to label -'6': 100%|██████████| 26/26 [00:00<00:00, 36.72it/s]\n",
      "Saving vectors to label -'7':  12%|█▏        | 3/26 [00:00<00:00, 24.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Saving vectors to label -'7':  23%|██▎       | 6/26 [00:00<00:00, 24.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving vectors to label -'7':  62%|██████▏   | 16/26 [00:00<00:00, 30.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving vectors to label -'7': 100%|██████████| 26/26 [00:00<00:00, 34.75it/s]\n",
      "Saving vectors to label -'8':   0%|          | 0/26 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving vectors to label -'8':  23%|██▎       | 6/26 [00:00<00:00, 21.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving vectors to label -'8':  58%|█████▊    | 15/26 [00:00<00:00, 27.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving vectors to label -'8':  92%|█████████▏| 24/26 [00:00<00:00, 32.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving vectors to label -'8': 100%|██████████| 26/26 [00:00<00:00, 36.31it/s]\n",
      "Saving vectors to label -'9':  12%|█▏        | 3/26 [00:00<00:00, 29.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving vectors to label -'9':  54%|█████▍    | 14/26 [00:00<00:00, 35.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving vectors to label -'9': 100%|██████████| 26/26 [00:00<00:00, 42.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n",
      "(20, 11)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "save_data_to_array()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test=get_train_test()\n",
    "X_train=X_train.reshape(X_train.shape[0],20,11,1)\n",
    "X_test=X_test.reshape(X_test.shape[0],20,11,1)\n",
    "y_train_hot=to_categorical(y_train)\n",
    "y_test_hot=to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 208 samples, validate on 52 samples\n",
      "Epoch 1/1\n",
      "208/208 [==============================] - 157s 756ms/step - loss: 3.2606 - acc: 0.0962 - val_loss: 2.3178 - val_acc: 0.1154\n",
      "Train on 208 samples, validate on 52 samples\n",
      "Epoch 1/2\n",
      "208/208 [==============================] - 8s 38ms/step - loss: 3.2605 - acc: 0.0962 - val_loss: 2.3178 - val_acc: 0.1154\n",
      "Epoch 2/2\n",
      "208/208 [==============================] - 0s 674us/step - loss: 2.3575 - acc: 0.3029 - val_loss: 1.9300 - val_acc: 0.3077\n",
      "Train on 208 samples, validate on 52 samples\n",
      "Epoch 1/3\n",
      "208/208 [==============================] - 8s 39ms/step - loss: 3.2605 - acc: 0.0962 - val_loss: 2.3147 - val_acc: 0.1154\n",
      "Epoch 2/3\n",
      "208/208 [==============================] - 0s 736us/step - loss: 2.3406 - acc: 0.3029 - val_loss: 1.9256 - val_acc: 0.3269\n",
      "Epoch 3/3\n",
      "208/208 [==============================] - 0s 811us/step - loss: 1.7149 - acc: 0.3942 - val_loss: 1.6008 - val_acc: 0.5000\n",
      "Train on 208 samples, validate on 52 samples\n",
      "Epoch 1/4\n",
      "208/208 [==============================] - 9s 44ms/step - loss: 3.2605 - acc: 0.0962 - val_loss: 2.3147 - val_acc: 0.1154\n",
      "Epoch 2/4\n",
      "208/208 [==============================] - 0s 672us/step - loss: 2.3406 - acc: 0.3029 - val_loss: 1.9256 - val_acc: 0.3269\n",
      "Epoch 3/4\n",
      "208/208 [==============================] - 0s 672us/step - loss: 1.7144 - acc: 0.3942 - val_loss: 1.6005 - val_acc: 0.5000\n",
      "Epoch 4/4\n",
      "208/208 [==============================] - 0s 586us/step - loss: 1.5453 - acc: 0.4279 - val_loss: 1.6269 - val_acc: 0.5385\n",
      "Train on 208 samples, validate on 52 samples\n",
      "Epoch 1/5\n",
      "208/208 [==============================] - 8s 40ms/step - loss: 3.2605 - acc: 0.0962 - val_loss: 2.3147 - val_acc: 0.1154\n",
      "Epoch 2/5\n",
      "208/208 [==============================] - 0s 479us/step - loss: 2.3406 - acc: 0.3029 - val_loss: 1.9256 - val_acc: 0.3269\n",
      "Epoch 3/5\n",
      "208/208 [==============================] - 0s 507us/step - loss: 1.7144 - acc: 0.3942 - val_loss: 1.6005 - val_acc: 0.5000\n",
      "Epoch 4/5\n",
      "208/208 [==============================] - 0s 482us/step - loss: 1.5453 - acc: 0.4279 - val_loss: 1.6269 - val_acc: 0.5385\n",
      "Epoch 5/5\n",
      "208/208 [==============================] - 0s 543us/step - loss: 1.5589 - acc: 0.5096 - val_loss: 1.4701 - val_acc: 0.5000\n",
      "Train on 208 samples, validate on 52 samples\n",
      "Epoch 1/6\n",
      "208/208 [==============================] - 8s 40ms/step - loss: 3.2605 - acc: 0.0962 - val_loss: 2.3147 - val_acc: 0.1154\n",
      "Epoch 2/6\n",
      "208/208 [==============================] - 0s 521us/step - loss: 2.3406 - acc: 0.3029 - val_loss: 1.9256 - val_acc: 0.3269\n",
      "Epoch 3/6\n",
      "208/208 [==============================] - 0s 522us/step - loss: 1.7144 - acc: 0.3942 - val_loss: 1.6005 - val_acc: 0.5000\n",
      "Epoch 4/6\n",
      "208/208 [==============================] - 0s 494us/step - loss: 1.5453 - acc: 0.4279 - val_loss: 1.6269 - val_acc: 0.5385\n",
      "Epoch 5/6\n",
      "208/208 [==============================] - 0s 497us/step - loss: 1.5589 - acc: 0.5096 - val_loss: 1.4701 - val_acc: 0.5000\n",
      "Epoch 6/6\n",
      "208/208 [==============================] - 0s 505us/step - loss: 1.1923 - acc: 0.5817 - val_loss: 1.5850 - val_acc: 0.4423\n",
      "Train on 208 samples, validate on 52 samples\n",
      "Epoch 1/7\n",
      "208/208 [==============================] - 10s 47ms/step - loss: 3.2605 - acc: 0.0962 - val_loss: 2.3147 - val_acc: 0.1154\n",
      "Epoch 2/7\n",
      "208/208 [==============================] - 0s 811us/step - loss: 2.3406 - acc: 0.3029 - val_loss: 1.9256 - val_acc: 0.3269\n",
      "Epoch 3/7\n",
      "208/208 [==============================] - 0s 806us/step - loss: 1.7144 - acc: 0.3942 - val_loss: 1.6005 - val_acc: 0.5000\n",
      "Epoch 4/7\n",
      "208/208 [==============================] - 0s 860us/step - loss: 1.5453 - acc: 0.4279 - val_loss: 1.6269 - val_acc: 0.5385\n",
      "Epoch 5/7\n",
      "208/208 [==============================] - 0s 836us/step - loss: 1.5589 - acc: 0.5096 - val_loss: 1.4701 - val_acc: 0.5000\n",
      "Epoch 6/7\n",
      "208/208 [==============================] - 0s 671us/step - loss: 1.1923 - acc: 0.5817 - val_loss: 1.5850 - val_acc: 0.4423\n",
      "Epoch 7/7\n",
      "208/208 [==============================] - 0s 491us/step - loss: 1.3101 - acc: 0.5577 - val_loss: 1.3253 - val_acc: 0.5769\n",
      "Train on 208 samples, validate on 52 samples\n",
      "Epoch 1/8\n",
      "208/208 [==============================] - 9s 43ms/step - loss: 3.2605 - acc: 0.0962 - val_loss: 2.3147 - val_acc: 0.1154\n",
      "Epoch 2/8\n",
      "208/208 [==============================] - 0s 712us/step - loss: 2.3406 - acc: 0.3029 - val_loss: 1.9256 - val_acc: 0.3269\n",
      "Epoch 3/8\n",
      "208/208 [==============================] - 0s 738us/step - loss: 1.7144 - acc: 0.3942 - val_loss: 1.6005 - val_acc: 0.5000\n",
      "Epoch 4/8\n",
      "208/208 [==============================] - 0s 703us/step - loss: 1.5453 - acc: 0.4279 - val_loss: 1.6269 - val_acc: 0.5385\n",
      "Epoch 5/8\n",
      "208/208 [==============================] - 0s 832us/step - loss: 1.5589 - acc: 0.5096 - val_loss: 1.4701 - val_acc: 0.5000\n",
      "Epoch 6/8\n",
      "208/208 [==============================] - 0s 735us/step - loss: 1.1923 - acc: 0.5817 - val_loss: 1.5850 - val_acc: 0.4423\n",
      "Epoch 7/8\n",
      "208/208 [==============================] - 0s 638us/step - loss: 1.3101 - acc: 0.5577 - val_loss: 1.3253 - val_acc: 0.5769\n",
      "Epoch 8/8\n",
      "208/208 [==============================] - 0s 605us/step - loss: 0.9788 - acc: 0.6346 - val_loss: 1.2279 - val_acc: 0.5577\n",
      "Train on 208 samples, validate on 52 samples\n",
      "Epoch 1/9\n",
      "208/208 [==============================] - 9s 42ms/step - loss: 3.2605 - acc: 0.0962 - val_loss: 2.3147 - val_acc: 0.1154\n",
      "Epoch 2/9\n",
      "208/208 [==============================] - 0s 567us/step - loss: 2.3406 - acc: 0.3029 - val_loss: 1.9256 - val_acc: 0.3269\n",
      "Epoch 3/9\n",
      "208/208 [==============================] - 0s 644us/step - loss: 1.7144 - acc: 0.3942 - val_loss: 1.6005 - val_acc: 0.5000\n",
      "Epoch 4/9\n",
      "208/208 [==============================] - 0s 549us/step - loss: 1.5453 - acc: 0.4279 - val_loss: 1.6269 - val_acc: 0.5385\n",
      "Epoch 5/9\n",
      "208/208 [==============================] - 0s 555us/step - loss: 1.5589 - acc: 0.5096 - val_loss: 1.4701 - val_acc: 0.5000\n",
      "Epoch 6/9\n",
      "208/208 [==============================] - 0s 643us/step - loss: 1.1923 - acc: 0.5817 - val_loss: 1.5850 - val_acc: 0.4423\n",
      "Epoch 7/9\n",
      "208/208 [==============================] - 0s 549us/step - loss: 1.3101 - acc: 0.5577 - val_loss: 1.3253 - val_acc: 0.5769\n",
      "Epoch 8/9\n",
      "208/208 [==============================] - 0s 543us/step - loss: 0.9788 - acc: 0.6346 - val_loss: 1.2279 - val_acc: 0.5577\n",
      "Epoch 9/9\n",
      "208/208 [==============================] - 0s 624us/step - loss: 0.9346 - acc: 0.6875 - val_loss: 1.4580 - val_acc: 0.5962\n",
      "Train on 208 samples, validate on 52 samples\n",
      "Epoch 1/10\n",
      "208/208 [==============================] - 9s 43ms/step - loss: 3.2605 - acc: 0.0962 - val_loss: 2.3147 - val_acc: 0.1154\n",
      "Epoch 2/10\n",
      "208/208 [==============================] - 0s 509us/step - loss: 2.3406 - acc: 0.3029 - val_loss: 1.9256 - val_acc: 0.3269\n",
      "Epoch 3/10\n",
      "208/208 [==============================] - 0s 550us/step - loss: 1.7144 - acc: 0.3942 - val_loss: 1.6005 - val_acc: 0.5000\n",
      "Epoch 4/10\n",
      "208/208 [==============================] - 0s 548us/step - loss: 1.5453 - acc: 0.4279 - val_loss: 1.6269 - val_acc: 0.5385\n",
      "Epoch 5/10\n",
      "208/208 [==============================] - 0s 499us/step - loss: 1.5589 - acc: 0.5096 - val_loss: 1.4701 - val_acc: 0.5000\n",
      "Epoch 6/10\n",
      "208/208 [==============================] - 0s 520us/step - loss: 1.1923 - acc: 0.5817 - val_loss: 1.5850 - val_acc: 0.4423\n",
      "Epoch 7/10\n",
      "208/208 [==============================] - 0s 541us/step - loss: 1.3101 - acc: 0.5577 - val_loss: 1.3253 - val_acc: 0.5769\n",
      "Epoch 8/10\n",
      "208/208 [==============================] - 0s 510us/step - loss: 0.9788 - acc: 0.6346 - val_loss: 1.2279 - val_acc: 0.5577\n",
      "Epoch 9/10\n",
      "208/208 [==============================] - 0s 530us/step - loss: 0.9346 - acc: 0.6875 - val_loss: 1.4580 - val_acc: 0.5962\n",
      "Epoch 10/10\n",
      "208/208 [==============================] - 0s 540us/step - loss: 0.8187 - acc: 0.7740 - val_loss: 1.0723 - val_acc: 0.6346\n",
      "Train on 208 samples, validate on 52 samples\n",
      "Epoch 1/11\n",
      "208/208 [==============================] - 9s 45ms/step - loss: 3.2605 - acc: 0.0962 - val_loss: 2.3147 - val_acc: 0.1154\n",
      "Epoch 2/11\n",
      "208/208 [==============================] - 0s 590us/step - loss: 2.3406 - acc: 0.3029 - val_loss: 1.9256 - val_acc: 0.3269\n",
      "Epoch 3/11\n",
      "208/208 [==============================] - 0s 517us/step - loss: 1.7144 - acc: 0.3942 - val_loss: 1.6005 - val_acc: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/11\n",
      "208/208 [==============================] - 0s 478us/step - loss: 1.5453 - acc: 0.4279 - val_loss: 1.6269 - val_acc: 0.5385\n",
      "Epoch 5/11\n",
      "208/208 [==============================] - 0s 581us/step - loss: 1.5589 - acc: 0.5096 - val_loss: 1.4701 - val_acc: 0.5000\n",
      "Epoch 6/11\n",
      "208/208 [==============================] - 0s 683us/step - loss: 1.1923 - acc: 0.5817 - val_loss: 1.5850 - val_acc: 0.4423\n",
      "Epoch 7/11\n",
      "208/208 [==============================] - 0s 594us/step - loss: 1.3101 - acc: 0.5577 - val_loss: 1.3253 - val_acc: 0.5769\n",
      "Epoch 8/11\n",
      "208/208 [==============================] - 0s 470us/step - loss: 0.9788 - acc: 0.6346 - val_loss: 1.2279 - val_acc: 0.5577\n",
      "Epoch 9/11\n",
      "208/208 [==============================] - 0s 555us/step - loss: 0.9346 - acc: 0.6875 - val_loss: 1.4580 - val_acc: 0.5962\n",
      "Epoch 10/11\n",
      "208/208 [==============================] - 0s 621us/step - loss: 0.8187 - acc: 0.7740 - val_loss: 1.0723 - val_acc: 0.6346\n",
      "Epoch 11/11\n",
      "208/208 [==============================] - 0s 679us/step - loss: 0.7353 - acc: 0.7596 - val_loss: 0.9954 - val_acc: 0.6731\n",
      "Train on 208 samples, validate on 52 samples\n",
      "Epoch 1/12\n",
      "208/208 [==============================] - 9s 41ms/step - loss: 3.2605 - acc: 0.0962 - val_loss: 2.3147 - val_acc: 0.1154\n",
      "Epoch 2/12\n",
      "208/208 [==============================] - 0s 534us/step - loss: 2.3406 - acc: 0.3029 - val_loss: 1.9256 - val_acc: 0.3269\n",
      "Epoch 3/12\n",
      "208/208 [==============================] - 0s 553us/step - loss: 1.7144 - acc: 0.3942 - val_loss: 1.6005 - val_acc: 0.5000\n",
      "Epoch 4/12\n",
      "208/208 [==============================] - 0s 512us/step - loss: 1.5453 - acc: 0.4279 - val_loss: 1.6269 - val_acc: 0.5385\n",
      "Epoch 5/12\n",
      "208/208 [==============================] - 0s 486us/step - loss: 1.5589 - acc: 0.5096 - val_loss: 1.4701 - val_acc: 0.5000\n",
      "Epoch 6/12\n",
      "208/208 [==============================] - 0s 513us/step - loss: 1.1923 - acc: 0.5817 - val_loss: 1.5850 - val_acc: 0.4423\n",
      "Epoch 7/12\n",
      "208/208 [==============================] - 0s 542us/step - loss: 1.3101 - acc: 0.5577 - val_loss: 1.3253 - val_acc: 0.5769\n",
      "Epoch 8/12\n",
      "208/208 [==============================] - 0s 597us/step - loss: 0.9788 - acc: 0.6346 - val_loss: 1.2279 - val_acc: 0.5577\n",
      "Epoch 9/12\n",
      "208/208 [==============================] - 0s 521us/step - loss: 0.9346 - acc: 0.6875 - val_loss: 1.4580 - val_acc: 0.5962\n",
      "Epoch 10/12\n",
      "208/208 [==============================] - 0s 490us/step - loss: 0.8187 - acc: 0.7740 - val_loss: 1.0723 - val_acc: 0.6346\n",
      "Epoch 11/12\n",
      "208/208 [==============================] - 0s 516us/step - loss: 0.7353 - acc: 0.7596 - val_loss: 0.9954 - val_acc: 0.6731\n",
      "Epoch 12/12\n",
      "208/208 [==============================] - 0s 512us/step - loss: 0.7850 - acc: 0.7356 - val_loss: 1.0725 - val_acc: 0.5769\n",
      "Train on 208 samples, validate on 52 samples\n",
      "Epoch 1/13\n",
      "208/208 [==============================] - 9s 41ms/step - loss: 3.2605 - acc: 0.0962 - val_loss: 2.3147 - val_acc: 0.1154\n",
      "Epoch 2/13\n",
      "208/208 [==============================] - 0s 505us/step - loss: 2.3406 - acc: 0.3029 - val_loss: 1.9256 - val_acc: 0.3269\n",
      "Epoch 3/13\n",
      "208/208 [==============================] - 0s 495us/step - loss: 1.7144 - acc: 0.3942 - val_loss: 1.6005 - val_acc: 0.5000\n",
      "Epoch 4/13\n",
      "208/208 [==============================] - 0s 511us/step - loss: 1.5453 - acc: 0.4279 - val_loss: 1.6269 - val_acc: 0.5385\n",
      "Epoch 5/13\n",
      "208/208 [==============================] - 0s 515us/step - loss: 1.5589 - acc: 0.5096 - val_loss: 1.4701 - val_acc: 0.5000\n",
      "Epoch 6/13\n",
      "208/208 [==============================] - 0s 586us/step - loss: 1.1923 - acc: 0.5817 - val_loss: 1.5850 - val_acc: 0.4423\n",
      "Epoch 7/13\n",
      "208/208 [==============================] - 0s 497us/step - loss: 1.3101 - acc: 0.5577 - val_loss: 1.3253 - val_acc: 0.5769\n",
      "Epoch 8/13\n",
      "208/208 [==============================] - 0s 507us/step - loss: 0.9788 - acc: 0.6346 - val_loss: 1.2279 - val_acc: 0.5577\n",
      "Epoch 9/13\n",
      "208/208 [==============================] - 0s 499us/step - loss: 0.9346 - acc: 0.6875 - val_loss: 1.4580 - val_acc: 0.5962\n",
      "Epoch 10/13\n",
      "208/208 [==============================] - 0s 496us/step - loss: 0.8187 - acc: 0.7740 - val_loss: 1.0723 - val_acc: 0.6346\n",
      "Epoch 11/13\n",
      "208/208 [==============================] - 0s 488us/step - loss: 0.7353 - acc: 0.7596 - val_loss: 0.9954 - val_acc: 0.6731\n",
      "Epoch 12/13\n",
      "208/208 [==============================] - 0s 472us/step - loss: 0.7850 - acc: 0.7356 - val_loss: 1.0725 - val_acc: 0.5769\n",
      "Epoch 13/13\n",
      "208/208 [==============================] - 0s 546us/step - loss: 0.5560 - acc: 0.7933 - val_loss: 1.0624 - val_acc: 0.6731\n",
      "Train on 208 samples, validate on 52 samples\n",
      "Epoch 1/14\n",
      "208/208 [==============================] - 9s 42ms/step - loss: 3.2605 - acc: 0.0962 - val_loss: 2.3147 - val_acc: 0.1154\n",
      "Epoch 2/14\n",
      "208/208 [==============================] - 0s 504us/step - loss: 2.3406 - acc: 0.3029 - val_loss: 1.9256 - val_acc: 0.3269\n",
      "Epoch 3/14\n",
      "208/208 [==============================] - 0s 472us/step - loss: 1.7144 - acc: 0.3942 - val_loss: 1.6005 - val_acc: 0.5000\n",
      "Epoch 4/14\n",
      "208/208 [==============================] - 0s 585us/step - loss: 1.5453 - acc: 0.4279 - val_loss: 1.6269 - val_acc: 0.5385\n",
      "Epoch 5/14\n",
      "208/208 [==============================] - 0s 506us/step - loss: 1.5589 - acc: 0.5096 - val_loss: 1.4701 - val_acc: 0.5000\n",
      "Epoch 6/14\n",
      "208/208 [==============================] - 0s 499us/step - loss: 1.1923 - acc: 0.5817 - val_loss: 1.5850 - val_acc: 0.4423\n",
      "Epoch 7/14\n",
      "208/208 [==============================] - 0s 675us/step - loss: 1.3101 - acc: 0.5577 - val_loss: 1.3253 - val_acc: 0.5769\n",
      "Epoch 8/14\n",
      "208/208 [==============================] - 0s 517us/step - loss: 0.9788 - acc: 0.6346 - val_loss: 1.2279 - val_acc: 0.5577\n",
      "Epoch 9/14\n",
      "208/208 [==============================] - 0s 525us/step - loss: 0.9346 - acc: 0.6875 - val_loss: 1.4580 - val_acc: 0.5962\n",
      "Epoch 10/14\n",
      "208/208 [==============================] - 0s 499us/step - loss: 0.8187 - acc: 0.7740 - val_loss: 1.0723 - val_acc: 0.6346\n",
      "Epoch 11/14\n",
      "208/208 [==============================] - 0s 525us/step - loss: 0.7353 - acc: 0.7596 - val_loss: 0.9954 - val_acc: 0.6731\n",
      "Epoch 12/14\n",
      "208/208 [==============================] - 0s 521us/step - loss: 0.7850 - acc: 0.7356 - val_loss: 1.0725 - val_acc: 0.5769\n",
      "Epoch 13/14\n",
      "208/208 [==============================] - 0s 482us/step - loss: 0.5560 - acc: 0.7933 - val_loss: 1.0624 - val_acc: 0.6731\n",
      "Epoch 14/14\n",
      "208/208 [==============================] - 0s 508us/step - loss: 0.5528 - acc: 0.8269 - val_loss: 1.0404 - val_acc: 0.6923\n",
      "Train on 208 samples, validate on 52 samples\n",
      "Epoch 1/15\n",
      "208/208 [==============================] - 9s 42ms/step - loss: 3.2605 - acc: 0.0962 - val_loss: 2.3147 - val_acc: 0.1154\n",
      "Epoch 2/15\n",
      "208/208 [==============================] - 0s 513us/step - loss: 2.3406 - acc: 0.3029 - val_loss: 1.9256 - val_acc: 0.3269\n",
      "Epoch 3/15\n",
      "208/208 [==============================] - 0s 528us/step - loss: 1.7144 - acc: 0.3942 - val_loss: 1.6005 - val_acc: 0.5000\n",
      "Epoch 4/15\n",
      "208/208 [==============================] - 0s 512us/step - loss: 1.5453 - acc: 0.4279 - val_loss: 1.6269 - val_acc: 0.5385\n",
      "Epoch 5/15\n",
      "208/208 [==============================] - 0s 553us/step - loss: 1.5589 - acc: 0.5096 - val_loss: 1.4701 - val_acc: 0.5000\n",
      "Epoch 6/15\n",
      "208/208 [==============================] - 0s 504us/step - loss: 1.1923 - acc: 0.5817 - val_loss: 1.5850 - val_acc: 0.4423\n",
      "Epoch 7/15\n",
      "208/208 [==============================] - 0s 484us/step - loss: 1.3101 - acc: 0.5577 - val_loss: 1.3253 - val_acc: 0.5769\n",
      "Epoch 8/15\n",
      "208/208 [==============================] - 0s 532us/step - loss: 0.9788 - acc: 0.6346 - val_loss: 1.2279 - val_acc: 0.5577\n",
      "Epoch 9/15\n",
      "208/208 [==============================] - 0s 508us/step - loss: 0.9346 - acc: 0.6875 - val_loss: 1.4580 - val_acc: 0.5962\n",
      "Epoch 10/15\n",
      "208/208 [==============================] - 0s 506us/step - loss: 0.8187 - acc: 0.7740 - val_loss: 1.0723 - val_acc: 0.6346\n",
      "Epoch 11/15\n",
      "208/208 [==============================] - 0s 477us/step - loss: 0.7353 - acc: 0.7596 - val_loss: 0.9954 - val_acc: 0.6731\n",
      "Epoch 12/15\n",
      "208/208 [==============================] - 0s 561us/step - loss: 0.7850 - acc: 0.7356 - val_loss: 1.0725 - val_acc: 0.5769\n",
      "Epoch 13/15\n",
      "208/208 [==============================] - 0s 772us/step - loss: 0.5560 - acc: 0.7933 - val_loss: 1.0624 - val_acc: 0.6731\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/15\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.5978 - acc: 0.804 - 0s 610us/step - loss: 0.5528 - acc: 0.8269 - val_loss: 1.0404 - val_acc: 0.6923\n",
      "Epoch 15/15\n",
      "208/208 [==============================] - 0s 644us/step - loss: 0.5593 - acc: 0.7885 - val_loss: 1.0953 - val_acc: 0.6923\n",
      "Train on 208 samples, validate on 52 samples\n",
      "Epoch 1/16\n",
      "208/208 [==============================] - 9s 44ms/step - loss: 3.2605 - acc: 0.0962 - val_loss: 2.3147 - val_acc: 0.1154\n",
      "Epoch 2/16\n",
      "208/208 [==============================] - 0s 491us/step - loss: 2.3406 - acc: 0.3029 - val_loss: 1.9256 - val_acc: 0.3269\n",
      "Epoch 3/16\n",
      "208/208 [==============================] - 0s 498us/step - loss: 1.7144 - acc: 0.3942 - val_loss: 1.6005 - val_acc: 0.5000\n",
      "Epoch 4/16\n",
      "208/208 [==============================] - 0s 481us/step - loss: 1.5453 - acc: 0.4279 - val_loss: 1.6269 - val_acc: 0.5385\n",
      "Epoch 5/16\n",
      "208/208 [==============================] - 0s 503us/step - loss: 1.5589 - acc: 0.5096 - val_loss: 1.4701 - val_acc: 0.5000\n",
      "Epoch 6/16\n",
      "208/208 [==============================] - 0s 497us/step - loss: 1.1923 - acc: 0.5817 - val_loss: 1.5850 - val_acc: 0.4423\n",
      "Epoch 7/16\n",
      "208/208 [==============================] - 0s 504us/step - loss: 1.3101 - acc: 0.5577 - val_loss: 1.3253 - val_acc: 0.5769\n",
      "Epoch 8/16\n",
      "208/208 [==============================] - 0s 501us/step - loss: 0.9788 - acc: 0.6346 - val_loss: 1.2279 - val_acc: 0.5577\n",
      "Epoch 9/16\n",
      "208/208 [==============================] - 0s 504us/step - loss: 0.9346 - acc: 0.6875 - val_loss: 1.4580 - val_acc: 0.5962\n",
      "Epoch 10/16\n",
      "208/208 [==============================] - 0s 473us/step - loss: 0.8187 - acc: 0.7740 - val_loss: 1.0723 - val_acc: 0.6346\n",
      "Epoch 11/16\n",
      "208/208 [==============================] - 0s 488us/step - loss: 0.7353 - acc: 0.7596 - val_loss: 0.9954 - val_acc: 0.6731\n",
      "Epoch 12/16\n",
      "208/208 [==============================] - 0s 475us/step - loss: 0.7850 - acc: 0.7356 - val_loss: 1.0725 - val_acc: 0.5769\n",
      "Epoch 13/16\n",
      "208/208 [==============================] - 0s 501us/step - loss: 0.5560 - acc: 0.7933 - val_loss: 1.0624 - val_acc: 0.6731\n",
      "Epoch 14/16\n",
      "208/208 [==============================] - 0s 474us/step - loss: 0.5528 - acc: 0.8269 - val_loss: 1.0404 - val_acc: 0.6923\n",
      "Epoch 15/16\n",
      "208/208 [==============================] - 0s 486us/step - loss: 0.5593 - acc: 0.7885 - val_loss: 1.0953 - val_acc: 0.6923\n",
      "Epoch 16/16\n",
      "208/208 [==============================] - 0s 497us/step - loss: 0.5367 - acc: 0.8029 - val_loss: 1.0774 - val_acc: 0.6538\n",
      "Train on 208 samples, validate on 52 samples\n",
      "Epoch 1/17\n",
      "208/208 [==============================] - 9s 44ms/step - loss: 3.2605 - acc: 0.0962 - val_loss: 2.3147 - val_acc: 0.1154\n",
      "Epoch 2/17\n",
      "208/208 [==============================] - 0s 543us/step - loss: 2.3406 - acc: 0.3029 - val_loss: 1.9256 - val_acc: 0.3269\n",
      "Epoch 3/17\n",
      "208/208 [==============================] - 0s 510us/step - loss: 1.7144 - acc: 0.3942 - val_loss: 1.6005 - val_acc: 0.5000\n",
      "Epoch 4/17\n",
      "208/208 [==============================] - 0s 495us/step - loss: 1.5453 - acc: 0.4279 - val_loss: 1.6269 - val_acc: 0.5385\n",
      "Epoch 5/17\n",
      "208/208 [==============================] - 0s 568us/step - loss: 1.5589 - acc: 0.5096 - val_loss: 1.4701 - val_acc: 0.5000\n",
      "Epoch 6/17\n",
      "208/208 [==============================] - 0s 561us/step - loss: 1.1923 - acc: 0.5817 - val_loss: 1.5850 - val_acc: 0.4423\n",
      "Epoch 7/17\n",
      "208/208 [==============================] - 0s 729us/step - loss: 1.3101 - acc: 0.5577 - val_loss: 1.3253 - val_acc: 0.5769\n",
      "Epoch 8/17\n",
      "208/208 [==============================] - 0s 535us/step - loss: 0.9788 - acc: 0.6346 - val_loss: 1.2279 - val_acc: 0.5577\n",
      "Epoch 9/17\n",
      "208/208 [==============================] - 0s 508us/step - loss: 0.9346 - acc: 0.6875 - val_loss: 1.4580 - val_acc: 0.5962\n",
      "Epoch 10/17\n",
      "208/208 [==============================] - 0s 499us/step - loss: 0.8187 - acc: 0.7740 - val_loss: 1.0723 - val_acc: 0.6346\n",
      "Epoch 11/17\n",
      "208/208 [==============================] - 0s 563us/step - loss: 0.7354 - acc: 0.7596 - val_loss: 0.9927 - val_acc: 0.6731\n",
      "Epoch 12/17\n",
      "208/208 [==============================] - 0s 500us/step - loss: 0.7755 - acc: 0.7452 - val_loss: 1.0653 - val_acc: 0.5962\n",
      "Epoch 13/17\n",
      "208/208 [==============================] - 0s 541us/step - loss: 0.5581 - acc: 0.8029 - val_loss: 1.0618 - val_acc: 0.6538\n",
      "Epoch 14/17\n",
      "208/208 [==============================] - 0s 565us/step - loss: 0.5532 - acc: 0.8365 - val_loss: 1.0320 - val_acc: 0.6923\n",
      "Epoch 15/17\n",
      "208/208 [==============================] - 0s 510us/step - loss: 0.5525 - acc: 0.7933 - val_loss: 1.0897 - val_acc: 0.6731\n",
      "Epoch 16/17\n",
      "208/208 [==============================] - 0s 541us/step - loss: 0.5233 - acc: 0.8125 - val_loss: 1.0699 - val_acc: 0.6731\n",
      "Epoch 17/17\n",
      "208/208 [==============================] - 0s 519us/step - loss: 0.5573 - acc: 0.8125 - val_loss: 1.1184 - val_acc: 0.5769\n",
      "Train on 208 samples, validate on 52 samples\n",
      "Epoch 1/18\n",
      "208/208 [==============================] - 10s 47ms/step - loss: 3.2605 - acc: 0.0962 - val_loss: 2.3147 - val_acc: 0.1154\n",
      "Epoch 2/18\n",
      "208/208 [==============================] - 0s 547us/step - loss: 2.3406 - acc: 0.3029 - val_loss: 1.9256 - val_acc: 0.3269\n",
      "Epoch 3/18\n",
      "208/208 [==============================] - 0s 571us/step - loss: 1.7144 - acc: 0.3942 - val_loss: 1.6005 - val_acc: 0.5000\n",
      "Epoch 4/18\n",
      "208/208 [==============================] - 0s 568us/step - loss: 1.5453 - acc: 0.4279 - val_loss: 1.6269 - val_acc: 0.5385\n",
      "Epoch 5/18\n",
      "208/208 [==============================] - 0s 543us/step - loss: 1.5589 - acc: 0.5096 - val_loss: 1.4701 - val_acc: 0.5000\n",
      "Epoch 6/18\n",
      "208/208 [==============================] - 0s 501us/step - loss: 1.1923 - acc: 0.5817 - val_loss: 1.5850 - val_acc: 0.4423\n",
      "Epoch 7/18\n",
      "208/208 [==============================] - 0s 489us/step - loss: 1.3101 - acc: 0.5577 - val_loss: 1.3253 - val_acc: 0.5769\n",
      "Epoch 8/18\n",
      "208/208 [==============================] - 0s 487us/step - loss: 0.9788 - acc: 0.6346 - val_loss: 1.2279 - val_acc: 0.5577\n",
      "Epoch 9/18\n",
      "208/208 [==============================] - 0s 496us/step - loss: 0.9346 - acc: 0.6875 - val_loss: 1.4580 - val_acc: 0.5962\n",
      "Epoch 10/18\n",
      "208/208 [==============================] - 0s 492us/step - loss: 0.8187 - acc: 0.7740 - val_loss: 1.0723 - val_acc: 0.6346\n",
      "Epoch 11/18\n",
      "208/208 [==============================] - 0s 494us/step - loss: 0.7353 - acc: 0.7596 - val_loss: 0.9954 - val_acc: 0.6731\n",
      "Epoch 12/18\n",
      "208/208 [==============================] - 0s 503us/step - loss: 0.7850 - acc: 0.7356 - val_loss: 1.0725 - val_acc: 0.5769\n",
      "Epoch 13/18\n",
      "208/208 [==============================] - 0s 483us/step - loss: 0.5560 - acc: 0.7933 - val_loss: 1.0624 - val_acc: 0.6731\n",
      "Epoch 14/18\n",
      "208/208 [==============================] - 0s 490us/step - loss: 0.5528 - acc: 0.8269 - val_loss: 1.0404 - val_acc: 0.6923\n",
      "Epoch 15/18\n",
      "208/208 [==============================] - 0s 499us/step - loss: 0.5593 - acc: 0.7885 - val_loss: 1.0953 - val_acc: 0.6923\n",
      "Epoch 16/18\n",
      "208/208 [==============================] - 0s 490us/step - loss: 0.5367 - acc: 0.8029 - val_loss: 1.0774 - val_acc: 0.6538\n",
      "Epoch 17/18\n",
      "208/208 [==============================] - 0s 533us/step - loss: 0.5675 - acc: 0.7885 - val_loss: 1.1222 - val_acc: 0.5577\n",
      "Epoch 18/18\n",
      "208/208 [==============================] - 0s 501us/step - loss: 0.4930 - acc: 0.8221 - val_loss: 0.9414 - val_acc: 0.7308\n",
      "Train on 208 samples, validate on 52 samples\n",
      "Epoch 1/19\n",
      "208/208 [==============================] - 9s 42ms/step - loss: 3.2605 - acc: 0.0962 - val_loss: 2.3147 - val_acc: 0.1154\n",
      "Epoch 2/19\n",
      "208/208 [==============================] - 0s 518us/step - loss: 2.3406 - acc: 0.3029 - val_loss: 1.9256 - val_acc: 0.3269\n",
      "Epoch 3/19\n",
      "208/208 [==============================] - 0s 491us/step - loss: 1.7144 - acc: 0.3942 - val_loss: 1.6005 - val_acc: 0.5000\n",
      "Epoch 4/19\n",
      "208/208 [==============================] - 0s 481us/step - loss: 1.5453 - acc: 0.4279 - val_loss: 1.6269 - val_acc: 0.5385\n",
      "Epoch 5/19\n",
      "208/208 [==============================] - 0s 487us/step - loss: 1.5589 - acc: 0.5096 - val_loss: 1.4701 - val_acc: 0.5000\n",
      "Epoch 6/19\n",
      "208/208 [==============================] - 0s 505us/step - loss: 1.1923 - acc: 0.5817 - val_loss: 1.5850 - val_acc: 0.4423\n",
      "Epoch 7/19\n",
      "208/208 [==============================] - 0s 500us/step - loss: 1.3101 - acc: 0.5577 - val_loss: 1.3253 - val_acc: 0.5769\n",
      "Epoch 8/19\n",
      "208/208 [==============================] - 0s 511us/step - loss: 0.9788 - acc: 0.6346 - val_loss: 1.2279 - val_acc: 0.5577\n",
      "Epoch 9/19\n",
      "208/208 [==============================] - 0s 484us/step - loss: 0.9346 - acc: 0.6875 - val_loss: 1.4580 - val_acc: 0.5962\n",
      "Epoch 10/19\n",
      "208/208 [==============================] - 0s 487us/step - loss: 0.8187 - acc: 0.7740 - val_loss: 1.0723 - val_acc: 0.6346\n",
      "Epoch 11/19\n",
      "208/208 [==============================] - 0s 489us/step - loss: 0.7353 - acc: 0.7596 - val_loss: 0.9954 - val_acc: 0.6731\n",
      "Epoch 12/19\n",
      "208/208 [==============================] - 0s 493us/step - loss: 0.7850 - acc: 0.7356 - val_loss: 1.0725 - val_acc: 0.5769\n",
      "Epoch 13/19\n",
      "208/208 [==============================] - 0s 500us/step - loss: 0.5560 - acc: 0.7933 - val_loss: 1.0624 - val_acc: 0.6731\n",
      "Epoch 14/19\n",
      "208/208 [==============================] - 0s 496us/step - loss: 0.5528 - acc: 0.8269 - val_loss: 1.0404 - val_acc: 0.6923\n",
      "Epoch 15/19\n",
      "208/208 [==============================] - 0s 509us/step - loss: 0.5593 - acc: 0.7885 - val_loss: 1.0953 - val_acc: 0.6923\n",
      "Epoch 16/19\n",
      "208/208 [==============================] - 0s 511us/step - loss: 0.5367 - acc: 0.8029 - val_loss: 1.0774 - val_acc: 0.6538\n",
      "Epoch 17/19\n",
      "208/208 [==============================] - 0s 510us/step - loss: 0.5675 - acc: 0.7885 - val_loss: 1.1222 - val_acc: 0.5577\n",
      "Epoch 18/19\n",
      "208/208 [==============================] - 0s 513us/step - loss: 0.4930 - acc: 0.8221 - val_loss: 0.9414 - val_acc: 0.7308\n",
      "Epoch 19/19\n",
      "208/208 [==============================] - 0s 489us/step - loss: 0.3706 - acc: 0.8798 - val_loss: 1.1944 - val_acc: 0.5769\n",
      "Train on 208 samples, validate on 52 samples\n",
      "Epoch 1/20\n",
      "208/208 [==============================] - 9s 42ms/step - loss: 3.2605 - acc: 0.0962 - val_loss: 2.3147 - val_acc: 0.1154\n",
      "Epoch 2/20\n",
      "208/208 [==============================] - 0s 500us/step - loss: 2.3406 - acc: 0.3029 - val_loss: 1.9256 - val_acc: 0.3269\n",
      "Epoch 3/20\n",
      "208/208 [==============================] - 0s 491us/step - loss: 1.7144 - acc: 0.3942 - val_loss: 1.6005 - val_acc: 0.5000\n",
      "Epoch 4/20\n",
      "208/208 [==============================] - 0s 464us/step - loss: 1.5453 - acc: 0.4279 - val_loss: 1.6269 - val_acc: 0.5385\n",
      "Epoch 5/20\n",
      "208/208 [==============================] - 0s 487us/step - loss: 1.5589 - acc: 0.5096 - val_loss: 1.4701 - val_acc: 0.5000\n",
      "Epoch 6/20\n",
      "208/208 [==============================] - 0s 503us/step - loss: 1.1923 - acc: 0.5817 - val_loss: 1.5850 - val_acc: 0.4423\n",
      "Epoch 7/20\n",
      "208/208 [==============================] - 0s 503us/step - loss: 1.3101 - acc: 0.5577 - val_loss: 1.3253 - val_acc: 0.5769\n",
      "Epoch 8/20\n",
      "208/208 [==============================] - 0s 516us/step - loss: 0.9788 - acc: 0.6346 - val_loss: 1.2279 - val_acc: 0.5577\n",
      "Epoch 9/20\n",
      "208/208 [==============================] - 0s 506us/step - loss: 0.9346 - acc: 0.6875 - val_loss: 1.4580 - val_acc: 0.5962\n",
      "Epoch 10/20\n",
      "208/208 [==============================] - 0s 509us/step - loss: 0.8187 - acc: 0.7740 - val_loss: 1.0723 - val_acc: 0.6346\n",
      "Epoch 11/20\n",
      "208/208 [==============================] - 0s 503us/step - loss: 0.7353 - acc: 0.7596 - val_loss: 0.9954 - val_acc: 0.6731\n",
      "Epoch 12/20\n",
      "208/208 [==============================] - 0s 502us/step - loss: 0.7850 - acc: 0.7356 - val_loss: 1.0725 - val_acc: 0.5769\n",
      "Epoch 13/20\n",
      "208/208 [==============================] - 0s 525us/step - loss: 0.5560 - acc: 0.7933 - val_loss: 1.0624 - val_acc: 0.6731\n",
      "Epoch 14/20\n",
      "208/208 [==============================] - 0s 498us/step - loss: 0.5528 - acc: 0.8269 - val_loss: 1.0404 - val_acc: 0.6923\n",
      "Epoch 15/20\n",
      "208/208 [==============================] - 0s 499us/step - loss: 0.5593 - acc: 0.7885 - val_loss: 1.0953 - val_acc: 0.6923\n",
      "Epoch 16/20\n",
      "208/208 [==============================] - 0s 485us/step - loss: 0.5367 - acc: 0.8029 - val_loss: 1.0774 - val_acc: 0.6538\n",
      "Epoch 17/20\n",
      "208/208 [==============================] - 0s 489us/step - loss: 0.5675 - acc: 0.7885 - val_loss: 1.1222 - val_acc: 0.5577\n",
      "Epoch 18/20\n",
      "208/208 [==============================] - 0s 498us/step - loss: 0.4930 - acc: 0.8221 - val_loss: 0.9414 - val_acc: 0.7308\n",
      "Epoch 19/20\n",
      "208/208 [==============================] - 0s 491us/step - loss: 0.3706 - acc: 0.8798 - val_loss: 1.1944 - val_acc: 0.5769\n",
      "Epoch 20/20\n",
      "208/208 [==============================] - 0s 500us/step - loss: 0.4193 - acc: 0.8654 - val_loss: 1.0358 - val_acc: 0.6731\n",
      "Train on 208 samples, validate on 52 samples\n",
      "Epoch 1/21\n",
      "208/208 [==============================] - 9s 44ms/step - loss: 3.2605 - acc: 0.0962 - val_loss: 2.3147 - val_acc: 0.1154\n",
      "Epoch 2/21\n",
      "208/208 [==============================] - 0s 487us/step - loss: 2.3406 - acc: 0.3029 - val_loss: 1.9256 - val_acc: 0.3269\n",
      "Epoch 3/21\n",
      "208/208 [==============================] - 0s 462us/step - loss: 1.7144 - acc: 0.3942 - val_loss: 1.6005 - val_acc: 0.5000\n",
      "Epoch 4/21\n",
      "208/208 [==============================] - 0s 492us/step - loss: 1.5453 - acc: 0.4279 - val_loss: 1.6269 - val_acc: 0.5385\n",
      "Epoch 5/21\n",
      "208/208 [==============================] - 0s 505us/step - loss: 1.5589 - acc: 0.5096 - val_loss: 1.4701 - val_acc: 0.5000\n",
      "Epoch 6/21\n",
      "208/208 [==============================] - 0s 553us/step - loss: 1.1923 - acc: 0.5817 - val_loss: 1.5850 - val_acc: 0.4423\n",
      "Epoch 7/21\n",
      "208/208 [==============================] - 0s 491us/step - loss: 1.3101 - acc: 0.5577 - val_loss: 1.3253 - val_acc: 0.5769\n",
      "Epoch 8/21\n",
      "208/208 [==============================] - 0s 492us/step - loss: 0.9788 - acc: 0.6346 - val_loss: 1.2279 - val_acc: 0.5577\n",
      "Epoch 9/21\n",
      "208/208 [==============================] - 0s 504us/step - loss: 0.9346 - acc: 0.6875 - val_loss: 1.4580 - val_acc: 0.5962\n",
      "Epoch 10/21\n",
      "208/208 [==============================] - 0s 519us/step - loss: 0.8187 - acc: 0.7740 - val_loss: 1.0723 - val_acc: 0.6346\n",
      "Epoch 11/21\n",
      "208/208 [==============================] - 0s 522us/step - loss: 0.7353 - acc: 0.7596 - val_loss: 0.9954 - val_acc: 0.6731\n",
      "Epoch 12/21\n",
      "208/208 [==============================] - 0s 494us/step - loss: 0.7850 - acc: 0.7356 - val_loss: 1.0725 - val_acc: 0.5769\n",
      "Epoch 13/21\n",
      "208/208 [==============================] - 0s 568us/step - loss: 0.5560 - acc: 0.7933 - val_loss: 1.0624 - val_acc: 0.6731\n",
      "Epoch 14/21\n",
      "208/208 [==============================] - 0s 504us/step - loss: 0.5528 - acc: 0.8269 - val_loss: 1.0404 - val_acc: 0.6923\n",
      "Epoch 15/21\n",
      "208/208 [==============================] - 0s 534us/step - loss: 0.5593 - acc: 0.7885 - val_loss: 1.0953 - val_acc: 0.6923\n",
      "Epoch 16/21\n",
      "208/208 [==============================] - 0s 619us/step - loss: 0.5367 - acc: 0.8029 - val_loss: 1.0774 - val_acc: 0.6538\n",
      "Epoch 17/21\n",
      "208/208 [==============================] - 0s 586us/step - loss: 0.5675 - acc: 0.7885 - val_loss: 1.1222 - val_acc: 0.5577\n",
      "Epoch 18/21\n",
      "208/208 [==============================] - 0s 548us/step - loss: 0.4930 - acc: 0.8221 - val_loss: 0.9414 - val_acc: 0.7308\n",
      "Epoch 19/21\n",
      "208/208 [==============================] - 0s 508us/step - loss: 0.3706 - acc: 0.8798 - val_loss: 1.1944 - val_acc: 0.5769\n",
      "Epoch 20/21\n",
      "208/208 [==============================] - 0s 618us/step - loss: 0.4193 - acc: 0.8654 - val_loss: 1.0358 - val_acc: 0.6731\n",
      "Epoch 21/21\n",
      "208/208 [==============================] - 0s 521us/step - loss: 0.3843 - acc: 0.8798 - val_loss: 1.0398 - val_acc: 0.6731\n",
      "Train on 208 samples, validate on 52 samples\n",
      "Epoch 1/22\n",
      "208/208 [==============================] - 9s 44ms/step - loss: 3.2605 - acc: 0.0962 - val_loss: 2.3147 - val_acc: 0.1154\n",
      "Epoch 2/22\n",
      "208/208 [==============================] - 0s 498us/step - loss: 2.3406 - acc: 0.3029 - val_loss: 1.9256 - val_acc: 0.3269\n",
      "Epoch 3/22\n",
      "208/208 [==============================] - 0s 490us/step - loss: 1.7144 - acc: 0.3942 - val_loss: 1.6005 - val_acc: 0.5000\n",
      "Epoch 4/22\n",
      "208/208 [==============================] - 0s 523us/step - loss: 1.5453 - acc: 0.4279 - val_loss: 1.6269 - val_acc: 0.5385\n",
      "Epoch 5/22\n",
      "208/208 [==============================] - 0s 504us/step - loss: 1.5589 - acc: 0.5096 - val_loss: 1.4701 - val_acc: 0.5000\n",
      "Epoch 6/22\n",
      "208/208 [==============================] - 0s 564us/step - loss: 1.1923 - acc: 0.5817 - val_loss: 1.5850 - val_acc: 0.4423\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/22\n",
      "208/208 [==============================] - 0s 595us/step - loss: 1.3101 - acc: 0.5577 - val_loss: 1.3253 - val_acc: 0.5769\n",
      "Epoch 8/22\n",
      "208/208 [==============================] - 0s 520us/step - loss: 0.9788 - acc: 0.6346 - val_loss: 1.2279 - val_acc: 0.5577\n",
      "Epoch 9/22\n",
      "208/208 [==============================] - 0s 519us/step - loss: 0.9346 - acc: 0.6875 - val_loss: 1.4580 - val_acc: 0.5962\n",
      "Epoch 10/22\n",
      "208/208 [==============================] - 0s 613us/step - loss: 0.8187 - acc: 0.7740 - val_loss: 1.0709 - val_acc: 0.6346\n",
      "Epoch 11/22\n",
      "208/208 [==============================] - 0s 537us/step - loss: 0.7357 - acc: 0.7596 - val_loss: 0.9924 - val_acc: 0.6731\n",
      "Epoch 12/22\n",
      "208/208 [==============================] - 0s 572us/step - loss: 0.7824 - acc: 0.7356 - val_loss: 1.0638 - val_acc: 0.5962\n",
      "Epoch 13/22\n",
      "208/208 [==============================] - 0s 489us/step - loss: 0.5521 - acc: 0.7981 - val_loss: 1.0666 - val_acc: 0.6923\n",
      "Epoch 14/22\n",
      "208/208 [==============================] - 0s 501us/step - loss: 0.5497 - acc: 0.8317 - val_loss: 1.0374 - val_acc: 0.6923\n",
      "Epoch 15/22\n",
      "208/208 [==============================] - 0s 633us/step - loss: 0.5690 - acc: 0.7837 - val_loss: 1.1322 - val_acc: 0.6731\n",
      "Epoch 16/22\n",
      "208/208 [==============================] - 0s 516us/step - loss: 0.5306 - acc: 0.8125 - val_loss: 1.0782 - val_acc: 0.6923\n",
      "Epoch 17/22\n",
      "208/208 [==============================] - 0s 484us/step - loss: 0.5663 - acc: 0.8077 - val_loss: 1.0952 - val_acc: 0.5577\n",
      "Epoch 18/22\n",
      "208/208 [==============================] - 0s 492us/step - loss: 0.4812 - acc: 0.8413 - val_loss: 0.9568 - val_acc: 0.7308\n",
      "Epoch 19/22\n",
      "208/208 [==============================] - 0s 556us/step - loss: 0.3876 - acc: 0.8702 - val_loss: 1.2377 - val_acc: 0.5769\n",
      "Epoch 20/22\n",
      "208/208 [==============================] - 0s 556us/step - loss: 0.4191 - acc: 0.8606 - val_loss: 1.0381 - val_acc: 0.6731\n",
      "Epoch 21/22\n",
      "208/208 [==============================] - 0s 516us/step - loss: 0.3939 - acc: 0.8750 - val_loss: 1.0406 - val_acc: 0.6731\n",
      "Epoch 22/22\n",
      "208/208 [==============================] - 0s 512us/step - loss: 0.3568 - acc: 0.8894 - val_loss: 1.0797 - val_acc: 0.6346\n",
      "Train on 208 samples, validate on 52 samples\n",
      "Epoch 1/23\n",
      "208/208 [==============================] - 9s 44ms/step - loss: 3.2605 - acc: 0.0962 - val_loss: 2.3147 - val_acc: 0.1154\n",
      "Epoch 2/23\n",
      "208/208 [==============================] - 0s 500us/step - loss: 2.3406 - acc: 0.3029 - val_loss: 1.9256 - val_acc: 0.3269\n",
      "Epoch 3/23\n",
      "208/208 [==============================] - 0s 495us/step - loss: 1.7144 - acc: 0.3942 - val_loss: 1.6005 - val_acc: 0.5000\n",
      "Epoch 4/23\n",
      "208/208 [==============================] - 0s 526us/step - loss: 1.5453 - acc: 0.4279 - val_loss: 1.6269 - val_acc: 0.5385\n",
      "Epoch 5/23\n",
      "208/208 [==============================] - 0s 512us/step - loss: 1.5589 - acc: 0.5096 - val_loss: 1.4701 - val_acc: 0.5000\n",
      "Epoch 6/23\n",
      "208/208 [==============================] - 0s 501us/step - loss: 1.1923 - acc: 0.5817 - val_loss: 1.5850 - val_acc: 0.4423\n",
      "Epoch 7/23\n",
      "208/208 [==============================] - 0s 484us/step - loss: 1.3101 - acc: 0.5577 - val_loss: 1.3253 - val_acc: 0.5769\n",
      "Epoch 8/23\n",
      "208/208 [==============================] - 0s 546us/step - loss: 0.9788 - acc: 0.6346 - val_loss: 1.2279 - val_acc: 0.5577\n",
      "Epoch 9/23\n",
      "208/208 [==============================] - 0s 588us/step - loss: 0.9346 - acc: 0.6875 - val_loss: 1.4580 - val_acc: 0.5962\n",
      "Epoch 10/23\n",
      "208/208 [==============================] - 0s 478us/step - loss: 0.8187 - acc: 0.7740 - val_loss: 1.0723 - val_acc: 0.6346\n",
      "Epoch 11/23\n",
      "208/208 [==============================] - 0s 523us/step - loss: 0.7353 - acc: 0.7596 - val_loss: 0.9954 - val_acc: 0.6731\n",
      "Epoch 12/23\n",
      "208/208 [==============================] - 0s 488us/step - loss: 0.7850 - acc: 0.7356 - val_loss: 1.0725 - val_acc: 0.5769\n",
      "Epoch 13/23\n",
      "208/208 [==============================] - 0s 596us/step - loss: 0.5560 - acc: 0.7933 - val_loss: 1.0624 - val_acc: 0.6731\n",
      "Epoch 14/23\n",
      "208/208 [==============================] - 0s 539us/step - loss: 0.5528 - acc: 0.8269 - val_loss: 1.0404 - val_acc: 0.6923\n",
      "Epoch 15/23\n",
      "208/208 [==============================] - 0s 498us/step - loss: 0.5593 - acc: 0.7885 - val_loss: 1.0953 - val_acc: 0.6923\n",
      "Epoch 16/23\n",
      "208/208 [==============================] - 0s 492us/step - loss: 0.5367 - acc: 0.8029 - val_loss: 1.0774 - val_acc: 0.6538\n",
      "Epoch 17/23\n",
      "208/208 [==============================] - 0s 499us/step - loss: 0.5675 - acc: 0.7885 - val_loss: 1.1222 - val_acc: 0.5577\n",
      "Epoch 18/23\n",
      "208/208 [==============================] - 0s 499us/step - loss: 0.4930 - acc: 0.8221 - val_loss: 0.9414 - val_acc: 0.7308\n",
      "Epoch 19/23\n",
      "208/208 [==============================] - 0s 516us/step - loss: 0.3706 - acc: 0.8798 - val_loss: 1.1944 - val_acc: 0.5769\n",
      "Epoch 20/23\n",
      "208/208 [==============================] - 0s 494us/step - loss: 0.4193 - acc: 0.8654 - val_loss: 1.0358 - val_acc: 0.6731\n",
      "Epoch 21/23\n",
      "208/208 [==============================] - 0s 495us/step - loss: 0.3843 - acc: 0.8798 - val_loss: 1.0398 - val_acc: 0.6731\n",
      "Epoch 22/23\n",
      "208/208 [==============================] - 0s 475us/step - loss: 0.3499 - acc: 0.8846 - val_loss: 1.0967 - val_acc: 0.6538\n",
      "Epoch 23/23\n",
      "208/208 [==============================] - 0s 505us/step - loss: 0.3756 - acc: 0.8846 - val_loss: 1.0502 - val_acc: 0.6346\n",
      "Train on 208 samples, validate on 52 samples\n",
      "Epoch 1/24\n",
      "208/208 [==============================] - 9s 45ms/step - loss: 3.2605 - acc: 0.0962 - val_loss: 2.3147 - val_acc: 0.1154\n",
      "Epoch 2/24\n",
      "208/208 [==============================] - 0s 493us/step - loss: 2.3406 - acc: 0.3029 - val_loss: 1.9256 - val_acc: 0.3269\n",
      "Epoch 3/24\n",
      "208/208 [==============================] - 0s 525us/step - loss: 1.7144 - acc: 0.3942 - val_loss: 1.6005 - val_acc: 0.5000\n",
      "Epoch 4/24\n",
      "208/208 [==============================] - 0s 548us/step - loss: 1.5453 - acc: 0.4279 - val_loss: 1.6269 - val_acc: 0.5385\n",
      "Epoch 5/24\n",
      "208/208 [==============================] - 0s 493us/step - loss: 1.5589 - acc: 0.5096 - val_loss: 1.4701 - val_acc: 0.5000\n",
      "Epoch 6/24\n",
      "208/208 [==============================] - 0s 487us/step - loss: 1.1923 - acc: 0.5817 - val_loss: 1.5850 - val_acc: 0.4423\n",
      "Epoch 7/24\n",
      "208/208 [==============================] - 0s 516us/step - loss: 1.3101 - acc: 0.5577 - val_loss: 1.3253 - val_acc: 0.5769\n",
      "Epoch 8/24\n",
      "208/208 [==============================] - 0s 520us/step - loss: 0.9788 - acc: 0.6346 - val_loss: 1.2279 - val_acc: 0.5577\n",
      "Epoch 9/24\n",
      "208/208 [==============================] - 0s 580us/step - loss: 0.9346 - acc: 0.6875 - val_loss: 1.4580 - val_acc: 0.5962\n",
      "Epoch 10/24\n",
      "208/208 [==============================] - 0s 500us/step - loss: 0.8187 - acc: 0.7740 - val_loss: 1.0723 - val_acc: 0.6346\n",
      "Epoch 11/24\n",
      "208/208 [==============================] - 0s 505us/step - loss: 0.7353 - acc: 0.7596 - val_loss: 0.9954 - val_acc: 0.6731\n",
      "Epoch 12/24\n",
      "208/208 [==============================] - 0s 535us/step - loss: 0.7850 - acc: 0.7356 - val_loss: 1.0725 - val_acc: 0.5769\n",
      "Epoch 13/24\n",
      "208/208 [==============================] - 0s 588us/step - loss: 0.5560 - acc: 0.7933 - val_loss: 1.0624 - val_acc: 0.6731\n",
      "Epoch 14/24\n",
      "208/208 [==============================] - 0s 493us/step - loss: 0.5528 - acc: 0.8269 - val_loss: 1.0404 - val_acc: 0.6923\n",
      "Epoch 15/24\n",
      "208/208 [==============================] - 0s 504us/step - loss: 0.5593 - acc: 0.7885 - val_loss: 1.0953 - val_acc: 0.6923\n",
      "Epoch 16/24\n",
      "208/208 [==============================] - 0s 500us/step - loss: 0.5367 - acc: 0.8029 - val_loss: 1.0774 - val_acc: 0.6538\n",
      "Epoch 17/24\n",
      "208/208 [==============================] - 0s 486us/step - loss: 0.5675 - acc: 0.7885 - val_loss: 1.1222 - val_acc: 0.5577\n",
      "Epoch 18/24\n",
      "208/208 [==============================] - 0s 503us/step - loss: 0.4930 - acc: 0.8221 - val_loss: 0.9414 - val_acc: 0.7308\n",
      "Epoch 19/24\n",
      "208/208 [==============================] - 0s 497us/step - loss: 0.3706 - acc: 0.8798 - val_loss: 1.1944 - val_acc: 0.5769\n",
      "Epoch 20/24\n",
      "208/208 [==============================] - 0s 519us/step - loss: 0.4193 - acc: 0.8654 - val_loss: 1.0358 - val_acc: 0.6731\n",
      "Epoch 21/24\n",
      "208/208 [==============================] - 0s 504us/step - loss: 0.3843 - acc: 0.8798 - val_loss: 1.0400 - val_acc: 0.6731\n",
      "Epoch 22/24\n",
      "208/208 [==============================] - 0s 554us/step - loss: 0.3499 - acc: 0.8846 - val_loss: 1.0967 - val_acc: 0.6538\n",
      "Epoch 23/24\n",
      "208/208 [==============================] - 0s 501us/step - loss: 0.3757 - acc: 0.8846 - val_loss: 1.0499 - val_acc: 0.6346\n",
      "Epoch 24/24\n",
      "208/208 [==============================] - 0s 641us/step - loss: 0.3206 - acc: 0.9038 - val_loss: 1.0041 - val_acc: 0.6538\n",
      "Train on 208 samples, validate on 52 samples\n",
      "Epoch 1/25\n",
      "208/208 [==============================] - 9s 45ms/step - loss: 3.2605 - acc: 0.0962 - val_loss: 2.3147 - val_acc: 0.1154\n",
      "Epoch 2/25\n",
      "208/208 [==============================] - 0s 530us/step - loss: 2.3406 - acc: 0.3029 - val_loss: 1.9256 - val_acc: 0.3269\n",
      "Epoch 3/25\n",
      "208/208 [==============================] - 0s 552us/step - loss: 1.7144 - acc: 0.3942 - val_loss: 1.6005 - val_acc: 0.5000\n",
      "Epoch 4/25\n",
      "208/208 [==============================] - 0s 494us/step - loss: 1.5453 - acc: 0.4279 - val_loss: 1.6269 - val_acc: 0.5385\n",
      "Epoch 5/25\n",
      "208/208 [==============================] - 0s 485us/step - loss: 1.5589 - acc: 0.5096 - val_loss: 1.4701 - val_acc: 0.5000\n",
      "Epoch 6/25\n",
      "208/208 [==============================] - 0s 497us/step - loss: 1.1923 - acc: 0.5817 - val_loss: 1.5850 - val_acc: 0.4423\n",
      "Epoch 7/25\n",
      "208/208 [==============================] - 0s 497us/step - loss: 1.3101 - acc: 0.5577 - val_loss: 1.3253 - val_acc: 0.5769\n",
      "Epoch 8/25\n",
      "208/208 [==============================] - 0s 591us/step - loss: 0.9788 - acc: 0.6346 - val_loss: 1.2279 - val_acc: 0.5577\n",
      "Epoch 9/25\n",
      "208/208 [==============================] - 0s 497us/step - loss: 0.9346 - acc: 0.6875 - val_loss: 1.4580 - val_acc: 0.5962\n",
      "Epoch 10/25\n",
      "208/208 [==============================] - 0s 487us/step - loss: 0.8187 - acc: 0.7740 - val_loss: 1.0723 - val_acc: 0.6346\n",
      "Epoch 11/25\n",
      "208/208 [==============================] - 0s 613us/step - loss: 0.7353 - acc: 0.7596 - val_loss: 0.9955 - val_acc: 0.6731\n",
      "Epoch 12/25\n",
      "208/208 [==============================] - 0s 507us/step - loss: 0.7868 - acc: 0.7356 - val_loss: 1.0632 - val_acc: 0.6346\n",
      "Epoch 13/25\n",
      "208/208 [==============================] - 0s 495us/step - loss: 0.5516 - acc: 0.8029 - val_loss: 1.0527 - val_acc: 0.6923\n",
      "Epoch 14/25\n",
      "208/208 [==============================] - 0s 509us/step - loss: 0.5550 - acc: 0.8269 - val_loss: 1.0342 - val_acc: 0.6923\n",
      "Epoch 15/25\n",
      "208/208 [==============================] - 0s 494us/step - loss: 0.5691 - acc: 0.7885 - val_loss: 1.0850 - val_acc: 0.7115\n",
      "Epoch 16/25\n",
      "208/208 [==============================] - 0s 543us/step - loss: 0.5335 - acc: 0.8077 - val_loss: 1.0762 - val_acc: 0.6538\n",
      "Epoch 17/25\n",
      "208/208 [==============================] - 0s 517us/step - loss: 0.5561 - acc: 0.7740 - val_loss: 1.1230 - val_acc: 0.5577\n",
      "Epoch 18/25\n",
      "208/208 [==============================] - 0s 514us/step - loss: 0.4836 - acc: 0.8510 - val_loss: 0.9478 - val_acc: 0.7115\n",
      "Epoch 19/25\n",
      "208/208 [==============================] - 0s 636us/step - loss: 0.3661 - acc: 0.8654 - val_loss: 1.1837 - val_acc: 0.5962\n",
      "Epoch 20/25\n",
      "208/208 [==============================] - 0s 489us/step - loss: 0.4130 - acc: 0.8606 - val_loss: 1.0201 - val_acc: 0.6731\n",
      "Epoch 21/25\n",
      "208/208 [==============================] - 0s 488us/step - loss: 0.3805 - acc: 0.8750 - val_loss: 1.0442 - val_acc: 0.6538\n",
      "Epoch 22/25\n",
      "208/208 [==============================] - 0s 605us/step - loss: 0.3630 - acc: 0.8798 - val_loss: 1.0882 - val_acc: 0.6346\n",
      "Epoch 23/25\n",
      "208/208 [==============================] - 0s 552us/step - loss: 0.3748 - acc: 0.8798 - val_loss: 1.0776 - val_acc: 0.6346\n",
      "Epoch 24/25\n",
      "208/208 [==============================] - 0s 503us/step - loss: 0.3200 - acc: 0.8990 - val_loss: 1.0309 - val_acc: 0.6346\n",
      "Epoch 25/25\n",
      "208/208 [==============================] - 0s 500us/step - loss: 0.3353 - acc: 0.9038 - val_loss: 0.9805 - val_acc: 0.6923\n",
      "Train on 208 samples, validate on 52 samples\n",
      "Epoch 1/26\n",
      "208/208 [==============================] - 9s 45ms/step - loss: 3.2605 - acc: 0.0962 - val_loss: 2.3147 - val_acc: 0.1154\n",
      "Epoch 2/26\n",
      "208/208 [==============================] - 0s 490us/step - loss: 2.3406 - acc: 0.3029 - val_loss: 1.9256 - val_acc: 0.3269\n",
      "Epoch 3/26\n",
      "208/208 [==============================] - 0s 663us/step - loss: 1.7144 - acc: 0.3942 - val_loss: 1.5971 - val_acc: 0.4808\n",
      "Epoch 4/26\n",
      "208/208 [==============================] - 0s 500us/step - loss: 1.5512 - acc: 0.4231 - val_loss: 1.6564 - val_acc: 0.4808\n",
      "Epoch 5/26\n",
      "208/208 [==============================] - 0s 484us/step - loss: 1.5958 - acc: 0.5000 - val_loss: 1.4873 - val_acc: 0.4808\n",
      "Epoch 6/26\n",
      "208/208 [==============================] - 0s 510us/step - loss: 1.1980 - acc: 0.5769 - val_loss: 1.5709 - val_acc: 0.4615\n",
      "Epoch 7/26\n",
      "208/208 [==============================] - 0s 590us/step - loss: 1.3101 - acc: 0.5240 - val_loss: 1.3984 - val_acc: 0.5385\n",
      "Epoch 8/26\n",
      "208/208 [==============================] - 0s 480us/step - loss: 1.0515 - acc: 0.6202 - val_loss: 1.2872 - val_acc: 0.5192\n",
      "Epoch 9/26\n",
      "208/208 [==============================] - 0s 493us/step - loss: 0.9023 - acc: 0.7019 - val_loss: 1.2969 - val_acc: 0.5962\n",
      "Epoch 10/26\n",
      "208/208 [==============================] - 0s 510us/step - loss: 0.7184 - acc: 0.7644 - val_loss: 1.1071 - val_acc: 0.6154\n",
      "Epoch 11/26\n",
      "208/208 [==============================] - 0s 486us/step - loss: 0.7579 - acc: 0.7596 - val_loss: 1.0061 - val_acc: 0.6731\n",
      "Epoch 12/26\n",
      "208/208 [==============================] - 0s 508us/step - loss: 0.7355 - acc: 0.7356 - val_loss: 1.0241 - val_acc: 0.6731\n",
      "Epoch 13/26\n",
      "208/208 [==============================] - 0s 490us/step - loss: 0.5920 - acc: 0.8125 - val_loss: 1.0364 - val_acc: 0.6538\n",
      "Epoch 14/26\n",
      "208/208 [==============================] - 0s 525us/step - loss: 0.5404 - acc: 0.8221 - val_loss: 1.0085 - val_acc: 0.7115\n",
      "Epoch 15/26\n",
      "208/208 [==============================] - 0s 497us/step - loss: 0.5817 - acc: 0.7788 - val_loss: 1.1276 - val_acc: 0.6346\n",
      "Epoch 16/26\n",
      "208/208 [==============================] - 0s 539us/step - loss: 0.5518 - acc: 0.8269 - val_loss: 1.0618 - val_acc: 0.6731\n",
      "Epoch 17/26\n",
      "208/208 [==============================] - 0s 513us/step - loss: 0.5702 - acc: 0.7788 - val_loss: 1.1079 - val_acc: 0.5962\n",
      "Epoch 18/26\n",
      "208/208 [==============================] - 0s 496us/step - loss: 0.4647 - acc: 0.8510 - val_loss: 0.9453 - val_acc: 0.7115\n",
      "Epoch 19/26\n",
      "208/208 [==============================] - 0s 513us/step - loss: 0.3728 - acc: 0.8846 - val_loss: 1.2227 - val_acc: 0.5769\n",
      "Epoch 20/26\n",
      "208/208 [==============================] - 0s 507us/step - loss: 0.4148 - acc: 0.8654 - val_loss: 1.0219 - val_acc: 0.6923\n",
      "Epoch 21/26\n",
      "208/208 [==============================] - 0s 514us/step - loss: 0.3910 - acc: 0.8942 - val_loss: 1.0587 - val_acc: 0.6538\n",
      "Epoch 22/26\n",
      "208/208 [==============================] - 0s 498us/step - loss: 0.3553 - acc: 0.9087 - val_loss: 1.0698 - val_acc: 0.6154\n",
      "Epoch 23/26\n",
      "208/208 [==============================] - 0s 483us/step - loss: 0.3725 - acc: 0.8702 - val_loss: 1.0605 - val_acc: 0.6538\n",
      "Epoch 24/26\n",
      "208/208 [==============================] - 0s 606us/step - loss: 0.3201 - acc: 0.8990 - val_loss: 1.0363 - val_acc: 0.6346\n",
      "Epoch 25/26\n",
      "208/208 [==============================] - 0s 545us/step - loss: 0.3255 - acc: 0.8798 - val_loss: 0.9583 - val_acc: 0.6731\n",
      "Epoch 26/26\n",
      "208/208 [==============================] - 0s 519us/step - loss: 0.2701 - acc: 0.9038 - val_loss: 1.0587 - val_acc: 0.6538\n",
      "Train on 208 samples, validate on 52 samples\n",
      "Epoch 1/27\n",
      "208/208 [==============================] - 9s 45ms/step - loss: 3.2605 - acc: 0.0962 - val_loss: 2.3147 - val_acc: 0.1154\n",
      "Epoch 2/27\n",
      "208/208 [==============================] - 0s 500us/step - loss: 2.3406 - acc: 0.3029 - val_loss: 1.9256 - val_acc: 0.3269\n",
      "Epoch 3/27\n",
      "208/208 [==============================] - 0s 505us/step - loss: 1.7144 - acc: 0.3942 - val_loss: 1.6005 - val_acc: 0.5000\n",
      "Epoch 4/27\n",
      "208/208 [==============================] - 0s 477us/step - loss: 1.5453 - acc: 0.4279 - val_loss: 1.6269 - val_acc: 0.5385\n",
      "Epoch 5/27\n",
      "208/208 [==============================] - 0s 497us/step - loss: 1.5589 - acc: 0.5096 - val_loss: 1.4701 - val_acc: 0.5000\n",
      "Epoch 6/27\n",
      "208/208 [==============================] - 0s 504us/step - loss: 1.1923 - acc: 0.5817 - val_loss: 1.5850 - val_acc: 0.4423\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/27\n",
      "208/208 [==============================] - 0s 496us/step - loss: 1.3101 - acc: 0.5577 - val_loss: 1.3253 - val_acc: 0.5769\n",
      "Epoch 8/27\n",
      "208/208 [==============================] - 0s 484us/step - loss: 0.9788 - acc: 0.6346 - val_loss: 1.2279 - val_acc: 0.5577\n",
      "Epoch 9/27\n",
      "208/208 [==============================] - 0s 498us/step - loss: 0.9346 - acc: 0.6875 - val_loss: 1.4580 - val_acc: 0.5962\n",
      "Epoch 10/27\n",
      "208/208 [==============================] - 0s 506us/step - loss: 0.8187 - acc: 0.7740 - val_loss: 1.0723 - val_acc: 0.6346\n",
      "Epoch 11/27\n",
      "208/208 [==============================] - 0s 490us/step - loss: 0.7353 - acc: 0.7596 - val_loss: 0.9954 - val_acc: 0.6731\n",
      "Epoch 12/27\n",
      "208/208 [==============================] - 0s 475us/step - loss: 0.7850 - acc: 0.7356 - val_loss: 1.0725 - val_acc: 0.5769\n",
      "Epoch 13/27\n",
      "208/208 [==============================] - 0s 496us/step - loss: 0.5560 - acc: 0.7933 - val_loss: 1.0624 - val_acc: 0.6731\n",
      "Epoch 14/27\n",
      "208/208 [==============================] - 0s 671us/step - loss: 0.5528 - acc: 0.8269 - val_loss: 1.0404 - val_acc: 0.6923\n",
      "Epoch 15/27\n",
      "208/208 [==============================] - 0s 572us/step - loss: 0.5593 - acc: 0.7885 - val_loss: 1.0953 - val_acc: 0.6923\n",
      "Epoch 16/27\n",
      "208/208 [==============================] - 0s 532us/step - loss: 0.5367 - acc: 0.8029 - val_loss: 1.0774 - val_acc: 0.6538\n",
      "Epoch 17/27\n",
      "208/208 [==============================] - 0s 558us/step - loss: 0.5675 - acc: 0.7885 - val_loss: 1.1222 - val_acc: 0.5577\n",
      "Epoch 18/27\n",
      "208/208 [==============================] - 0s 561us/step - loss: 0.4930 - acc: 0.8221 - val_loss: 0.9414 - val_acc: 0.7308\n",
      "Epoch 19/27\n",
      "208/208 [==============================] - 0s 570us/step - loss: 0.3706 - acc: 0.8798 - val_loss: 1.1944 - val_acc: 0.5769\n",
      "Epoch 20/27\n",
      "208/208 [==============================] - 0s 629us/step - loss: 0.4193 - acc: 0.8654 - val_loss: 1.0358 - val_acc: 0.6731\n",
      "Epoch 21/27\n",
      "208/208 [==============================] - 0s 572us/step - loss: 0.3843 - acc: 0.8798 - val_loss: 1.0398 - val_acc: 0.6731\n",
      "Epoch 22/27\n",
      "208/208 [==============================] - 0s 571us/step - loss: 0.3499 - acc: 0.8846 - val_loss: 1.0967 - val_acc: 0.6538\n",
      "Epoch 23/27\n",
      "208/208 [==============================] - 0s 573us/step - loss: 0.3756 - acc: 0.8846 - val_loss: 1.0502 - val_acc: 0.6346\n",
      "Epoch 24/27\n",
      "208/208 [==============================] - 0s 493us/step - loss: 0.3208 - acc: 0.9038 - val_loss: 1.0037 - val_acc: 0.6538\n",
      "Epoch 25/27\n",
      "208/208 [==============================] - 0s 485us/step - loss: 0.3328 - acc: 0.9135 - val_loss: 0.9661 - val_acc: 0.6731\n",
      "Epoch 26/27\n",
      "208/208 [==============================] - 0s 512us/step - loss: 0.2630 - acc: 0.9135 - val_loss: 1.0296 - val_acc: 0.6346\n",
      "Epoch 27/27\n",
      "208/208 [==============================] - 0s 492us/step - loss: 0.3162 - acc: 0.9038 - val_loss: 1.1386 - val_acc: 0.5385\n",
      "Train on 208 samples, validate on 52 samples\n",
      "Epoch 1/28\n",
      "208/208 [==============================] - 11s 51ms/step - loss: 3.2605 - acc: 0.0962 - val_loss: 2.3147 - val_acc: 0.1154\n",
      "Epoch 2/28\n",
      "208/208 [==============================] - 0s 559us/step - loss: 2.3406 - acc: 0.3029 - val_loss: 1.9256 - val_acc: 0.3269\n",
      "Epoch 3/28\n",
      "208/208 [==============================] - 0s 583us/step - loss: 1.7144 - acc: 0.3942 - val_loss: 1.6005 - val_acc: 0.5000\n",
      "Epoch 4/28\n",
      "208/208 [==============================] - 0s 548us/step - loss: 1.5453 - acc: 0.4279 - val_loss: 1.6269 - val_acc: 0.5385\n",
      "Epoch 5/28\n",
      "208/208 [==============================] - 0s 526us/step - loss: 1.5589 - acc: 0.5096 - val_loss: 1.4680 - val_acc: 0.4808\n",
      "Epoch 6/28\n",
      "208/208 [==============================] - 0s 575us/step - loss: 1.1893 - acc: 0.5769 - val_loss: 1.5705 - val_acc: 0.4231\n",
      "Epoch 7/28\n",
      "208/208 [==============================] - 0s 914us/step - loss: 1.2999 - acc: 0.5625 - val_loss: 1.2745 - val_acc: 0.5769\n",
      "Epoch 8/28\n",
      "208/208 [==============================] - 0s 561us/step - loss: 0.9623 - acc: 0.6635 - val_loss: 1.2640 - val_acc: 0.5577\n",
      "Epoch 9/28\n",
      "208/208 [==============================] - 0s 502us/step - loss: 0.9485 - acc: 0.6587 - val_loss: 1.4633 - val_acc: 0.5577\n",
      "Epoch 10/28\n",
      "208/208 [==============================] - 0s 644us/step - loss: 0.8064 - acc: 0.7596 - val_loss: 1.0580 - val_acc: 0.6538\n",
      "Epoch 11/28\n",
      "208/208 [==============================] - 0s 905us/step - loss: 0.7343 - acc: 0.7788 - val_loss: 1.0000 - val_acc: 0.6923\n",
      "Epoch 12/28\n",
      "208/208 [==============================] - 0s 804us/step - loss: 0.8136 - acc: 0.7212 - val_loss: 1.0517 - val_acc: 0.6346\n",
      "Epoch 13/28\n",
      "208/208 [==============================] - 0s 594us/step - loss: 0.5798 - acc: 0.8029 - val_loss: 1.0421 - val_acc: 0.6538\n",
      "Epoch 14/28\n",
      "208/208 [==============================] - 0s 532us/step - loss: 0.5673 - acc: 0.8317 - val_loss: 1.0188 - val_acc: 0.6731\n",
      "Epoch 15/28\n",
      "208/208 [==============================] - 0s 672us/step - loss: 0.5593 - acc: 0.7981 - val_loss: 1.1054 - val_acc: 0.6731\n",
      "Epoch 16/28\n",
      "208/208 [==============================] - 0s 835us/step - loss: 0.5451 - acc: 0.8125 - val_loss: 1.0333 - val_acc: 0.6731\n",
      "Epoch 17/28\n",
      "208/208 [==============================] - 0s 842us/step - loss: 0.5658 - acc: 0.8029 - val_loss: 1.0795 - val_acc: 0.5962\n",
      "Epoch 18/28\n",
      "208/208 [==============================] - 0s 752us/step - loss: 0.4787 - acc: 0.8413 - val_loss: 0.9329 - val_acc: 0.7115\n",
      "Epoch 19/28\n",
      "208/208 [==============================] - 0s 647us/step - loss: 0.3593 - acc: 0.8846 - val_loss: 1.1751 - val_acc: 0.5769\n",
      "Epoch 20/28\n",
      "208/208 [==============================] - 0s 807us/step - loss: 0.4197 - acc: 0.8702 - val_loss: 0.9977 - val_acc: 0.6731\n",
      "Epoch 21/28\n",
      "208/208 [==============================] - 0s 785us/step - loss: 0.3540 - acc: 0.8894 - val_loss: 1.0574 - val_acc: 0.6538\n",
      "Epoch 22/28\n",
      "208/208 [==============================] - 0s 629us/step - loss: 0.3510 - acc: 0.8894 - val_loss: 1.1173 - val_acc: 0.6154\n",
      "Epoch 23/28\n",
      "208/208 [==============================] - 0s 820us/step - loss: 0.3885 - acc: 0.8750 - val_loss: 1.0422 - val_acc: 0.6346\n",
      "Epoch 24/28\n",
      "208/208 [==============================] - 0s 829us/step - loss: 0.3327 - acc: 0.8798 - val_loss: 1.0263 - val_acc: 0.6538\n",
      "Epoch 25/28\n",
      "208/208 [==============================] - 0s 532us/step - loss: 0.3373 - acc: 0.9087 - val_loss: 0.9751 - val_acc: 0.6538\n",
      "Epoch 26/28\n",
      "208/208 [==============================] - 0s 655us/step - loss: 0.2647 - acc: 0.9135 - val_loss: 1.0230 - val_acc: 0.6346\n",
      "Epoch 27/28\n",
      "208/208 [==============================] - 0s 666us/step - loss: 0.3151 - acc: 0.8990 - val_loss: 1.1955 - val_acc: 0.5769\n",
      "Epoch 28/28\n",
      "208/208 [==============================] - 0s 663us/step - loss: 0.2346 - acc: 0.9375 - val_loss: 1.0263 - val_acc: 0.6346\n",
      "Train on 208 samples, validate on 52 samples\n",
      "Epoch 1/29\n",
      "208/208 [==============================] - 10s 48ms/step - loss: 3.2605 - acc: 0.0962 - val_loss: 2.3147 - val_acc: 0.1154\n",
      "Epoch 2/29\n",
      "208/208 [==============================] - 0s 588us/step - loss: 2.3406 - acc: 0.3029 - val_loss: 1.9256 - val_acc: 0.3269\n",
      "Epoch 3/29\n",
      "208/208 [==============================] - 0s 566us/step - loss: 1.7144 - acc: 0.3942 - val_loss: 1.6005 - val_acc: 0.5000\n",
      "Epoch 4/29\n",
      "208/208 [==============================] - 0s 575us/step - loss: 1.5453 - acc: 0.4279 - val_loss: 1.6269 - val_acc: 0.5385\n",
      "Epoch 5/29\n",
      "208/208 [==============================] - 0s 865us/step - loss: 1.5589 - acc: 0.5096 - val_loss: 1.4701 - val_acc: 0.5000\n",
      "Epoch 6/29\n",
      "208/208 [==============================] - 0s 1ms/step - loss: 1.1923 - acc: 0.5817 - val_loss: 1.5850 - val_acc: 0.4423\n",
      "Epoch 7/29\n",
      "208/208 [==============================] - 0s 659us/step - loss: 1.3101 - acc: 0.5577 - val_loss: 1.3253 - val_acc: 0.5769\n",
      "Epoch 8/29\n",
      "208/208 [==============================] - 0s 643us/step - loss: 0.9788 - acc: 0.6346 - val_loss: 1.2279 - val_acc: 0.5577\n",
      "Epoch 9/29\n",
      "208/208 [==============================] - 0s 673us/step - loss: 0.9346 - acc: 0.6875 - val_loss: 1.4580 - val_acc: 0.5962\n",
      "Epoch 10/29\n",
      "208/208 [==============================] - 0s 653us/step - loss: 0.8187 - acc: 0.7740 - val_loss: 1.0723 - val_acc: 0.6346\n",
      "Epoch 11/29\n",
      "208/208 [==============================] - 0s 675us/step - loss: 0.7353 - acc: 0.7596 - val_loss: 0.9954 - val_acc: 0.6731\n",
      "Epoch 12/29\n",
      "208/208 [==============================] - 0s 631us/step - loss: 0.7850 - acc: 0.7356 - val_loss: 1.0725 - val_acc: 0.5769\n",
      "Epoch 13/29\n",
      "208/208 [==============================] - 0s 554us/step - loss: 0.5560 - acc: 0.7933 - val_loss: 1.0624 - val_acc: 0.6731\n",
      "Epoch 14/29\n",
      "208/208 [==============================] - 0s 529us/step - loss: 0.5528 - acc: 0.8269 - val_loss: 1.0404 - val_acc: 0.6923\n",
      "Epoch 15/29\n",
      "208/208 [==============================] - 0s 501us/step - loss: 0.5593 - acc: 0.7885 - val_loss: 1.0953 - val_acc: 0.6923\n",
      "Epoch 16/29\n",
      "208/208 [==============================] - 0s 500us/step - loss: 0.5367 - acc: 0.8029 - val_loss: 1.0774 - val_acc: 0.6538\n",
      "Epoch 17/29\n",
      "208/208 [==============================] - 0s 498us/step - loss: 0.5675 - acc: 0.7885 - val_loss: 1.1222 - val_acc: 0.5577\n",
      "Epoch 18/29\n",
      "208/208 [==============================] - 0s 498us/step - loss: 0.4930 - acc: 0.8221 - val_loss: 0.9414 - val_acc: 0.7308\n",
      "Epoch 19/29\n",
      "208/208 [==============================] - 0s 502us/step - loss: 0.3706 - acc: 0.8798 - val_loss: 1.1944 - val_acc: 0.5769\n",
      "Epoch 20/29\n",
      "208/208 [==============================] - 0s 541us/step - loss: 0.4193 - acc: 0.8654 - val_loss: 1.0358 - val_acc: 0.6731\n",
      "Epoch 21/29\n",
      "208/208 [==============================] - 0s 493us/step - loss: 0.3843 - acc: 0.8798 - val_loss: 1.0398 - val_acc: 0.6731\n",
      "Epoch 22/29\n",
      "208/208 [==============================] - 0s 577us/step - loss: 0.3499 - acc: 0.8846 - val_loss: 1.0975 - val_acc: 0.6346\n",
      "Epoch 23/29\n",
      "208/208 [==============================] - 0s 544us/step - loss: 0.3769 - acc: 0.8846 - val_loss: 1.0534 - val_acc: 0.6346\n",
      "Epoch 24/29\n",
      "208/208 [==============================] - 0s 575us/step - loss: 0.3202 - acc: 0.9038 - val_loss: 1.0005 - val_acc: 0.6538\n",
      "Epoch 25/29\n",
      "208/208 [==============================] - 0s 579us/step - loss: 0.3357 - acc: 0.9087 - val_loss: 0.9628 - val_acc: 0.6731\n",
      "Epoch 26/29\n",
      "208/208 [==============================] - 0s 626us/step - loss: 0.2661 - acc: 0.9183 - val_loss: 1.0215 - val_acc: 0.6346\n",
      "Epoch 27/29\n",
      "208/208 [==============================] - 0s 577us/step - loss: 0.3134 - acc: 0.8990 - val_loss: 1.1533 - val_acc: 0.5577\n",
      "Epoch 28/29\n",
      "208/208 [==============================] - 0s 630us/step - loss: 0.2356 - acc: 0.9327 - val_loss: 1.0385 - val_acc: 0.6346\n",
      "Epoch 29/29\n",
      "208/208 [==============================] - 0s 670us/step - loss: 0.1976 - acc: 0.9375 - val_loss: 1.1116 - val_acc: 0.6154\n",
      "Train on 208 samples, validate on 52 samples\n",
      "Epoch 1/30\n",
      "128/208 [=================>............] - ETA: 11s - loss: 3.3213 - acc: 0.0781"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rakibul/anaconda3/lib/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.986501). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "208/208 [==============================] - 27s 128ms/step - loss: 3.2605 - acc: 0.0962 - val_loss: 2.3147 - val_acc: 0.1154\n",
      "Epoch 2/30\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 2.3406 - acc: 0.3029 - val_loss: 1.9153 - val_acc: 0.3269\n",
      "Epoch 3/30\n",
      "208/208 [==============================] - ETA: 0s - loss: 1.7088 - acc: 0.437 - 0s 1ms/step - loss: 1.7166 - acc: 0.3894 - val_loss: 1.6255 - val_acc: 0.4808\n",
      "Epoch 4/30\n",
      "208/208 [==============================] - 0s 639us/step - loss: 1.5497 - acc: 0.4279 - val_loss: 1.6066 - val_acc: 0.5769\n",
      "Epoch 5/30\n",
      "208/208 [==============================] - 0s 568us/step - loss: 1.5778 - acc: 0.5288 - val_loss: 1.5619 - val_acc: 0.4808\n",
      "Epoch 6/30\n",
      "208/208 [==============================] - 0s 556us/step - loss: 1.2419 - acc: 0.5577 - val_loss: 1.5282 - val_acc: 0.4615\n",
      "Epoch 7/30\n",
      "208/208 [==============================] - 0s 500us/step - loss: 1.2892 - acc: 0.5577 - val_loss: 1.3572 - val_acc: 0.5962\n",
      "Epoch 8/30\n",
      "208/208 [==============================] - 0s 500us/step - loss: 1.0215 - acc: 0.6250 - val_loss: 1.2697 - val_acc: 0.5385\n",
      "Epoch 9/30\n",
      "208/208 [==============================] - 0s 551us/step - loss: 0.9090 - acc: 0.6971 - val_loss: 1.4225 - val_acc: 0.5577\n",
      "Epoch 10/30\n",
      "208/208 [==============================] - 0s 592us/step - loss: 0.8035 - acc: 0.7452 - val_loss: 1.0446 - val_acc: 0.6731\n",
      "Epoch 11/30\n",
      "208/208 [==============================] - 0s 755us/step - loss: 0.7521 - acc: 0.7788 - val_loss: 0.9675 - val_acc: 0.7308\n",
      "Epoch 12/30\n",
      "208/208 [==============================] - 0s 2ms/step - loss: 0.7491 - acc: 0.7356 - val_loss: 0.9869 - val_acc: 0.6923\n",
      "Epoch 13/30\n",
      "208/208 [==============================] - 0s 761us/step - loss: 0.5711 - acc: 0.7885 - val_loss: 0.9992 - val_acc: 0.6923\n",
      "Epoch 14/30\n",
      "208/208 [==============================] - 0s 551us/step - loss: 0.5499 - acc: 0.8317 - val_loss: 1.0208 - val_acc: 0.7115\n",
      "Epoch 15/30\n",
      "208/208 [==============================] - 0s 645us/step - loss: 0.5729 - acc: 0.7933 - val_loss: 1.0931 - val_acc: 0.6538\n",
      "Epoch 16/30\n",
      "208/208 [==============================] - 0s 665us/step - loss: 0.5343 - acc: 0.8125 - val_loss: 1.0221 - val_acc: 0.6923\n",
      "Epoch 17/30\n",
      "208/208 [==============================] - 0s 959us/step - loss: 0.5491 - acc: 0.8029 - val_loss: 1.1106 - val_acc: 0.5385\n",
      "Epoch 18/30\n",
      "208/208 [==============================] - 0s 902us/step - loss: 0.4816 - acc: 0.8365 - val_loss: 0.9459 - val_acc: 0.7308\n",
      "Epoch 19/30\n",
      "208/208 [==============================] - 0s 684us/step - loss: 0.3501 - acc: 0.8990 - val_loss: 1.2687 - val_acc: 0.5769\n",
      "Epoch 20/30\n",
      "208/208 [==============================] - 0s 495us/step - loss: 0.4724 - acc: 0.8221 - val_loss: 1.1882 - val_acc: 0.6346\n",
      "Epoch 21/30\n",
      "208/208 [==============================] - 0s 484us/step - loss: 0.5082 - acc: 0.8510 - val_loss: 1.1596 - val_acc: 0.6346\n",
      "Epoch 22/30\n",
      "208/208 [==============================] - 0s 493us/step - loss: 0.3784 - acc: 0.8654 - val_loss: 1.0836 - val_acc: 0.6346\n",
      "Epoch 23/30\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 0.3866 - acc: 0.8750 - val_loss: 1.0682 - val_acc: 0.6154\n",
      "Epoch 24/30\n",
      "208/208 [==============================] - 0s 866us/step - loss: 0.3370 - acc: 0.8942 - val_loss: 1.0077 - val_acc: 0.6538\n",
      "Epoch 25/30\n",
      "208/208 [==============================] - 0s 539us/step - loss: 0.3271 - acc: 0.8846 - val_loss: 0.9641 - val_acc: 0.7115\n",
      "Epoch 26/30\n",
      "208/208 [==============================] - 0s 482us/step - loss: 0.2473 - acc: 0.9375 - val_loss: 1.0327 - val_acc: 0.6346\n",
      "Epoch 27/30\n",
      "208/208 [==============================] - 0s 485us/step - loss: 0.3108 - acc: 0.8942 - val_loss: 1.1553 - val_acc: 0.5769\n",
      "Epoch 28/30\n",
      "208/208 [==============================] - 0s 484us/step - loss: 0.2251 - acc: 0.9423 - val_loss: 1.0773 - val_acc: 0.6538\n",
      "Epoch 29/30\n",
      "208/208 [==============================] - 0s 483us/step - loss: 0.1957 - acc: 0.9519 - val_loss: 1.1214 - val_acc: 0.6346\n",
      "Epoch 30/30\n",
      "208/208 [==============================] - 0s 492us/step - loss: 0.2028 - acc: 0.9423 - val_loss: 1.1537 - val_acc: 0.6154\n",
      "Train on 208 samples, validate on 52 samples\n",
      "Epoch 1/31\n",
      "208/208 [==============================] - 11s 52ms/step - loss: 3.2605 - acc: 0.0962 - val_loss: 2.3147 - val_acc: 0.1154\n",
      "Epoch 2/31\n",
      "208/208 [==============================] - 0s 619us/step - loss: 2.3406 - acc: 0.3029 - val_loss: 1.9256 - val_acc: 0.3269\n",
      "Epoch 3/31\n",
      "208/208 [==============================] - 0s 696us/step - loss: 1.7144 - acc: 0.3942 - val_loss: 1.6005 - val_acc: 0.5000\n",
      "Epoch 4/31\n",
      "208/208 [==============================] - 0s 725us/step - loss: 1.5453 - acc: 0.4279 - val_loss: 1.6269 - val_acc: 0.5385\n",
      "Epoch 5/31\n",
      "208/208 [==============================] - 0s 647us/step - loss: 1.5589 - acc: 0.5096 - val_loss: 1.4680 - val_acc: 0.4808\n",
      "Epoch 6/31\n",
      "208/208 [==============================] - 0s 724us/step - loss: 1.1893 - acc: 0.5769 - val_loss: 1.5709 - val_acc: 0.4231\n",
      "Epoch 7/31\n",
      "208/208 [==============================] - 0s 589us/step - loss: 1.3099 - acc: 0.5529 - val_loss: 1.2813 - val_acc: 0.5769\n",
      "Epoch 8/31\n",
      "208/208 [==============================] - 0s 578us/step - loss: 0.9735 - acc: 0.6587 - val_loss: 1.2512 - val_acc: 0.5769\n",
      "Epoch 9/31\n",
      "208/208 [==============================] - 0s 618us/step - loss: 0.9377 - acc: 0.6731 - val_loss: 1.4439 - val_acc: 0.5769\n",
      "Epoch 10/31\n",
      "208/208 [==============================] - 0s 588us/step - loss: 0.8160 - acc: 0.7548 - val_loss: 1.0709 - val_acc: 0.6538\n",
      "Epoch 11/31\n",
      "208/208 [==============================] - 0s 613us/step - loss: 0.7316 - acc: 0.7644 - val_loss: 0.9999 - val_acc: 0.7115\n",
      "Epoch 12/31\n",
      "208/208 [==============================] - 0s 574us/step - loss: 0.8169 - acc: 0.7212 - val_loss: 1.0401 - val_acc: 0.6346\n",
      "Epoch 13/31\n",
      "208/208 [==============================] - 0s 627us/step - loss: 0.5787 - acc: 0.7933 - val_loss: 1.0378 - val_acc: 0.6346\n",
      "Epoch 14/31\n",
      "208/208 [==============================] - 0s 557us/step - loss: 0.5577 - acc: 0.8221 - val_loss: 1.0116 - val_acc: 0.6923\n",
      "Epoch 15/31\n",
      "208/208 [==============================] - 0s 617us/step - loss: 0.5866 - acc: 0.8029 - val_loss: 1.1444 - val_acc: 0.6538\n",
      "Epoch 16/31\n",
      "208/208 [==============================] - 0s 577us/step - loss: 0.5429 - acc: 0.8077 - val_loss: 1.0671 - val_acc: 0.6923\n",
      "Epoch 17/31\n",
      "208/208 [==============================] - 0s 627us/step - loss: 0.5628 - acc: 0.7981 - val_loss: 1.0426 - val_acc: 0.5769\n",
      "Epoch 18/31\n",
      "208/208 [==============================] - 0s 590us/step - loss: 0.4621 - acc: 0.8510 - val_loss: 0.9022 - val_acc: 0.7308\n",
      "Epoch 19/31\n",
      "208/208 [==============================] - 0s 629us/step - loss: 0.3721 - acc: 0.8846 - val_loss: 1.1330 - val_acc: 0.6154\n",
      "Epoch 20/31\n",
      "208/208 [==============================] - 0s 590us/step - loss: 0.4033 - acc: 0.8702 - val_loss: 1.0690 - val_acc: 0.6538\n",
      "Epoch 21/31\n",
      "208/208 [==============================] - 0s 583us/step - loss: 0.4036 - acc: 0.8846 - val_loss: 1.0791 - val_acc: 0.6538\n",
      "Epoch 22/31\n",
      "208/208 [==============================] - 0s 576us/step - loss: 0.3464 - acc: 0.8798 - val_loss: 1.0819 - val_acc: 0.6346\n",
      "Epoch 23/31\n",
      "208/208 [==============================] - 0s 669us/step - loss: 0.3779 - acc: 0.8750 - val_loss: 1.0450 - val_acc: 0.6538\n",
      "Epoch 24/31\n",
      "208/208 [==============================] - 0s 630us/step - loss: 0.3262 - acc: 0.8990 - val_loss: 1.0255 - val_acc: 0.6346\n",
      "Epoch 25/31\n",
      "208/208 [==============================] - 0s 623us/step - loss: 0.3442 - acc: 0.8798 - val_loss: 0.9770 - val_acc: 0.7115\n",
      "Epoch 26/31\n",
      "208/208 [==============================] - 0s 586us/step - loss: 0.2740 - acc: 0.9087 - val_loss: 0.9960 - val_acc: 0.6538\n",
      "Epoch 27/31\n",
      "208/208 [==============================] - 0s 638us/step - loss: 0.3109 - acc: 0.8942 - val_loss: 1.1611 - val_acc: 0.6154\n",
      "Epoch 28/31\n",
      "208/208 [==============================] - 0s 574us/step - loss: 0.2361 - acc: 0.9327 - val_loss: 1.0394 - val_acc: 0.6538\n",
      "Epoch 29/31\n",
      "208/208 [==============================] - 0s 575us/step - loss: 0.2034 - acc: 0.9471 - val_loss: 1.0733 - val_acc: 0.6538\n",
      "Epoch 30/31\n",
      "208/208 [==============================] - 0s 619us/step - loss: 0.2116 - acc: 0.9375 - val_loss: 1.1356 - val_acc: 0.5769\n",
      "Epoch 31/31\n",
      "208/208 [==============================] - 0s 613us/step - loss: 0.2858 - acc: 0.8942 - val_loss: 1.0723 - val_acc: 0.6923\n",
      "Train on 208 samples, validate on 52 samples\n",
      "Epoch 1/32\n",
      "128/208 [=================>............] - ETA: 2:35 - loss: 3.3213 - acc: 0.0781"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rakibul/anaconda3/lib/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.819301). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "208/208 [==============================] - 259s 1s/step - loss: 3.2605 - acc: 0.0962 - val_loss: 2.3147 - val_acc: 0.1154\n",
      "Epoch 2/32\n",
      "208/208 [==============================] - 1s 4ms/step - loss: 2.3406 - acc: 0.3029 - val_loss: 1.9292 - val_acc: 0.3269\n",
      "Epoch 3/32\n",
      "208/208 [==============================] - 0s 975us/step - loss: 1.7209 - acc: 0.3942 - val_loss: 1.6150 - val_acc: 0.5000\n",
      "Epoch 4/32\n",
      "208/208 [==============================] - 0s 2ms/step - loss: 1.5247 - acc: 0.4519 - val_loss: 1.5664 - val_acc: 0.5000\n",
      "Epoch 5/32\n",
      "208/208 [==============================] - 0s 908us/step - loss: 1.5866 - acc: 0.5000 - val_loss: 1.5794 - val_acc: 0.4615\n",
      "Epoch 6/32\n",
      "208/208 [==============================] - 0s 2ms/step - loss: 1.1735 - acc: 0.5913 - val_loss: 1.5573 - val_acc: 0.4423\n",
      "Epoch 7/32\n",
      "128/208 [=================>............] - ETA: 0s - loss: 1.2925 - acc: 0.5547"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rakibul/anaconda3/lib/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.169142). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "208/208 [==============================] - 1s 4ms/step - loss: 1.2457 - acc: 0.5673 - val_loss: 1.4400 - val_acc: 0.5577\n",
      "Epoch 8/32\n",
      "208/208 [==============================] - 0s 475us/step - loss: 1.0770 - acc: 0.6154 - val_loss: 1.2559 - val_acc: 0.5769\n",
      "Epoch 9/32\n",
      "208/208 [==============================] - 0s 669us/step - loss: 0.9139 - acc: 0.7115 - val_loss: 1.4696 - val_acc: 0.5769\n",
      "Epoch 10/32\n",
      "208/208 [==============================] - 0s 764us/step - loss: 0.8111 - acc: 0.7500 - val_loss: 1.1513 - val_acc: 0.6538\n",
      "Epoch 11/32\n",
      "208/208 [==============================] - 0s 706us/step - loss: 0.7667 - acc: 0.7452 - val_loss: 1.0009 - val_acc: 0.6731\n",
      "Epoch 12/32\n",
      "208/208 [==============================] - 0s 579us/step - loss: 0.7497 - acc: 0.7308 - val_loss: 1.0411 - val_acc: 0.6154\n",
      "Epoch 13/32\n",
      "208/208 [==============================] - 0s 466us/step - loss: 0.5846 - acc: 0.8221 - val_loss: 1.0572 - val_acc: 0.6538\n",
      "Epoch 14/32\n",
      "208/208 [==============================] - 0s 514us/step - loss: 0.5733 - acc: 0.8317 - val_loss: 1.0317 - val_acc: 0.7308\n",
      "Epoch 15/32\n",
      "208/208 [==============================] - 0s 483us/step - loss: 0.5654 - acc: 0.8077 - val_loss: 1.1370 - val_acc: 0.6731\n",
      "Epoch 16/32\n",
      "208/208 [==============================] - 0s 483us/step - loss: 0.5326 - acc: 0.8125 - val_loss: 1.0402 - val_acc: 0.6538\n",
      "Epoch 17/32\n",
      "208/208 [==============================] - 0s 981us/step - loss: 0.5504 - acc: 0.7933 - val_loss: 1.0876 - val_acc: 0.5769\n",
      "Epoch 18/32\n",
      "208/208 [==============================] - 0s 473us/step - loss: 0.4885 - acc: 0.8221 - val_loss: 0.9453 - val_acc: 0.7308\n",
      "Epoch 19/32\n",
      "208/208 [==============================] - 0s 767us/step - loss: 0.3471 - acc: 0.8942 - val_loss: 1.2308 - val_acc: 0.5769\n",
      "Epoch 20/32\n",
      "208/208 [==============================] - 0s 487us/step - loss: 0.4260 - acc: 0.8558 - val_loss: 1.0372 - val_acc: 0.7115\n",
      "Epoch 21/32\n",
      "208/208 [==============================] - 0s 504us/step - loss: 0.4086 - acc: 0.8702 - val_loss: 1.0318 - val_acc: 0.6731\n",
      "Epoch 22/32\n",
      "208/208 [==============================] - 0s 505us/step - loss: 0.3469 - acc: 0.8894 - val_loss: 1.0890 - val_acc: 0.6154\n",
      "Epoch 23/32\n",
      "208/208 [==============================] - 0s 476us/step - loss: 0.3941 - acc: 0.8750 - val_loss: 1.0836 - val_acc: 0.6346\n",
      "Epoch 24/32\n",
      "208/208 [==============================] - 0s 491us/step - loss: 0.3369 - acc: 0.8750 - val_loss: 0.9970 - val_acc: 0.6538\n",
      "Epoch 25/32\n",
      "208/208 [==============================] - 0s 503us/step - loss: 0.3395 - acc: 0.8942 - val_loss: 0.9746 - val_acc: 0.6923\n",
      "Epoch 26/32\n",
      "208/208 [==============================] - 0s 2ms/step - loss: 0.2636 - acc: 0.9279 - val_loss: 1.0075 - val_acc: 0.6731\n",
      "Epoch 27/32\n",
      "208/208 [==============================] - 0s 484us/step - loss: 0.2999 - acc: 0.8942 - val_loss: 1.1767 - val_acc: 0.5962\n",
      "Epoch 28/32\n",
      "208/208 [==============================] - 0s 480us/step - loss: 0.2293 - acc: 0.9327 - val_loss: 1.0910 - val_acc: 0.6538\n",
      "Epoch 29/32\n",
      "208/208 [==============================] - 0s 479us/step - loss: 0.2063 - acc: 0.9471 - val_loss: 1.1939 - val_acc: 0.6154\n",
      "Epoch 30/32\n",
      "208/208 [==============================] - 0s 678us/step - loss: 0.2156 - acc: 0.9423 - val_loss: 1.2383 - val_acc: 0.6154\n",
      "Epoch 31/32\n",
      "208/208 [==============================] - 0s 502us/step - loss: 0.2953 - acc: 0.8942 - val_loss: 1.0942 - val_acc: 0.6923\n",
      "Epoch 32/32\n",
      "208/208 [==============================] - 0s 492us/step - loss: 0.2402 - acc: 0.9038 - val_loss: 1.0580 - val_acc: 0.6923\n",
      "Train on 208 samples, validate on 52 samples\n",
      "Epoch 1/33\n",
      "128/208 [=================>............] - ETA: 15s - loss: 3.3213 - acc: 0.0781"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rakibul/anaconda3/lib/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.230388). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "208/208 [==============================] - 27s 131ms/step - loss: 3.2605 - acc: 0.0962 - val_loss: 2.3147 - val_acc: 0.1154\n",
      "Epoch 2/33\n",
      "208/208 [==============================] - 0s 1ms/step - loss: 2.3406 - acc: 0.3029 - val_loss: 1.9256 - val_acc: 0.3269\n",
      "Epoch 3/33\n",
      "208/208 [==============================] - 0s 519us/step - loss: 1.7144 - acc: 0.3942 - val_loss: 1.6005 - val_acc: 0.5000\n",
      "Epoch 4/33\n",
      "208/208 [==============================] - 0s 516us/step - loss: 1.5453 - acc: 0.4279 - val_loss: 1.6269 - val_acc: 0.5385\n",
      "Epoch 5/33\n",
      "208/208 [==============================] - 3s 12ms/step - loss: 1.5589 - acc: 0.5096 - val_loss: 1.4701 - val_acc: 0.5000\n",
      "Epoch 6/33\n",
      "208/208 [==============================] - 0s 484us/step - loss: 1.1923 - acc: 0.5817 - val_loss: 1.5850 - val_acc: 0.4423\n",
      "Epoch 7/33\n",
      "208/208 [==============================] - 0s 488us/step - loss: 1.3101 - acc: 0.5577 - val_loss: 1.3253 - val_acc: 0.5769\n",
      "Epoch 8/33\n",
      "208/208 [==============================] - 0s 510us/step - loss: 0.9788 - acc: 0.6346 - val_loss: 1.2279 - val_acc: 0.5577\n",
      "Epoch 9/33\n",
      "208/208 [==============================] - 0s 497us/step - loss: 0.9346 - acc: 0.6875 - val_loss: 1.4580 - val_acc: 0.5962\n",
      "Epoch 10/33\n",
      "208/208 [==============================] - 0s 501us/step - loss: 0.8187 - acc: 0.7740 - val_loss: 1.0723 - val_acc: 0.6346\n",
      "Epoch 11/33\n",
      "208/208 [==============================] - 0s 529us/step - loss: 0.7353 - acc: 0.7596 - val_loss: 0.9954 - val_acc: 0.6731\n",
      "Epoch 12/33\n",
      "208/208 [==============================] - 0s 623us/step - loss: 0.7850 - acc: 0.7356 - val_loss: 1.0725 - val_acc: 0.5769\n",
      "Epoch 13/33\n",
      "208/208 [==============================] - 0s 783us/step - loss: 0.5560 - acc: 0.7933 - val_loss: 1.0624 - val_acc: 0.6731\n",
      "Epoch 14/33\n",
      "208/208 [==============================] - 0s 596us/step - loss: 0.5528 - acc: 0.8269 - val_loss: 1.0404 - val_acc: 0.6923\n",
      "Epoch 15/33\n",
      "208/208 [==============================] - 0s 515us/step - loss: 0.5593 - acc: 0.7885 - val_loss: 1.0953 - val_acc: 0.6923\n",
      "Epoch 16/33\n",
      "208/208 [==============================] - 0s 511us/step - loss: 0.5367 - acc: 0.8029 - val_loss: 1.0774 - val_acc: 0.6538\n",
      "Epoch 17/33\n",
      "208/208 [==============================] - 0s 520us/step - loss: 0.5675 - acc: 0.7885 - val_loss: 1.1222 - val_acc: 0.5577\n",
      "Epoch 18/33\n",
      "208/208 [==============================] - 0s 518us/step - loss: 0.4930 - acc: 0.8221 - val_loss: 0.9414 - val_acc: 0.7308\n",
      "Epoch 19/33\n",
      "208/208 [==============================] - 0s 512us/step - loss: 0.3706 - acc: 0.8798 - val_loss: 1.1944 - val_acc: 0.5769\n",
      "Epoch 20/33\n",
      "208/208 [==============================] - 0s 1ms/step - loss: 0.4193 - acc: 0.8654 - val_loss: 1.0358 - val_acc: 0.6731\n",
      "Epoch 21/33\n",
      "208/208 [==============================] - 0s 529us/step - loss: 0.3843 - acc: 0.8798 - val_loss: 1.0398 - val_acc: 0.6731\n",
      "Epoch 22/33\n",
      "208/208 [==============================] - 0s 506us/step - loss: 0.3499 - acc: 0.8846 - val_loss: 1.0967 - val_acc: 0.6538\n",
      "Epoch 23/33\n",
      "208/208 [==============================] - 0s 503us/step - loss: 0.3756 - acc: 0.8846 - val_loss: 1.0502 - val_acc: 0.6346\n",
      "Epoch 24/33\n",
      "208/208 [==============================] - 0s 1ms/step - loss: 0.3208 - acc: 0.9038 - val_loss: 1.0037 - val_acc: 0.6538\n",
      "Epoch 25/33\n",
      "208/208 [==============================] - 0s 495us/step - loss: 0.3328 - acc: 0.9135 - val_loss: 0.9661 - val_acc: 0.6731\n",
      "Epoch 26/33\n",
      "208/208 [==============================] - 0s 499us/step - loss: 0.2630 - acc: 0.9135 - val_loss: 1.0296 - val_acc: 0.6346\n",
      "Epoch 27/33\n",
      "208/208 [==============================] - 0s 515us/step - loss: 0.3162 - acc: 0.9038 - val_loss: 1.1386 - val_acc: 0.5385\n",
      "Epoch 28/33\n",
      "208/208 [==============================] - 0s 860us/step - loss: 0.2284 - acc: 0.9519 - val_loss: 1.0425 - val_acc: 0.6346\n",
      "Epoch 29/33\n",
      "208/208 [==============================] - 0s 555us/step - loss: 0.2003 - acc: 0.9375 - val_loss: 1.1107 - val_acc: 0.6346\n",
      "Epoch 30/33\n",
      "208/208 [==============================] - 0s 577us/step - loss: 0.2084 - acc: 0.9471 - val_loss: 1.1170 - val_acc: 0.5962\n",
      "Epoch 31/33\n",
      "208/208 [==============================] - 0s 507us/step - loss: 0.2852 - acc: 0.9135 - val_loss: 1.0340 - val_acc: 0.6923\n",
      "Epoch 32/33\n",
      "208/208 [==============================] - 0s 503us/step - loss: 0.2169 - acc: 0.9423 - val_loss: 1.0292 - val_acc: 0.7115\n",
      "Epoch 33/33\n",
      "208/208 [==============================] - 0s 530us/step - loss: 0.2252 - acc: 0.9231 - val_loss: 1.0604 - val_acc: 0.7115\n",
      "Train on 208 samples, validate on 52 samples\n",
      "Epoch 1/34\n",
      "208/208 [==============================] - 10s 50ms/step - loss: 3.2605 - acc: 0.0962 - val_loss: 2.3147 - val_acc: 0.1154\n",
      "Epoch 2/34\n",
      "208/208 [==============================] - 0s 501us/step - loss: 2.3406 - acc: 0.3029 - val_loss: 1.9256 - val_acc: 0.3269\n",
      "Epoch 3/34\n",
      "208/208 [==============================] - 0s 523us/step - loss: 1.7144 - acc: 0.3942 - val_loss: 1.6005 - val_acc: 0.5000\n",
      "Epoch 4/34\n",
      "208/208 [==============================] - 0s 608us/step - loss: 1.5453 - acc: 0.4279 - val_loss: 1.6269 - val_acc: 0.5385\n",
      "Epoch 5/34\n",
      "208/208 [==============================] - 0s 493us/step - loss: 1.5589 - acc: 0.5096 - val_loss: 1.4701 - val_acc: 0.5000\n",
      "Epoch 6/34\n",
      "208/208 [==============================] - 0s 673us/step - loss: 1.1923 - acc: 0.5817 - val_loss: 1.5850 - val_acc: 0.4423\n",
      "Epoch 7/34\n",
      "208/208 [==============================] - 0s 510us/step - loss: 1.3101 - acc: 0.5577 - val_loss: 1.3253 - val_acc: 0.5769\n",
      "Epoch 8/34\n",
      "208/208 [==============================] - 0s 493us/step - loss: 0.9788 - acc: 0.6346 - val_loss: 1.2279 - val_acc: 0.5577\n",
      "Epoch 9/34\n",
      "208/208 [==============================] - 0s 506us/step - loss: 0.9346 - acc: 0.6875 - val_loss: 1.4580 - val_acc: 0.5962\n",
      "Epoch 10/34\n",
      "208/208 [==============================] - 0s 496us/step - loss: 0.8187 - acc: 0.7740 - val_loss: 1.0723 - val_acc: 0.6346\n",
      "Epoch 11/34\n",
      "208/208 [==============================] - 0s 492us/step - loss: 0.7354 - acc: 0.7596 - val_loss: 0.9927 - val_acc: 0.6731\n",
      "Epoch 12/34\n",
      "208/208 [==============================] - 0s 574us/step - loss: 0.7755 - acc: 0.7452 - val_loss: 1.0653 - val_acc: 0.5962\n",
      "Epoch 13/34\n",
      "208/208 [==============================] - 0s 536us/step - loss: 0.5581 - acc: 0.8029 - val_loss: 1.0618 - val_acc: 0.6538\n",
      "Epoch 14/34\n",
      "208/208 [==============================] - 0s 496us/step - loss: 0.5532 - acc: 0.8365 - val_loss: 1.0320 - val_acc: 0.6923\n",
      "Epoch 15/34\n",
      "208/208 [==============================] - 0s 500us/step - loss: 0.5525 - acc: 0.7933 - val_loss: 1.0897 - val_acc: 0.6731\n",
      "Epoch 16/34\n",
      "208/208 [==============================] - 0s 576us/step - loss: 0.5233 - acc: 0.8125 - val_loss: 1.0699 - val_acc: 0.6731\n",
      "Epoch 17/34\n",
      "208/208 [==============================] - 0s 481us/step - loss: 0.5573 - acc: 0.8125 - val_loss: 1.1184 - val_acc: 0.5769\n",
      "Epoch 18/34\n",
      "208/208 [==============================] - 0s 499us/step - loss: 0.4818 - acc: 0.8462 - val_loss: 0.9372 - val_acc: 0.7115\n",
      "Epoch 19/34\n",
      "208/208 [==============================] - 0s 514us/step - loss: 0.3760 - acc: 0.8750 - val_loss: 1.1909 - val_acc: 0.5962\n",
      "Epoch 20/34\n",
      "208/208 [==============================] - 0s 487us/step - loss: 0.4120 - acc: 0.8654 - val_loss: 1.0081 - val_acc: 0.6731\n",
      "Epoch 21/34\n",
      "208/208 [==============================] - 0s 849us/step - loss: 0.3777 - acc: 0.8798 - val_loss: 1.0303 - val_acc: 0.6731\n",
      "Epoch 22/34\n",
      "208/208 [==============================] - 0s 580us/step - loss: 0.3644 - acc: 0.8750 - val_loss: 1.1129 - val_acc: 0.5962\n",
      "Epoch 23/34\n",
      "208/208 [==============================] - 0s 592us/step - loss: 0.3835 - acc: 0.8798 - val_loss: 1.0586 - val_acc: 0.6346\n",
      "Epoch 24/34\n",
      "208/208 [==============================] - 0s 517us/step - loss: 0.3287 - acc: 0.8846 - val_loss: 1.0279 - val_acc: 0.6346\n",
      "Epoch 25/34\n",
      "208/208 [==============================] - 0s 502us/step - loss: 0.3293 - acc: 0.8990 - val_loss: 0.9829 - val_acc: 0.6923\n",
      "Epoch 26/34\n",
      "208/208 [==============================] - 0s 494us/step - loss: 0.2554 - acc: 0.9087 - val_loss: 1.0415 - val_acc: 0.6731\n",
      "Epoch 27/34\n",
      "208/208 [==============================] - 0s 517us/step - loss: 0.3157 - acc: 0.8846 - val_loss: 1.1547 - val_acc: 0.5385\n",
      "Epoch 28/34\n",
      "208/208 [==============================] - 0s 520us/step - loss: 0.2257 - acc: 0.9423 - val_loss: 1.0787 - val_acc: 0.6346\n",
      "Epoch 29/34\n",
      "208/208 [==============================] - 0s 500us/step - loss: 0.2032 - acc: 0.9375 - val_loss: 1.1024 - val_acc: 0.6346\n",
      "Epoch 30/34\n",
      "208/208 [==============================] - 0s 530us/step - loss: 0.2095 - acc: 0.9471 - val_loss: 1.1174 - val_acc: 0.5769\n",
      "Epoch 31/34\n",
      "208/208 [==============================] - 0s 610us/step - loss: 0.2890 - acc: 0.9135 - val_loss: 1.0797 - val_acc: 0.6346\n",
      "Epoch 32/34\n",
      "208/208 [==============================] - 0s 504us/step - loss: 0.2182 - acc: 0.9375 - val_loss: 1.0290 - val_acc: 0.6923\n",
      "Epoch 33/34\n",
      "208/208 [==============================] - 0s 496us/step - loss: 0.2282 - acc: 0.9183 - val_loss: 1.0536 - val_acc: 0.6923\n",
      "Epoch 34/34\n",
      "208/208 [==============================] - 0s 481us/step - loss: 0.2543 - acc: 0.9135 - val_loss: 0.9844 - val_acc: 0.6923\n",
      "Train on 208 samples, validate on 52 samples\n",
      "Epoch 1/35\n",
      "208/208 [==============================] - 10s 48ms/step - loss: 3.2605 - acc: 0.0962 - val_loss: 2.3147 - val_acc: 0.1154\n",
      "Epoch 2/35\n",
      "208/208 [==============================] - 0s 496us/step - loss: 2.3406 - acc: 0.3029 - val_loss: 1.9256 - val_acc: 0.3269\n",
      "Epoch 3/35\n",
      "208/208 [==============================] - 0s 579us/step - loss: 1.7144 - acc: 0.3942 - val_loss: 1.6005 - val_acc: 0.5000\n",
      "Epoch 4/35\n",
      "208/208 [==============================] - 0s 566us/step - loss: 1.5453 - acc: 0.4279 - val_loss: 1.6269 - val_acc: 0.5385\n",
      "Epoch 5/35\n",
      "208/208 [==============================] - 0s 564us/step - loss: 1.5589 - acc: 0.5096 - val_loss: 1.4701 - val_acc: 0.5000\n",
      "Epoch 6/35\n",
      "208/208 [==============================] - 0s 561us/step - loss: 1.1923 - acc: 0.5817 - val_loss: 1.5850 - val_acc: 0.4423\n",
      "Epoch 7/35\n",
      "208/208 [==============================] - 0s 577us/step - loss: 1.3101 - acc: 0.5577 - val_loss: 1.3253 - val_acc: 0.5769\n",
      "Epoch 8/35\n",
      "208/208 [==============================] - 0s 579us/step - loss: 0.9788 - acc: 0.6346 - val_loss: 1.2279 - val_acc: 0.5577\n",
      "Epoch 9/35\n",
      "208/208 [==============================] - 0s 579us/step - loss: 0.9346 - acc: 0.6875 - val_loss: 1.4580 - val_acc: 0.5962\n",
      "Epoch 10/35\n",
      "208/208 [==============================] - 0s 573us/step - loss: 0.8187 - acc: 0.7740 - val_loss: 1.0723 - val_acc: 0.6346\n",
      "Epoch 11/35\n",
      "208/208 [==============================] - 0s 610us/step - loss: 0.7353 - acc: 0.7596 - val_loss: 0.9954 - val_acc: 0.6731\n",
      "Epoch 12/35\n",
      "208/208 [==============================] - 0s 571us/step - loss: 0.7850 - acc: 0.7356 - val_loss: 1.0725 - val_acc: 0.5769\n",
      "Epoch 13/35\n",
      "208/208 [==============================] - 0s 581us/step - loss: 0.5560 - acc: 0.7933 - val_loss: 1.0624 - val_acc: 0.6731\n",
      "Epoch 14/35\n",
      "208/208 [==============================] - 0s 572us/step - loss: 0.5528 - acc: 0.8269 - val_loss: 1.0404 - val_acc: 0.6923\n",
      "Epoch 15/35\n",
      "208/208 [==============================] - 0s 573us/step - loss: 0.5593 - acc: 0.7885 - val_loss: 1.0953 - val_acc: 0.6923\n",
      "Epoch 16/35\n",
      "208/208 [==============================] - 0s 558us/step - loss: 0.5367 - acc: 0.8029 - val_loss: 1.0774 - val_acc: 0.6538\n",
      "Epoch 17/35\n",
      "208/208 [==============================] - 0s 580us/step - loss: 0.5675 - acc: 0.7885 - val_loss: 1.1222 - val_acc: 0.5577\n",
      "Epoch 18/35\n",
      "208/208 [==============================] - 0s 571us/step - loss: 0.4930 - acc: 0.8221 - val_loss: 0.9414 - val_acc: 0.7308\n",
      "Epoch 19/35\n",
      "208/208 [==============================] - 0s 572us/step - loss: 0.3706 - acc: 0.8798 - val_loss: 1.1944 - val_acc: 0.5769\n",
      "Epoch 20/35\n",
      "208/208 [==============================] - 0s 586us/step - loss: 0.4193 - acc: 0.8654 - val_loss: 1.0358 - val_acc: 0.6731\n",
      "Epoch 21/35\n",
      "208/208 [==============================] - 0s 562us/step - loss: 0.3843 - acc: 0.8798 - val_loss: 1.0398 - val_acc: 0.6731\n",
      "Epoch 22/35\n",
      "208/208 [==============================] - 0s 629us/step - loss: 0.3499 - acc: 0.8846 - val_loss: 1.0967 - val_acc: 0.6538\n",
      "Epoch 23/35\n",
      "208/208 [==============================] - 0s 564us/step - loss: 0.3756 - acc: 0.8846 - val_loss: 1.0502 - val_acc: 0.6346\n",
      "Epoch 24/35\n",
      "208/208 [==============================] - 0s 564us/step - loss: 0.3208 - acc: 0.9038 - val_loss: 1.0037 - val_acc: 0.6538\n",
      "Epoch 25/35\n",
      "208/208 [==============================] - 0s 564us/step - loss: 0.3328 - acc: 0.9135 - val_loss: 0.9661 - val_acc: 0.6731\n",
      "Epoch 26/35\n",
      "208/208 [==============================] - 0s 554us/step - loss: 0.2630 - acc: 0.9135 - val_loss: 1.0296 - val_acc: 0.6346\n",
      "Epoch 27/35\n",
      "208/208 [==============================] - 0s 540us/step - loss: 0.3162 - acc: 0.9038 - val_loss: 1.1386 - val_acc: 0.5385\n",
      "Epoch 28/35\n",
      "208/208 [==============================] - 0s 586us/step - loss: 0.2284 - acc: 0.9519 - val_loss: 1.0425 - val_acc: 0.6346\n",
      "Epoch 29/35\n",
      "208/208 [==============================] - 0s 573us/step - loss: 0.2003 - acc: 0.9375 - val_loss: 1.1107 - val_acc: 0.6346\n",
      "Epoch 30/35\n",
      "208/208 [==============================] - 0s 581us/step - loss: 0.2084 - acc: 0.9471 - val_loss: 1.1170 - val_acc: 0.5962\n",
      "Epoch 31/35\n",
      "208/208 [==============================] - 0s 615us/step - loss: 0.2852 - acc: 0.9135 - val_loss: 1.0340 - val_acc: 0.6923\n",
      "Epoch 32/35\n",
      "208/208 [==============================] - 0s 606us/step - loss: 0.2169 - acc: 0.9423 - val_loss: 1.0292 - val_acc: 0.7115\n",
      "Epoch 33/35\n",
      "208/208 [==============================] - 0s 552us/step - loss: 0.2252 - acc: 0.9231 - val_loss: 1.0604 - val_acc: 0.7115\n",
      "Epoch 34/35\n",
      "208/208 [==============================] - 0s 585us/step - loss: 0.2510 - acc: 0.9135 - val_loss: 0.9785 - val_acc: 0.7115\n",
      "Epoch 35/35\n",
      "208/208 [==============================] - 0s 569us/step - loss: 0.2004 - acc: 0.9519 - val_loss: 0.9934 - val_acc: 0.6923\n",
      "Train on 208 samples, validate on 52 samples\n",
      "Epoch 1/36\n",
      "208/208 [==============================] - 10s 47ms/step - loss: 3.2605 - acc: 0.0962 - val_loss: 2.3147 - val_acc: 0.1154\n",
      "Epoch 2/36\n",
      "208/208 [==============================] - 0s 544us/step - loss: 2.3406 - acc: 0.3029 - val_loss: 1.9256 - val_acc: 0.3269\n",
      "Epoch 3/36\n",
      "208/208 [==============================] - 0s 593us/step - loss: 1.7144 - acc: 0.3942 - val_loss: 1.6005 - val_acc: 0.5000\n",
      "Epoch 4/36\n",
      "208/208 [==============================] - 0s 581us/step - loss: 1.5453 - acc: 0.4279 - val_loss: 1.6269 - val_acc: 0.5385\n",
      "Epoch 5/36\n",
      "208/208 [==============================] - 0s 571us/step - loss: 1.5589 - acc: 0.5096 - val_loss: 1.4701 - val_acc: 0.5000\n",
      "Epoch 6/36\n",
      "208/208 [==============================] - 0s 566us/step - loss: 1.1923 - acc: 0.5817 - val_loss: 1.5850 - val_acc: 0.4423\n",
      "Epoch 7/36\n",
      "208/208 [==============================] - 0s 570us/step - loss: 1.3101 - acc: 0.5577 - val_loss: 1.3253 - val_acc: 0.5769\n",
      "Epoch 8/36\n",
      "208/208 [==============================] - 0s 584us/step - loss: 0.9788 - acc: 0.6346 - val_loss: 1.2279 - val_acc: 0.5577\n",
      "Epoch 9/36\n",
      "208/208 [==============================] - 0s 580us/step - loss: 0.9346 - acc: 0.6875 - val_loss: 1.4580 - val_acc: 0.5962\n",
      "Epoch 10/36\n",
      "208/208 [==============================] - 0s 581us/step - loss: 0.8187 - acc: 0.7740 - val_loss: 1.0723 - val_acc: 0.6346\n",
      "Epoch 11/36\n",
      "208/208 [==============================] - 0s 604us/step - loss: 0.7353 - acc: 0.7596 - val_loss: 0.9954 - val_acc: 0.6731\n",
      "Epoch 12/36\n",
      "208/208 [==============================] - 0s 579us/step - loss: 0.7850 - acc: 0.7356 - val_loss: 1.0725 - val_acc: 0.5769\n",
      "Epoch 13/36\n",
      "208/208 [==============================] - 0s 558us/step - loss: 0.5560 - acc: 0.7933 - val_loss: 1.0624 - val_acc: 0.6731\n",
      "Epoch 14/36\n",
      "208/208 [==============================] - 0s 591us/step - loss: 0.5528 - acc: 0.8269 - val_loss: 1.0404 - val_acc: 0.6923\n",
      "Epoch 15/36\n",
      "208/208 [==============================] - 0s 605us/step - loss: 0.5593 - acc: 0.7885 - val_loss: 1.0953 - val_acc: 0.6923\n",
      "Epoch 16/36\n",
      "208/208 [==============================] - 0s 585us/step - loss: 0.5367 - acc: 0.8029 - val_loss: 1.0774 - val_acc: 0.6538\n",
      "Epoch 17/36\n",
      "208/208 [==============================] - 0s 566us/step - loss: 0.5675 - acc: 0.7885 - val_loss: 1.1222 - val_acc: 0.5577\n",
      "Epoch 18/36\n",
      "208/208 [==============================] - 0s 564us/step - loss: 0.4930 - acc: 0.8221 - val_loss: 0.9414 - val_acc: 0.7308\n",
      "Epoch 19/36\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "208/208 [==============================] - 0s 567us/step - loss: 0.3706 - acc: 0.8798 - val_loss: 1.1944 - val_acc: 0.5769\n",
      "Epoch 20/36\n",
      "208/208 [==============================] - 0s 590us/step - loss: 0.4193 - acc: 0.8654 - val_loss: 1.0358 - val_acc: 0.6731\n",
      "Epoch 21/36\n",
      "208/208 [==============================] - 0s 572us/step - loss: 0.3843 - acc: 0.8798 - val_loss: 1.0398 - val_acc: 0.6731\n",
      "Epoch 22/36\n",
      "208/208 [==============================] - 0s 564us/step - loss: 0.3499 - acc: 0.8846 - val_loss: 1.0967 - val_acc: 0.6538\n",
      "Epoch 23/36\n",
      "208/208 [==============================] - 0s 563us/step - loss: 0.3756 - acc: 0.8846 - val_loss: 1.0502 - val_acc: 0.6346\n",
      "Epoch 24/36\n",
      "208/208 [==============================] - 0s 574us/step - loss: 0.3208 - acc: 0.9038 - val_loss: 1.0037 - val_acc: 0.6538\n",
      "Epoch 25/36\n",
      "208/208 [==============================] - 0s 565us/step - loss: 0.3328 - acc: 0.9135 - val_loss: 0.9661 - val_acc: 0.6731\n",
      "Epoch 26/36\n",
      "208/208 [==============================] - 0s 571us/step - loss: 0.2630 - acc: 0.9135 - val_loss: 1.0296 - val_acc: 0.6346\n",
      "Epoch 27/36\n",
      "208/208 [==============================] - 0s 553us/step - loss: 0.3162 - acc: 0.9038 - val_loss: 1.1386 - val_acc: 0.5385\n",
      "Epoch 28/36\n",
      "208/208 [==============================] - 0s 572us/step - loss: 0.2284 - acc: 0.9519 - val_loss: 1.0425 - val_acc: 0.6346\n",
      "Epoch 29/36\n",
      "208/208 [==============================] - 0s 579us/step - loss: 0.2003 - acc: 0.9375 - val_loss: 1.1107 - val_acc: 0.6346\n",
      "Epoch 30/36\n",
      "208/208 [==============================] - 0s 579us/step - loss: 0.2084 - acc: 0.9471 - val_loss: 1.1170 - val_acc: 0.5962\n",
      "Epoch 31/36\n",
      "208/208 [==============================] - 0s 539us/step - loss: 0.2852 - acc: 0.9135 - val_loss: 1.0340 - val_acc: 0.6923\n",
      "Epoch 32/36\n",
      "208/208 [==============================] - 0s 513us/step - loss: 0.2169 - acc: 0.9423 - val_loss: 1.0292 - val_acc: 0.7115\n",
      "Epoch 33/36\n",
      "208/208 [==============================] - 0s 493us/step - loss: 0.2252 - acc: 0.9231 - val_loss: 1.0604 - val_acc: 0.7115\n",
      "Epoch 34/36\n",
      "208/208 [==============================] - 0s 507us/step - loss: 0.2510 - acc: 0.9135 - val_loss: 0.9785 - val_acc: 0.7115\n",
      "Epoch 35/36\n",
      "208/208 [==============================] - 0s 502us/step - loss: 0.2005 - acc: 0.9519 - val_loss: 0.9934 - val_acc: 0.6923\n",
      "Epoch 36/36\n",
      "208/208 [==============================] - 0s 497us/step - loss: 0.1707 - acc: 0.9471 - val_loss: 1.0380 - val_acc: 0.6923\n",
      "Train on 208 samples, validate on 52 samples\n",
      "Epoch 1/37\n",
      "208/208 [==============================] - 10s 48ms/step - loss: 3.2605 - acc: 0.0962 - val_loss: 2.3147 - val_acc: 0.1154\n",
      "Epoch 2/37\n",
      "208/208 [==============================] - 0s 560us/step - loss: 2.3406 - acc: 0.3029 - val_loss: 1.9256 - val_acc: 0.3269\n",
      "Epoch 3/37\n",
      "208/208 [==============================] - 0s 577us/step - loss: 1.7144 - acc: 0.3942 - val_loss: 1.6005 - val_acc: 0.5000\n",
      "Epoch 4/37\n",
      "208/208 [==============================] - 0s 544us/step - loss: 1.5453 - acc: 0.4279 - val_loss: 1.6269 - val_acc: 0.5385\n",
      "Epoch 5/37\n",
      "208/208 [==============================] - 0s 587us/step - loss: 1.5589 - acc: 0.5096 - val_loss: 1.4701 - val_acc: 0.5000\n",
      "Epoch 6/37\n",
      "208/208 [==============================] - 0s 564us/step - loss: 1.1923 - acc: 0.5817 - val_loss: 1.5850 - val_acc: 0.4423\n",
      "Epoch 7/37\n",
      "208/208 [==============================] - 0s 573us/step - loss: 1.3101 - acc: 0.5577 - val_loss: 1.3253 - val_acc: 0.5769\n",
      "Epoch 8/37\n",
      "208/208 [==============================] - 0s 501us/step - loss: 0.9788 - acc: 0.6346 - val_loss: 1.2279 - val_acc: 0.5577\n",
      "Epoch 9/37\n",
      "208/208 [==============================] - 0s 492us/step - loss: 0.9346 - acc: 0.6875 - val_loss: 1.4580 - val_acc: 0.5962\n",
      "Epoch 10/37\n",
      "208/208 [==============================] - 0s 622us/step - loss: 0.8187 - acc: 0.7740 - val_loss: 1.0723 - val_acc: 0.6346\n",
      "Epoch 11/37\n",
      "208/208 [==============================] - 0s 562us/step - loss: 0.7353 - acc: 0.7596 - val_loss: 0.9954 - val_acc: 0.6731\n",
      "Epoch 12/37\n",
      "208/208 [==============================] - 0s 560us/step - loss: 0.7850 - acc: 0.7356 - val_loss: 1.0718 - val_acc: 0.5962\n",
      "Epoch 13/37\n",
      "208/208 [==============================] - 0s 595us/step - loss: 0.5562 - acc: 0.7885 - val_loss: 1.0590 - val_acc: 0.6731\n",
      "Epoch 14/37\n",
      "208/208 [==============================] - 0s 563us/step - loss: 0.5537 - acc: 0.8317 - val_loss: 1.0425 - val_acc: 0.6923\n",
      "Epoch 15/37\n",
      "208/208 [==============================] - 0s 557us/step - loss: 0.5662 - acc: 0.7837 - val_loss: 1.1045 - val_acc: 0.6731\n",
      "Epoch 16/37\n",
      "208/208 [==============================] - 0s 633us/step - loss: 0.5277 - acc: 0.8221 - val_loss: 1.0771 - val_acc: 0.6538\n",
      "Epoch 17/37\n",
      "208/208 [==============================] - 0s 656us/step - loss: 0.5533 - acc: 0.7933 - val_loss: 1.1146 - val_acc: 0.5577\n",
      "Epoch 18/37\n",
      "208/208 [==============================] - 0s 594us/step - loss: 0.4923 - acc: 0.8317 - val_loss: 0.9510 - val_acc: 0.7115\n",
      "Epoch 19/37\n",
      "208/208 [==============================] - 0s 630us/step - loss: 0.3775 - acc: 0.8798 - val_loss: 1.2051 - val_acc: 0.5769\n",
      "Epoch 20/37\n",
      "208/208 [==============================] - 0s 634us/step - loss: 0.4161 - acc: 0.8558 - val_loss: 1.0270 - val_acc: 0.6731\n",
      "Epoch 21/37\n",
      "208/208 [==============================] - 0s 587us/step - loss: 0.3780 - acc: 0.8894 - val_loss: 1.0229 - val_acc: 0.6538\n",
      "Epoch 22/37\n",
      "208/208 [==============================] - 0s 624us/step - loss: 0.3570 - acc: 0.8942 - val_loss: 1.1090 - val_acc: 0.6154\n",
      "Epoch 23/37\n",
      "208/208 [==============================] - 0s 561us/step - loss: 0.3843 - acc: 0.8750 - val_loss: 1.0586 - val_acc: 0.6346\n",
      "Epoch 24/37\n",
      "208/208 [==============================] - 0s 592us/step - loss: 0.3192 - acc: 0.8894 - val_loss: 1.0271 - val_acc: 0.6538\n",
      "Epoch 25/37\n",
      "208/208 [==============================] - 0s 582us/step - loss: 0.3347 - acc: 0.8990 - val_loss: 0.9603 - val_acc: 0.6923\n",
      "Epoch 26/37\n",
      "208/208 [==============================] - 0s 545us/step - loss: 0.2634 - acc: 0.9183 - val_loss: 0.9988 - val_acc: 0.6538\n",
      "Epoch 27/37\n",
      "208/208 [==============================] - 0s 603us/step - loss: 0.3015 - acc: 0.8990 - val_loss: 1.1435 - val_acc: 0.5577\n",
      "Epoch 28/37\n",
      "208/208 [==============================] - 0s 825us/step - loss: 0.2270 - acc: 0.9471 - val_loss: 1.0353 - val_acc: 0.6346\n",
      "Epoch 29/37\n",
      "208/208 [==============================] - 0s 596us/step - loss: 0.1966 - acc: 0.9423 - val_loss: 1.1366 - val_acc: 0.6154\n",
      "Epoch 30/37\n",
      "208/208 [==============================] - 0s 516us/step - loss: 0.1920 - acc: 0.9663 - val_loss: 1.1156 - val_acc: 0.5962\n",
      "Epoch 31/37\n",
      "208/208 [==============================] - 0s 605us/step - loss: 0.2815 - acc: 0.9087 - val_loss: 1.0554 - val_acc: 0.7115\n",
      "Epoch 32/37\n",
      "208/208 [==============================] - 0s 574us/step - loss: 0.2214 - acc: 0.9231 - val_loss: 1.0234 - val_acc: 0.6731\n",
      "Epoch 33/37\n",
      "208/208 [==============================] - 0s 557us/step - loss: 0.2264 - acc: 0.9231 - val_loss: 1.0754 - val_acc: 0.6538\n",
      "Epoch 34/37\n",
      "208/208 [==============================] - 0s 817us/step - loss: 0.2502 - acc: 0.8990 - val_loss: 1.0065 - val_acc: 0.6731\n",
      "Epoch 35/37\n",
      "208/208 [==============================] - 0s 550us/step - loss: 0.2055 - acc: 0.9471 - val_loss: 0.9935 - val_acc: 0.7308\n",
      "Epoch 36/37\n",
      "208/208 [==============================] - 0s 612us/step - loss: 0.1612 - acc: 0.9663 - val_loss: 1.0405 - val_acc: 0.6731\n",
      "Epoch 37/37\n",
      "208/208 [==============================] - 0s 650us/step - loss: 0.1797 - acc: 0.9519 - val_loss: 1.0769 - val_acc: 0.6731\n",
      "Train on 208 samples, validate on 52 samples\n",
      "Epoch 1/38\n",
      "208/208 [==============================] - 10s 48ms/step - loss: 3.2605 - acc: 0.0962 - val_loss: 2.3147 - val_acc: 0.1154\n",
      "Epoch 2/38\n",
      "208/208 [==============================] - 0s 647us/step - loss: 2.3406 - acc: 0.3029 - val_loss: 1.9256 - val_acc: 0.3269\n",
      "Epoch 3/38\n",
      "208/208 [==============================] - 0s 656us/step - loss: 1.7144 - acc: 0.3942 - val_loss: 1.6005 - val_acc: 0.5000\n",
      "Epoch 4/38\n",
      "208/208 [==============================] - 0s 582us/step - loss: 1.5453 - acc: 0.4279 - val_loss: 1.6255 - val_acc: 0.5385\n",
      "Epoch 5/38\n",
      "208/208 [==============================] - 0s 656us/step - loss: 1.5699 - acc: 0.4952 - val_loss: 1.4690 - val_acc: 0.4808\n",
      "Epoch 6/38\n",
      "208/208 [==============================] - 0s 717us/step - loss: 1.1851 - acc: 0.5721 - val_loss: 1.5286 - val_acc: 0.4615\n",
      "Epoch 7/38\n",
      "208/208 [==============================] - 0s 639us/step - loss: 1.2728 - acc: 0.5288 - val_loss: 1.3361 - val_acc: 0.5577\n",
      "Epoch 8/38\n",
      "208/208 [==============================] - 0s 566us/step - loss: 0.9942 - acc: 0.6154 - val_loss: 1.2526 - val_acc: 0.5577\n",
      "Epoch 9/38\n",
      "208/208 [==============================] - 0s 598us/step - loss: 0.9319 - acc: 0.6875 - val_loss: 1.3588 - val_acc: 0.5962\n",
      "Epoch 10/38\n",
      "208/208 [==============================] - 0s 561us/step - loss: 0.7528 - acc: 0.7644 - val_loss: 1.0886 - val_acc: 0.5769\n",
      "Epoch 11/38\n",
      "208/208 [==============================] - 0s 603us/step - loss: 0.7632 - acc: 0.7644 - val_loss: 1.0119 - val_acc: 0.6731\n",
      "Epoch 12/38\n",
      "208/208 [==============================] - 0s 569us/step - loss: 0.7496 - acc: 0.7212 - val_loss: 1.0208 - val_acc: 0.6538\n",
      "Epoch 13/38\n",
      "208/208 [==============================] - 0s 600us/step - loss: 0.5705 - acc: 0.8269 - val_loss: 1.0149 - val_acc: 0.6923\n",
      "Epoch 14/38\n",
      "208/208 [==============================] - 0s 566us/step - loss: 0.5669 - acc: 0.8269 - val_loss: 1.0008 - val_acc: 0.6731\n",
      "Epoch 15/38\n",
      "208/208 [==============================] - 0s 601us/step - loss: 0.5547 - acc: 0.7933 - val_loss: 1.1382 - val_acc: 0.6346\n",
      "Epoch 16/38\n",
      "208/208 [==============================] - 0s 540us/step - loss: 0.5430 - acc: 0.8077 - val_loss: 1.0986 - val_acc: 0.6923\n",
      "Epoch 17/38\n",
      "208/208 [==============================] - 0s 618us/step - loss: 0.5691 - acc: 0.7837 - val_loss: 1.0981 - val_acc: 0.5962\n",
      "Epoch 18/38\n",
      "208/208 [==============================] - 0s 587us/step - loss: 0.4698 - acc: 0.8462 - val_loss: 0.9420 - val_acc: 0.7115\n",
      "Epoch 19/38\n",
      "208/208 [==============================] - 0s 620us/step - loss: 0.3568 - acc: 0.8942 - val_loss: 1.1896 - val_acc: 0.5962\n",
      "Epoch 20/38\n",
      "208/208 [==============================] - 0s 548us/step - loss: 0.3968 - acc: 0.8702 - val_loss: 1.0533 - val_acc: 0.6923\n",
      "Epoch 21/38\n",
      "208/208 [==============================] - 0s 600us/step - loss: 0.3537 - acc: 0.8846 - val_loss: 1.0994 - val_acc: 0.6538\n",
      "Epoch 22/38\n",
      "208/208 [==============================] - 0s 555us/step - loss: 0.3830 - acc: 0.8750 - val_loss: 1.0657 - val_acc: 0.6346\n",
      "Epoch 23/38\n",
      "208/208 [==============================] - 0s 595us/step - loss: 0.3834 - acc: 0.8846 - val_loss: 1.0484 - val_acc: 0.6731\n",
      "Epoch 24/38\n",
      "208/208 [==============================] - 0s 558us/step - loss: 0.3327 - acc: 0.9038 - val_loss: 1.0693 - val_acc: 0.5962\n",
      "Epoch 25/38\n",
      "208/208 [==============================] - 0s 635us/step - loss: 0.3243 - acc: 0.9038 - val_loss: 0.9887 - val_acc: 0.6923\n",
      "Epoch 26/38\n",
      "208/208 [==============================] - 0s 567us/step - loss: 0.2684 - acc: 0.9231 - val_loss: 1.0308 - val_acc: 0.6538\n",
      "Epoch 27/38\n",
      "208/208 [==============================] - 0s 613us/step - loss: 0.3140 - acc: 0.8942 - val_loss: 1.1358 - val_acc: 0.5962\n",
      "Epoch 28/38\n",
      "208/208 [==============================] - 0s 574us/step - loss: 0.2329 - acc: 0.9279 - val_loss: 1.0630 - val_acc: 0.6731\n",
      "Epoch 29/38\n",
      "208/208 [==============================] - 0s 597us/step - loss: 0.2057 - acc: 0.9471 - val_loss: 1.1100 - val_acc: 0.6346\n",
      "Epoch 30/38\n",
      "208/208 [==============================] - 0s 567us/step - loss: 0.2042 - acc: 0.9423 - val_loss: 1.1097 - val_acc: 0.6538\n",
      "Epoch 31/38\n",
      "208/208 [==============================] - 0s 615us/step - loss: 0.2703 - acc: 0.9135 - val_loss: 1.0717 - val_acc: 0.6731\n",
      "Epoch 32/38\n",
      "208/208 [==============================] - 0s 605us/step - loss: 0.2220 - acc: 0.9279 - val_loss: 1.0503 - val_acc: 0.6731\n",
      "Epoch 33/38\n",
      "208/208 [==============================] - 0s 618us/step - loss: 0.2252 - acc: 0.9183 - val_loss: 1.0855 - val_acc: 0.6538\n",
      "Epoch 34/38\n",
      "208/208 [==============================] - 0s 578us/step - loss: 0.2238 - acc: 0.9279 - val_loss: 0.9930 - val_acc: 0.6923\n",
      "Epoch 35/38\n",
      "208/208 [==============================] - 0s 614us/step - loss: 0.1895 - acc: 0.9567 - val_loss: 1.0328 - val_acc: 0.7115\n",
      "Epoch 36/38\n",
      "208/208 [==============================] - 0s 589us/step - loss: 0.1765 - acc: 0.9567 - val_loss: 1.0733 - val_acc: 0.6154\n",
      "Epoch 37/38\n",
      "208/208 [==============================] - 0s 595us/step - loss: 0.1848 - acc: 0.9567 - val_loss: 1.0769 - val_acc: 0.6731\n",
      "Epoch 38/38\n",
      "208/208 [==============================] - 0s 579us/step - loss: 0.1761 - acc: 0.9567 - val_loss: 1.0439 - val_acc: 0.7308\n",
      "Train on 208 samples, validate on 52 samples\n",
      "Epoch 1/39\n",
      "208/208 [==============================] - 12s 57ms/step - loss: 3.2605 - acc: 0.0962 - val_loss: 2.3147 - val_acc: 0.1154\n",
      "Epoch 2/39\n",
      "208/208 [==============================] - 0s 659us/step - loss: 2.3406 - acc: 0.3029 - val_loss: 1.9256 - val_acc: 0.3269\n",
      "Epoch 3/39\n",
      "208/208 [==============================] - 0s 681us/step - loss: 1.7144 - acc: 0.3942 - val_loss: 1.6005 - val_acc: 0.5000\n",
      "Epoch 4/39\n",
      "208/208 [==============================] - 0s 686us/step - loss: 1.5453 - acc: 0.4279 - val_loss: 1.6269 - val_acc: 0.5385\n",
      "Epoch 5/39\n",
      "208/208 [==============================] - 0s 618us/step - loss: 1.5589 - acc: 0.5096 - val_loss: 1.4701 - val_acc: 0.5000\n",
      "Epoch 6/39\n",
      "208/208 [==============================] - 0s 578us/step - loss: 1.1923 - acc: 0.5817 - val_loss: 1.5850 - val_acc: 0.4423\n",
      "Epoch 7/39\n",
      "208/208 [==============================] - 0s 684us/step - loss: 1.3101 - acc: 0.5577 - val_loss: 1.3253 - val_acc: 0.5769\n",
      "Epoch 8/39\n",
      "208/208 [==============================] - 0s 618us/step - loss: 0.9788 - acc: 0.6346 - val_loss: 1.2279 - val_acc: 0.5577\n",
      "Epoch 9/39\n",
      "208/208 [==============================] - 0s 686us/step - loss: 0.9346 - acc: 0.6875 - val_loss: 1.4580 - val_acc: 0.5962\n",
      "Epoch 10/39\n",
      "208/208 [==============================] - 0s 623us/step - loss: 0.8187 - acc: 0.7740 - val_loss: 1.0723 - val_acc: 0.6346\n",
      "Epoch 11/39\n",
      "208/208 [==============================] - 0s 846us/step - loss: 0.7353 - acc: 0.7596 - val_loss: 0.9954 - val_acc: 0.6731\n",
      "Epoch 12/39\n",
      "208/208 [==============================] - 0s 783us/step - loss: 0.7850 - acc: 0.7356 - val_loss: 1.0725 - val_acc: 0.5769\n",
      "Epoch 13/39\n",
      "208/208 [==============================] - 0s 707us/step - loss: 0.5554 - acc: 0.7933 - val_loss: 1.0614 - val_acc: 0.6731\n",
      "Epoch 14/39\n",
      "208/208 [==============================] - 0s 543us/step - loss: 0.5521 - acc: 0.8317 - val_loss: 1.0394 - val_acc: 0.6923\n",
      "Epoch 15/39\n",
      "208/208 [==============================] - 0s 653us/step - loss: 0.5600 - acc: 0.7885 - val_loss: 1.1057 - val_acc: 0.6731\n",
      "Epoch 16/39\n",
      "208/208 [==============================] - 0s 760us/step - loss: 0.5311 - acc: 0.8077 - val_loss: 1.0735 - val_acc: 0.6731\n",
      "Epoch 17/39\n",
      "208/208 [==============================] - 0s 615us/step - loss: 0.5611 - acc: 0.8125 - val_loss: 1.0954 - val_acc: 0.6154\n",
      "Epoch 18/39\n",
      "208/208 [==============================] - 0s 588us/step - loss: 0.4712 - acc: 0.8558 - val_loss: 0.9317 - val_acc: 0.7500\n",
      "Epoch 19/39\n",
      "208/208 [==============================] - 0s 648us/step - loss: 0.3755 - acc: 0.8846 - val_loss: 1.1700 - val_acc: 0.5769\n",
      "Epoch 20/39\n",
      "208/208 [==============================] - 0s 609us/step - loss: 0.4207 - acc: 0.8750 - val_loss: 1.0136 - val_acc: 0.6731\n",
      "Epoch 21/39\n",
      "208/208 [==============================] - 0s 639us/step - loss: 0.3849 - acc: 0.8894 - val_loss: 1.0426 - val_acc: 0.6538\n",
      "Epoch 22/39\n",
      "208/208 [==============================] - 0s 672us/step - loss: 0.3585 - acc: 0.8798 - val_loss: 1.1041 - val_acc: 0.6154\n",
      "Epoch 23/39\n",
      "208/208 [==============================] - 0s 612us/step - loss: 0.4046 - acc: 0.8606 - val_loss: 1.0419 - val_acc: 0.6538\n",
      "Epoch 24/39\n",
      "208/208 [==============================] - 0s 635us/step - loss: 0.3266 - acc: 0.8990 - val_loss: 1.0022 - val_acc: 0.6538\n",
      "Epoch 25/39\n",
      "208/208 [==============================] - 0s 638us/step - loss: 0.3303 - acc: 0.9087 - val_loss: 0.9586 - val_acc: 0.6923\n",
      "Epoch 26/39\n",
      "208/208 [==============================] - 0s 565us/step - loss: 0.2709 - acc: 0.9038 - val_loss: 1.0201 - val_acc: 0.6346\n",
      "Epoch 27/39\n",
      "208/208 [==============================] - 0s 594us/step - loss: 0.3086 - acc: 0.8990 - val_loss: 1.1114 - val_acc: 0.5769\n",
      "Epoch 28/39\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "208/208 [==============================] - 0s 603us/step - loss: 0.2248 - acc: 0.9519 - val_loss: 1.0324 - val_acc: 0.6538\n",
      "Epoch 29/39\n",
      "208/208 [==============================] - 0s 504us/step - loss: 0.1989 - acc: 0.9471 - val_loss: 1.0992 - val_acc: 0.6154\n",
      "Epoch 30/39\n",
      "208/208 [==============================] - 0s 509us/step - loss: 0.2145 - acc: 0.9471 - val_loss: 1.0913 - val_acc: 0.5962\n",
      "Epoch 31/39\n",
      "208/208 [==============================] - 0s 504us/step - loss: 0.2736 - acc: 0.9135 - val_loss: 1.0387 - val_acc: 0.6923\n",
      "Epoch 32/39\n",
      "208/208 [==============================] - 0s 482us/step - loss: 0.2148 - acc: 0.9375 - val_loss: 1.0143 - val_acc: 0.7115\n",
      "Epoch 33/39\n",
      "208/208 [==============================] - 0s 488us/step - loss: 0.2116 - acc: 0.9231 - val_loss: 1.0500 - val_acc: 0.7115\n",
      "Epoch 34/39\n",
      "208/208 [==============================] - 0s 519us/step - loss: 0.2452 - acc: 0.9183 - val_loss: 0.9490 - val_acc: 0.7115\n",
      "Epoch 35/39\n",
      "208/208 [==============================] - 0s 491us/step - loss: 0.1976 - acc: 0.9471 - val_loss: 0.9587 - val_acc: 0.7308\n",
      "Epoch 36/39\n",
      "208/208 [==============================] - 0s 510us/step - loss: 0.1639 - acc: 0.9567 - val_loss: 1.0089 - val_acc: 0.7115\n",
      "Epoch 37/39\n",
      "208/208 [==============================] - 0s 498us/step - loss: 0.1690 - acc: 0.9567 - val_loss: 1.0629 - val_acc: 0.6731\n",
      "Epoch 38/39\n",
      "208/208 [==============================] - 0s 510us/step - loss: 0.1789 - acc: 0.9423 - val_loss: 1.0004 - val_acc: 0.7308\n",
      "Epoch 39/39\n",
      "208/208 [==============================] - 0s 616us/step - loss: 0.1991 - acc: 0.9231 - val_loss: 1.0864 - val_acc: 0.6923\n",
      "Train on 208 samples, validate on 52 samples\n",
      "Epoch 1/40\n",
      "208/208 [==============================] - 11s 53ms/step - loss: 3.2605 - acc: 0.0962 - val_loss: 2.3147 - val_acc: 0.1154\n",
      "Epoch 2/40\n",
      "208/208 [==============================] - 0s 635us/step - loss: 2.3406 - acc: 0.3029 - val_loss: 1.9256 - val_acc: 0.3269\n",
      "Epoch 3/40\n",
      "208/208 [==============================] - 0s 564us/step - loss: 1.7144 - acc: 0.3942 - val_loss: 1.6005 - val_acc: 0.5000\n",
      "Epoch 4/40\n",
      "208/208 [==============================] - 0s 589us/step - loss: 1.5453 - acc: 0.4279 - val_loss: 1.6269 - val_acc: 0.5385\n",
      "Epoch 5/40\n",
      "208/208 [==============================] - 0s 558us/step - loss: 1.5589 - acc: 0.5096 - val_loss: 1.4701 - val_acc: 0.5000\n",
      "Epoch 6/40\n",
      "208/208 [==============================] - 0s 563us/step - loss: 1.1923 - acc: 0.5817 - val_loss: 1.5850 - val_acc: 0.4423\n",
      "Epoch 7/40\n",
      "208/208 [==============================] - 0s 587us/step - loss: 1.3101 - acc: 0.5577 - val_loss: 1.3253 - val_acc: 0.5769\n",
      "Epoch 8/40\n",
      "208/208 [==============================] - 0s 556us/step - loss: 0.9788 - acc: 0.6346 - val_loss: 1.2279 - val_acc: 0.5577\n",
      "Epoch 9/40\n",
      "208/208 [==============================] - 0s 564us/step - loss: 0.9346 - acc: 0.6875 - val_loss: 1.4580 - val_acc: 0.5962\n",
      "Epoch 10/40\n",
      "208/208 [==============================] - 0s 660us/step - loss: 0.8187 - acc: 0.7740 - val_loss: 1.0723 - val_acc: 0.6346\n",
      "Epoch 11/40\n",
      "208/208 [==============================] - 0s 587us/step - loss: 0.7353 - acc: 0.7596 - val_loss: 0.9954 - val_acc: 0.6731\n",
      "Epoch 12/40\n",
      "208/208 [==============================] - 0s 548us/step - loss: 0.7850 - acc: 0.7356 - val_loss: 1.0725 - val_acc: 0.5769\n",
      "Epoch 13/40\n",
      "208/208 [==============================] - 0s 508us/step - loss: 0.5560 - acc: 0.7933 - val_loss: 1.0624 - val_acc: 0.6731\n",
      "Epoch 14/40\n",
      "208/208 [==============================] - 0s 484us/step - loss: 0.5528 - acc: 0.8269 - val_loss: 1.0404 - val_acc: 0.6923\n",
      "Epoch 15/40\n",
      "208/208 [==============================] - 0s 483us/step - loss: 0.5593 - acc: 0.7885 - val_loss: 1.0953 - val_acc: 0.6923\n",
      "Epoch 16/40\n",
      "208/208 [==============================] - 0s 502us/step - loss: 0.5367 - acc: 0.8029 - val_loss: 1.0774 - val_acc: 0.6538\n",
      "Epoch 17/40\n",
      "208/208 [==============================] - 0s 504us/step - loss: 0.5675 - acc: 0.7885 - val_loss: 1.1222 - val_acc: 0.5577\n",
      "Epoch 18/40\n",
      "208/208 [==============================] - 0s 503us/step - loss: 0.4930 - acc: 0.8221 - val_loss: 0.9414 - val_acc: 0.7308\n",
      "Epoch 19/40\n",
      "208/208 [==============================] - 0s 505us/step - loss: 0.3706 - acc: 0.8798 - val_loss: 1.1944 - val_acc: 0.5769\n",
      "Epoch 20/40\n",
      "208/208 [==============================] - 0s 512us/step - loss: 0.4193 - acc: 0.8654 - val_loss: 1.0358 - val_acc: 0.6731\n",
      "Epoch 21/40\n",
      "208/208 [==============================] - 0s 525us/step - loss: 0.3843 - acc: 0.8798 - val_loss: 1.0398 - val_acc: 0.6731\n",
      "Epoch 22/40\n",
      "208/208 [==============================] - 0s 512us/step - loss: 0.3499 - acc: 0.8846 - val_loss: 1.0967 - val_acc: 0.6538\n",
      "Epoch 23/40\n",
      "208/208 [==============================] - 0s 518us/step - loss: 0.3756 - acc: 0.8846 - val_loss: 1.0502 - val_acc: 0.6346\n",
      "Epoch 24/40\n",
      "208/208 [==============================] - 0s 492us/step - loss: 0.3208 - acc: 0.9038 - val_loss: 1.0037 - val_acc: 0.6538\n",
      "Epoch 25/40\n",
      "208/208 [==============================] - 0s 509us/step - loss: 0.3328 - acc: 0.9135 - val_loss: 0.9661 - val_acc: 0.6731\n",
      "Epoch 26/40\n",
      "208/208 [==============================] - 0s 499us/step - loss: 0.2630 - acc: 0.9135 - val_loss: 1.0296 - val_acc: 0.6346\n",
      "Epoch 27/40\n",
      "208/208 [==============================] - 0s 516us/step - loss: 0.3162 - acc: 0.9038 - val_loss: 1.1386 - val_acc: 0.5385\n",
      "Epoch 28/40\n",
      "208/208 [==============================] - 0s 490us/step - loss: 0.2284 - acc: 0.9519 - val_loss: 1.0425 - val_acc: 0.6346\n",
      "Epoch 29/40\n",
      "208/208 [==============================] - 0s 509us/step - loss: 0.2003 - acc: 0.9375 - val_loss: 1.1107 - val_acc: 0.6346\n",
      "Epoch 30/40\n",
      "208/208 [==============================] - 0s 492us/step - loss: 0.2084 - acc: 0.9471 - val_loss: 1.1170 - val_acc: 0.5962\n",
      "Epoch 31/40\n",
      "208/208 [==============================] - 0s 522us/step - loss: 0.2852 - acc: 0.9135 - val_loss: 1.0340 - val_acc: 0.6923\n",
      "Epoch 32/40\n",
      "208/208 [==============================] - 0s 503us/step - loss: 0.2169 - acc: 0.9423 - val_loss: 1.0292 - val_acc: 0.7115\n",
      "Epoch 33/40\n",
      "208/208 [==============================] - 0s 517us/step - loss: 0.2252 - acc: 0.9231 - val_loss: 1.0604 - val_acc: 0.7115\n",
      "Epoch 34/40\n",
      "208/208 [==============================] - 0s 518us/step - loss: 0.2510 - acc: 0.9135 - val_loss: 0.9785 - val_acc: 0.7115\n",
      "Epoch 35/40\n",
      "208/208 [==============================] - 0s 507us/step - loss: 0.2005 - acc: 0.9519 - val_loss: 0.9934 - val_acc: 0.6923\n",
      "Epoch 36/40\n",
      "208/208 [==============================] - 0s 508us/step - loss: 0.1707 - acc: 0.9471 - val_loss: 1.0380 - val_acc: 0.6923\n",
      "Epoch 37/40\n",
      "208/208 [==============================] - 0s 513us/step - loss: 0.1786 - acc: 0.9567 - val_loss: 1.0664 - val_acc: 0.6731\n",
      "Epoch 38/40\n",
      "208/208 [==============================] - 0s 559us/step - loss: 0.1787 - acc: 0.9471 - val_loss: 1.0043 - val_acc: 0.6923\n",
      "Epoch 39/40\n",
      "208/208 [==============================] - 0s 505us/step - loss: 0.1833 - acc: 0.9327 - val_loss: 1.0840 - val_acc: 0.6923\n",
      "Epoch 40/40\n",
      "208/208 [==============================] - 0s 503us/step - loss: 0.1597 - acc: 0.9615 - val_loss: 1.1222 - val_acc: 0.6346\n",
      "Train on 208 samples, validate on 52 samples\n",
      "Epoch 1/41\n",
      "208/208 [==============================] - 11s 53ms/step - loss: 3.2605 - acc: 0.0962 - val_loss: 2.3147 - val_acc: 0.1154\n",
      "Epoch 2/41\n",
      "208/208 [==============================] - 0s 522us/step - loss: 2.3406 - acc: 0.3029 - val_loss: 1.9256 - val_acc: 0.3269\n",
      "Epoch 3/41\n",
      "208/208 [==============================] - 0s 522us/step - loss: 1.7144 - acc: 0.3942 - val_loss: 1.6005 - val_acc: 0.5000\n",
      "Epoch 4/41\n",
      "208/208 [==============================] - 0s 493us/step - loss: 1.5453 - acc: 0.4279 - val_loss: 1.6269 - val_acc: 0.5385\n",
      "Epoch 5/41\n",
      "208/208 [==============================] - 0s 480us/step - loss: 1.5589 - acc: 0.5096 - val_loss: 1.4701 - val_acc: 0.5000\n",
      "Epoch 6/41\n",
      "208/208 [==============================] - 0s 466us/step - loss: 1.1923 - acc: 0.5817 - val_loss: 1.5850 - val_acc: 0.4423\n",
      "Epoch 7/41\n",
      "208/208 [==============================] - 0s 492us/step - loss: 1.3101 - acc: 0.5577 - val_loss: 1.3253 - val_acc: 0.5769\n",
      "Epoch 8/41\n",
      "208/208 [==============================] - 0s 476us/step - loss: 0.9788 - acc: 0.6346 - val_loss: 1.2279 - val_acc: 0.5577\n",
      "Epoch 9/41\n",
      "208/208 [==============================] - 0s 477us/step - loss: 0.9346 - acc: 0.6875 - val_loss: 1.4580 - val_acc: 0.5962\n",
      "Epoch 10/41\n",
      "208/208 [==============================] - 0s 522us/step - loss: 0.8187 - acc: 0.7740 - val_loss: 1.0723 - val_acc: 0.6346\n",
      "Epoch 11/41\n",
      "208/208 [==============================] - 0s 506us/step - loss: 0.7353 - acc: 0.7596 - val_loss: 0.9954 - val_acc: 0.6731\n",
      "Epoch 12/41\n",
      "208/208 [==============================] - 0s 512us/step - loss: 0.7850 - acc: 0.7356 - val_loss: 1.0725 - val_acc: 0.5769\n",
      "Epoch 13/41\n",
      "208/208 [==============================] - 0s 505us/step - loss: 0.5560 - acc: 0.7933 - val_loss: 1.0624 - val_acc: 0.6731\n",
      "Epoch 14/41\n",
      "208/208 [==============================] - 0s 518us/step - loss: 0.5528 - acc: 0.8269 - val_loss: 1.0404 - val_acc: 0.6923\n",
      "Epoch 15/41\n",
      "208/208 [==============================] - 0s 565us/step - loss: 0.5593 - acc: 0.7885 - val_loss: 1.0953 - val_acc: 0.6923\n",
      "Epoch 16/41\n",
      "208/208 [==============================] - 0s 634us/step - loss: 0.5367 - acc: 0.8029 - val_loss: 1.0774 - val_acc: 0.6538\n",
      "Epoch 17/41\n",
      "208/208 [==============================] - 0s 662us/step - loss: 0.5675 - acc: 0.7885 - val_loss: 1.1222 - val_acc: 0.5577\n",
      "Epoch 18/41\n",
      "208/208 [==============================] - 0s 588us/step - loss: 0.4930 - acc: 0.8221 - val_loss: 0.9414 - val_acc: 0.7308\n",
      "Epoch 19/41\n",
      "208/208 [==============================] - 0s 673us/step - loss: 0.3706 - acc: 0.8798 - val_loss: 1.1944 - val_acc: 0.5769\n",
      "Epoch 20/41\n",
      "208/208 [==============================] - 0s 780us/step - loss: 0.4193 - acc: 0.8654 - val_loss: 1.0358 - val_acc: 0.6731\n",
      "Epoch 21/41\n",
      "208/208 [==============================] - 0s 588us/step - loss: 0.3843 - acc: 0.8798 - val_loss: 1.0398 - val_acc: 0.6731\n",
      "Epoch 22/41\n",
      "208/208 [==============================] - 0s 583us/step - loss: 0.3499 - acc: 0.8846 - val_loss: 1.0967 - val_acc: 0.6538\n",
      "Epoch 23/41\n",
      "208/208 [==============================] - 0s 594us/step - loss: 0.3756 - acc: 0.8846 - val_loss: 1.0502 - val_acc: 0.6346\n",
      "Epoch 24/41\n",
      "208/208 [==============================] - 0s 588us/step - loss: 0.3208 - acc: 0.9038 - val_loss: 1.0037 - val_acc: 0.6538\n",
      "Epoch 25/41\n",
      "208/208 [==============================] - 0s 654us/step - loss: 0.3328 - acc: 0.9135 - val_loss: 0.9661 - val_acc: 0.6731\n",
      "Epoch 26/41\n",
      "208/208 [==============================] - 0s 596us/step - loss: 0.2630 - acc: 0.9135 - val_loss: 1.0296 - val_acc: 0.6346\n",
      "Epoch 27/41\n",
      "208/208 [==============================] - 0s 613us/step - loss: 0.3162 - acc: 0.9038 - val_loss: 1.1386 - val_acc: 0.5385\n",
      "Epoch 28/41\n",
      "208/208 [==============================] - 0s 625us/step - loss: 0.2284 - acc: 0.9519 - val_loss: 1.0425 - val_acc: 0.6346\n",
      "Epoch 29/41\n",
      "208/208 [==============================] - 0s 644us/step - loss: 0.2003 - acc: 0.9375 - val_loss: 1.1107 - val_acc: 0.6346\n",
      "Epoch 30/41\n",
      "208/208 [==============================] - 0s 640us/step - loss: 0.2084 - acc: 0.9471 - val_loss: 1.1170 - val_acc: 0.5962\n",
      "Epoch 31/41\n",
      "208/208 [==============================] - 0s 722us/step - loss: 0.2852 - acc: 0.9135 - val_loss: 1.0340 - val_acc: 0.6923\n",
      "Epoch 32/41\n",
      "208/208 [==============================] - 0s 709us/step - loss: 0.2169 - acc: 0.9423 - val_loss: 1.0292 - val_acc: 0.7115\n",
      "Epoch 33/41\n",
      "208/208 [==============================] - 0s 778us/step - loss: 0.2252 - acc: 0.9231 - val_loss: 1.0604 - val_acc: 0.7115\n",
      "Epoch 34/41\n",
      "208/208 [==============================] - 0s 686us/step - loss: 0.2510 - acc: 0.9135 - val_loss: 0.9785 - val_acc: 0.7115\n",
      "Epoch 35/41\n",
      "208/208 [==============================] - 0s 862us/step - loss: 0.2005 - acc: 0.9519 - val_loss: 0.9934 - val_acc: 0.6923\n",
      "Epoch 36/41\n",
      "208/208 [==============================] - 0s 902us/step - loss: 0.1707 - acc: 0.9471 - val_loss: 1.0380 - val_acc: 0.6923\n",
      "Epoch 37/41\n",
      "208/208 [==============================] - 0s 883us/step - loss: 0.1786 - acc: 0.9567 - val_loss: 1.0664 - val_acc: 0.6731\n",
      "Epoch 38/41\n",
      "208/208 [==============================] - 0s 693us/step - loss: 0.1787 - acc: 0.9471 - val_loss: 1.0043 - val_acc: 0.6923\n",
      "Epoch 39/41\n",
      "208/208 [==============================] - 0s 666us/step - loss: 0.1833 - acc: 0.9327 - val_loss: 1.0840 - val_acc: 0.6923\n",
      "Epoch 40/41\n",
      "208/208 [==============================] - 0s 639us/step - loss: 0.1597 - acc: 0.9615 - val_loss: 1.1222 - val_acc: 0.6346\n",
      "Epoch 41/41\n",
      "208/208 [==============================] - 0s 680us/step - loss: 0.1421 - acc: 0.9663 - val_loss: 0.9937 - val_acc: 0.7308\n",
      "Train on 208 samples, validate on 52 samples\n",
      "Epoch 1/42\n",
      "208/208 [==============================] - 12s 57ms/step - loss: 3.2605 - acc: 0.0962 - val_loss: 2.3147 - val_acc: 0.1154\n",
      "Epoch 2/42\n",
      "208/208 [==============================] - 0s 921us/step - loss: 2.3406 - acc: 0.3029 - val_loss: 1.9256 - val_acc: 0.3269\n",
      "Epoch 3/42\n",
      "208/208 [==============================] - 0s 631us/step - loss: 1.7144 - acc: 0.3942 - val_loss: 1.6005 - val_acc: 0.5000\n",
      "Epoch 4/42\n",
      "208/208 [==============================] - 0s 649us/step - loss: 1.5453 - acc: 0.4279 - val_loss: 1.6269 - val_acc: 0.5385\n",
      "Epoch 5/42\n",
      "208/208 [==============================] - 0s 781us/step - loss: 1.5589 - acc: 0.5096 - val_loss: 1.4701 - val_acc: 0.5000\n",
      "Epoch 6/42\n",
      "208/208 [==============================] - 0s 805us/step - loss: 1.1923 - acc: 0.5817 - val_loss: 1.5850 - val_acc: 0.4423\n",
      "Epoch 7/42\n",
      "208/208 [==============================] - 0s 736us/step - loss: 1.3101 - acc: 0.5577 - val_loss: 1.3253 - val_acc: 0.5769\n",
      "Epoch 8/42\n",
      "208/208 [==============================] - 0s 879us/step - loss: 0.9788 - acc: 0.6346 - val_loss: 1.2279 - val_acc: 0.5577\n",
      "Epoch 9/42\n",
      "208/208 [==============================] - 0s 831us/step - loss: 0.9346 - acc: 0.6875 - val_loss: 1.4580 - val_acc: 0.5962\n",
      "Epoch 10/42\n",
      "208/208 [==============================] - 0s 796us/step - loss: 0.8187 - acc: 0.7740 - val_loss: 1.0723 - val_acc: 0.6346\n",
      "Epoch 11/42\n",
      "208/208 [==============================] - 0s 703us/step - loss: 0.7353 - acc: 0.7596 - val_loss: 0.9954 - val_acc: 0.6731\n",
      "Epoch 12/42\n",
      "208/208 [==============================] - 0s 691us/step - loss: 0.7850 - acc: 0.7356 - val_loss: 1.0725 - val_acc: 0.5769\n",
      "Epoch 13/42\n",
      "208/208 [==============================] - 0s 712us/step - loss: 0.5560 - acc: 0.7933 - val_loss: 1.0624 - val_acc: 0.6731\n",
      "Epoch 14/42\n",
      "208/208 [==============================] - 0s 897us/step - loss: 0.5528 - acc: 0.8269 - val_loss: 1.0409 - val_acc: 0.6923\n",
      "Epoch 15/42\n",
      "208/208 [==============================] - 0s 723us/step - loss: 0.5607 - acc: 0.7933 - val_loss: 1.0993 - val_acc: 0.6923\n",
      "Epoch 16/42\n",
      "208/208 [==============================] - 0s 675us/step - loss: 0.5362 - acc: 0.8029 - val_loss: 1.0706 - val_acc: 0.6538\n",
      "Epoch 17/42\n",
      "208/208 [==============================] - 0s 731us/step - loss: 0.5674 - acc: 0.7788 - val_loss: 1.1236 - val_acc: 0.5769\n",
      "Epoch 18/42\n",
      "208/208 [==============================] - 0s 689us/step - loss: 0.4926 - acc: 0.8317 - val_loss: 0.9414 - val_acc: 0.7308\n",
      "Epoch 19/42\n",
      "208/208 [==============================] - 0s 718us/step - loss: 0.3709 - acc: 0.8798 - val_loss: 1.1883 - val_acc: 0.5962\n",
      "Epoch 20/42\n",
      "208/208 [==============================] - 0s 734us/step - loss: 0.4103 - acc: 0.8606 - val_loss: 1.0288 - val_acc: 0.6731\n",
      "Epoch 21/42\n",
      "208/208 [==============================] - 0s 722us/step - loss: 0.3859 - acc: 0.8798 - val_loss: 1.0356 - val_acc: 0.6538\n",
      "Epoch 22/42\n",
      "208/208 [==============================] - 0s 739us/step - loss: 0.3509 - acc: 0.8846 - val_loss: 1.1045 - val_acc: 0.6346\n",
      "Epoch 23/42\n",
      "208/208 [==============================] - 0s 707us/step - loss: 0.3833 - acc: 0.8894 - val_loss: 1.0498 - val_acc: 0.6346\n",
      "Epoch 24/42\n",
      "208/208 [==============================] - 0s 717us/step - loss: 0.3252 - acc: 0.8990 - val_loss: 0.9989 - val_acc: 0.6346\n",
      "Epoch 25/42\n",
      "208/208 [==============================] - 0s 697us/step - loss: 0.3252 - acc: 0.9183 - val_loss: 0.9632 - val_acc: 0.6731\n",
      "Epoch 26/42\n",
      "208/208 [==============================] - 0s 682us/step - loss: 0.2674 - acc: 0.9135 - val_loss: 1.0444 - val_acc: 0.6346\n",
      "Epoch 27/42\n",
      "208/208 [==============================] - 0s 743us/step - loss: 0.3170 - acc: 0.8894 - val_loss: 1.1402 - val_acc: 0.5577\n",
      "Epoch 28/42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "208/208 [==============================] - 0s 715us/step - loss: 0.2219 - acc: 0.9519 - val_loss: 1.0237 - val_acc: 0.6538\n",
      "Epoch 29/42\n",
      "208/208 [==============================] - 0s 756us/step - loss: 0.1952 - acc: 0.9519 - val_loss: 1.0998 - val_acc: 0.6346\n",
      "Epoch 30/42\n",
      "208/208 [==============================] - 0s 697us/step - loss: 0.2035 - acc: 0.9519 - val_loss: 1.1179 - val_acc: 0.5962\n",
      "Epoch 31/42\n",
      "208/208 [==============================] - 0s 681us/step - loss: 0.2881 - acc: 0.9087 - val_loss: 1.0341 - val_acc: 0.7115\n",
      "Epoch 32/42\n",
      "208/208 [==============================] - 0s 668us/step - loss: 0.2242 - acc: 0.9279 - val_loss: 1.0228 - val_acc: 0.6923\n",
      "Epoch 33/42\n",
      "208/208 [==============================] - 0s 599us/step - loss: 0.2177 - acc: 0.9279 - val_loss: 1.0326 - val_acc: 0.6731\n",
      "Epoch 34/42\n",
      "208/208 [==============================] - 0s 621us/step - loss: 0.2349 - acc: 0.9183 - val_loss: 0.9690 - val_acc: 0.6731\n",
      "Epoch 35/42\n",
      "208/208 [==============================] - 0s 608us/step - loss: 0.2009 - acc: 0.9567 - val_loss: 0.9853 - val_acc: 0.7115\n",
      "Epoch 36/42\n",
      "208/208 [==============================] - 0s 615us/step - loss: 0.1781 - acc: 0.9519 - val_loss: 1.0262 - val_acc: 0.6731\n",
      "Epoch 37/42\n",
      "208/208 [==============================] - 0s 601us/step - loss: 0.1782 - acc: 0.9615 - val_loss: 1.0588 - val_acc: 0.6731\n",
      "Epoch 38/42\n",
      "208/208 [==============================] - 0s 613us/step - loss: 0.1728 - acc: 0.9375 - val_loss: 1.0078 - val_acc: 0.7115\n",
      "Epoch 39/42\n",
      "208/208 [==============================] - 0s 606us/step - loss: 0.1813 - acc: 0.9423 - val_loss: 1.0664 - val_acc: 0.6923\n",
      "Epoch 40/42\n",
      "208/208 [==============================] - 0s 597us/step - loss: 0.1590 - acc: 0.9519 - val_loss: 1.1322 - val_acc: 0.6346\n",
      "Epoch 41/42\n",
      "208/208 [==============================] - 0s 630us/step - loss: 0.1458 - acc: 0.9663 - val_loss: 0.9900 - val_acc: 0.7115\n",
      "Epoch 42/42\n",
      "208/208 [==============================] - 0s 626us/step - loss: 0.1095 - acc: 0.9904 - val_loss: 1.0414 - val_acc: 0.6923\n",
      "Train on 208 samples, validate on 52 samples\n",
      "Epoch 1/43\n",
      "208/208 [==============================] - 11s 52ms/step - loss: 3.2605 - acc: 0.0962 - val_loss: 2.3147 - val_acc: 0.1154\n",
      "Epoch 2/43\n",
      "208/208 [==============================] - 0s 624us/step - loss: 2.3406 - acc: 0.3029 - val_loss: 1.9256 - val_acc: 0.3269\n",
      "Epoch 3/43\n",
      "208/208 [==============================] - 0s 707us/step - loss: 1.7144 - acc: 0.3942 - val_loss: 1.6005 - val_acc: 0.5000\n",
      "Epoch 4/43\n",
      "208/208 [==============================] - 0s 725us/step - loss: 1.5453 - acc: 0.4279 - val_loss: 1.6269 - val_acc: 0.5385\n",
      "Epoch 5/43\n",
      "208/208 [==============================] - 0s 676us/step - loss: 1.5589 - acc: 0.5096 - val_loss: 1.4701 - val_acc: 0.5000\n",
      "Epoch 6/43\n",
      "208/208 [==============================] - 0s 700us/step - loss: 1.1923 - acc: 0.5817 - val_loss: 1.5850 - val_acc: 0.4423\n",
      "Epoch 7/43\n",
      "208/208 [==============================] - 0s 692us/step - loss: 1.3101 - acc: 0.5577 - val_loss: 1.3253 - val_acc: 0.5769\n",
      "Epoch 8/43\n",
      "208/208 [==============================] - 0s 653us/step - loss: 0.9788 - acc: 0.6346 - val_loss: 1.2279 - val_acc: 0.5577\n",
      "Epoch 9/43\n",
      "208/208 [==============================] - 0s 706us/step - loss: 0.9346 - acc: 0.6875 - val_loss: 1.4580 - val_acc: 0.5962\n",
      "Epoch 10/43\n",
      "208/208 [==============================] - 0s 700us/step - loss: 0.8187 - acc: 0.7740 - val_loss: 1.0723 - val_acc: 0.6346\n",
      "Epoch 11/43\n",
      "208/208 [==============================] - 0s 716us/step - loss: 0.7353 - acc: 0.7596 - val_loss: 0.9954 - val_acc: 0.6731\n",
      "Epoch 12/43\n",
      "208/208 [==============================] - 0s 696us/step - loss: 0.7850 - acc: 0.7356 - val_loss: 1.0725 - val_acc: 0.5769\n",
      "Epoch 13/43\n",
      "208/208 [==============================] - 0s 727us/step - loss: 0.5560 - acc: 0.7933 - val_loss: 1.0624 - val_acc: 0.6731\n",
      "Epoch 14/43\n",
      "208/208 [==============================] - 0s 712us/step - loss: 0.5528 - acc: 0.8269 - val_loss: 1.0404 - val_acc: 0.6923\n",
      "Epoch 15/43\n",
      "208/208 [==============================] - 0s 719us/step - loss: 0.5593 - acc: 0.7885 - val_loss: 1.0953 - val_acc: 0.6923\n",
      "Epoch 16/43\n",
      "208/208 [==============================] - 0s 710us/step - loss: 0.5367 - acc: 0.8029 - val_loss: 1.0774 - val_acc: 0.6538\n",
      "Epoch 17/43\n",
      "208/208 [==============================] - 0s 713us/step - loss: 0.5675 - acc: 0.7885 - val_loss: 1.1222 - val_acc: 0.5577\n",
      "Epoch 18/43\n",
      "208/208 [==============================] - 0s 632us/step - loss: 0.4930 - acc: 0.8221 - val_loss: 0.9414 - val_acc: 0.7308\n",
      "Epoch 19/43\n",
      "208/208 [==============================] - 0s 831us/step - loss: 0.3709 - acc: 0.8798 - val_loss: 1.1959 - val_acc: 0.5769\n",
      "Epoch 20/43\n",
      "208/208 [==============================] - 0s 775us/step - loss: 0.4204 - acc: 0.8654 - val_loss: 1.0374 - val_acc: 0.6731\n",
      "Epoch 21/43\n",
      "208/208 [==============================] - 0s 764us/step - loss: 0.3859 - acc: 0.8798 - val_loss: 1.0378 - val_acc: 0.6923\n",
      "Epoch 22/43\n",
      "208/208 [==============================] - 0s 745us/step - loss: 0.3502 - acc: 0.8894 - val_loss: 1.0900 - val_acc: 0.6538\n",
      "Epoch 23/43\n",
      "208/208 [==============================] - 0s 779us/step - loss: 0.3700 - acc: 0.8846 - val_loss: 1.0499 - val_acc: 0.6346\n",
      "Epoch 24/43\n",
      "208/208 [==============================] - 0s 725us/step - loss: 0.3228 - acc: 0.8990 - val_loss: 0.9905 - val_acc: 0.6538\n",
      "Epoch 25/43\n",
      "208/208 [==============================] - 0s 606us/step - loss: 0.3337 - acc: 0.9135 - val_loss: 0.9599 - val_acc: 0.6731\n",
      "Epoch 26/43\n",
      "208/208 [==============================] - 0s 759us/step - loss: 0.2648 - acc: 0.9135 - val_loss: 1.0327 - val_acc: 0.6346\n",
      "Epoch 27/43\n",
      "208/208 [==============================] - 0s 768us/step - loss: 0.3139 - acc: 0.8942 - val_loss: 1.1519 - val_acc: 0.5385\n",
      "Epoch 28/43\n",
      "208/208 [==============================] - 0s 662us/step - loss: 0.2310 - acc: 0.9423 - val_loss: 1.0428 - val_acc: 0.6346\n",
      "Epoch 29/43\n",
      "208/208 [==============================] - 0s 782us/step - loss: 0.2018 - acc: 0.9375 - val_loss: 1.1190 - val_acc: 0.6154\n",
      "Epoch 30/43\n",
      "208/208 [==============================] - 0s 725us/step - loss: 0.2071 - acc: 0.9471 - val_loss: 1.1202 - val_acc: 0.5962\n",
      "Epoch 31/43\n",
      "208/208 [==============================] - 0s 675us/step - loss: 0.2905 - acc: 0.9183 - val_loss: 1.0241 - val_acc: 0.7115\n",
      "Epoch 32/43\n",
      "208/208 [==============================] - 0s 761us/step - loss: 0.2144 - acc: 0.9423 - val_loss: 1.0148 - val_acc: 0.7115\n",
      "Epoch 33/43\n",
      "208/208 [==============================] - 0s 718us/step - loss: 0.2186 - acc: 0.9231 - val_loss: 1.0381 - val_acc: 0.7115\n",
      "Epoch 34/43\n",
      "208/208 [==============================] - 0s 686us/step - loss: 0.2481 - acc: 0.9135 - val_loss: 0.9702 - val_acc: 0.7115\n",
      "Epoch 35/43\n",
      "208/208 [==============================] - 0s 783us/step - loss: 0.1964 - acc: 0.9567 - val_loss: 0.9725 - val_acc: 0.6923\n",
      "Epoch 36/43\n",
      "208/208 [==============================] - 0s 547us/step - loss: 0.1798 - acc: 0.9375 - val_loss: 1.0352 - val_acc: 0.6923\n",
      "Epoch 37/43\n",
      "208/208 [==============================] - 0s 552us/step - loss: 0.1777 - acc: 0.9519 - val_loss: 1.0591 - val_acc: 0.6731\n",
      "Epoch 38/43\n",
      "208/208 [==============================] - 0s 768us/step - loss: 0.1831 - acc: 0.9375 - val_loss: 1.0144 - val_acc: 0.7308\n",
      "Epoch 39/43\n",
      "208/208 [==============================] - 0s 723us/step - loss: 0.1783 - acc: 0.9375 - val_loss: 1.0648 - val_acc: 0.6923\n",
      "Epoch 40/43\n",
      "208/208 [==============================] - 0s 718us/step - loss: 0.1567 - acc: 0.9615 - val_loss: 1.1274 - val_acc: 0.6346\n",
      "Epoch 41/43\n",
      "208/208 [==============================] - 0s 745us/step - loss: 0.1416 - acc: 0.9712 - val_loss: 0.9890 - val_acc: 0.7308\n",
      "Epoch 42/43\n",
      "208/208 [==============================] - 0s 688us/step - loss: 0.1082 - acc: 0.9808 - val_loss: 1.0481 - val_acc: 0.6923\n",
      "Epoch 43/43\n",
      "208/208 [==============================] - 0s 721us/step - loss: 0.1431 - acc: 0.9615 - val_loss: 0.9969 - val_acc: 0.7308\n",
      "Train on 208 samples, validate on 52 samples\n",
      "Epoch 1/44\n",
      "208/208 [==============================] - 11s 52ms/step - loss: 3.2605 - acc: 0.0962 - val_loss: 2.3147 - val_acc: 0.1154\n",
      "Epoch 2/44\n",
      "208/208 [==============================] - 0s 648us/step - loss: 2.3406 - acc: 0.3029 - val_loss: 1.9256 - val_acc: 0.3269\n",
      "Epoch 3/44\n",
      "208/208 [==============================] - 0s 640us/step - loss: 1.7144 - acc: 0.3942 - val_loss: 1.6005 - val_acc: 0.5000\n",
      "Epoch 4/44\n",
      "208/208 [==============================] - 0s 623us/step - loss: 1.5453 - acc: 0.4279 - val_loss: 1.6269 - val_acc: 0.5385\n",
      "Epoch 5/44\n",
      "208/208 [==============================] - 0s 599us/step - loss: 1.5589 - acc: 0.5096 - val_loss: 1.4701 - val_acc: 0.5000\n",
      "Epoch 6/44\n",
      "208/208 [==============================] - 0s 646us/step - loss: 1.1923 - acc: 0.5817 - val_loss: 1.5850 - val_acc: 0.4423\n",
      "Epoch 7/44\n",
      "208/208 [==============================] - 0s 618us/step - loss: 1.3101 - acc: 0.5577 - val_loss: 1.3253 - val_acc: 0.5769\n",
      "Epoch 8/44\n",
      "208/208 [==============================] - 0s 623us/step - loss: 0.9788 - acc: 0.6346 - val_loss: 1.2279 - val_acc: 0.5577\n",
      "Epoch 9/44\n",
      "208/208 [==============================] - 0s 624us/step - loss: 0.9346 - acc: 0.6875 - val_loss: 1.4580 - val_acc: 0.5962\n",
      "Epoch 10/44\n",
      "208/208 [==============================] - 0s 589us/step - loss: 0.8187 - acc: 0.7740 - val_loss: 1.0723 - val_acc: 0.6346\n",
      "Epoch 11/44\n",
      "208/208 [==============================] - 0s 604us/step - loss: 0.7353 - acc: 0.7596 - val_loss: 0.9954 - val_acc: 0.6731\n",
      "Epoch 12/44\n",
      "208/208 [==============================] - 0s 603us/step - loss: 0.7850 - acc: 0.7356 - val_loss: 1.0725 - val_acc: 0.5769\n",
      "Epoch 13/44\n",
      "208/208 [==============================] - 0s 575us/step - loss: 0.5560 - acc: 0.7933 - val_loss: 1.0624 - val_acc: 0.6731\n",
      "Epoch 14/44\n",
      "208/208 [==============================] - 0s 621us/step - loss: 0.5528 - acc: 0.8269 - val_loss: 1.0409 - val_acc: 0.6923\n",
      "Epoch 15/44\n",
      "208/208 [==============================] - 0s 615us/step - loss: 0.5607 - acc: 0.7933 - val_loss: 1.0993 - val_acc: 0.6923\n",
      "Epoch 16/44\n",
      "208/208 [==============================] - 0s 604us/step - loss: 0.5362 - acc: 0.8029 - val_loss: 1.0706 - val_acc: 0.6538\n",
      "Epoch 17/44\n",
      "208/208 [==============================] - 0s 555us/step - loss: 0.5674 - acc: 0.7788 - val_loss: 1.1236 - val_acc: 0.5769\n",
      "Epoch 18/44\n",
      "208/208 [==============================] - 0s 612us/step - loss: 0.4926 - acc: 0.8317 - val_loss: 0.9414 - val_acc: 0.7308\n",
      "Epoch 19/44\n",
      "208/208 [==============================] - 0s 618us/step - loss: 0.3709 - acc: 0.8798 - val_loss: 1.1883 - val_acc: 0.5962\n",
      "Epoch 20/44\n",
      "208/208 [==============================] - 0s 607us/step - loss: 0.4103 - acc: 0.8606 - val_loss: 1.0288 - val_acc: 0.6731\n",
      "Epoch 21/44\n",
      "208/208 [==============================] - 0s 644us/step - loss: 0.3859 - acc: 0.8798 - val_loss: 1.0356 - val_acc: 0.6538\n",
      "Epoch 22/44\n",
      "208/208 [==============================] - 0s 618us/step - loss: 0.3509 - acc: 0.8846 - val_loss: 1.1045 - val_acc: 0.6346\n",
      "Epoch 23/44\n",
      "208/208 [==============================] - 0s 616us/step - loss: 0.3833 - acc: 0.8894 - val_loss: 1.0498 - val_acc: 0.6346\n",
      "Epoch 24/44\n",
      "208/208 [==============================] - 0s 606us/step - loss: 0.3252 - acc: 0.8990 - val_loss: 0.9989 - val_acc: 0.6346\n",
      "Epoch 25/44\n",
      "208/208 [==============================] - 0s 839us/step - loss: 0.3252 - acc: 0.9183 - val_loss: 0.9632 - val_acc: 0.6731\n",
      "Epoch 26/44\n",
      "208/208 [==============================] - 0s 610us/step - loss: 0.2674 - acc: 0.9135 - val_loss: 1.0444 - val_acc: 0.6346\n",
      "Epoch 27/44\n",
      "208/208 [==============================] - 0s 567us/step - loss: 0.3170 - acc: 0.8894 - val_loss: 1.1402 - val_acc: 0.5577\n",
      "Epoch 28/44\n",
      "208/208 [==============================] - 0s 613us/step - loss: 0.2219 - acc: 0.9519 - val_loss: 1.0237 - val_acc: 0.6538\n",
      "Epoch 29/44\n",
      "208/208 [==============================] - 0s 562us/step - loss: 0.1952 - acc: 0.9519 - val_loss: 1.0998 - val_acc: 0.6346\n",
      "Epoch 30/44\n",
      "208/208 [==============================] - 0s 509us/step - loss: 0.2035 - acc: 0.9519 - val_loss: 1.1179 - val_acc: 0.5962\n",
      "Epoch 31/44\n",
      "208/208 [==============================] - 0s 518us/step - loss: 0.2881 - acc: 0.9087 - val_loss: 1.0341 - val_acc: 0.7115\n",
      "Epoch 32/44\n",
      "208/208 [==============================] - 0s 578us/step - loss: 0.2242 - acc: 0.9279 - val_loss: 1.0228 - val_acc: 0.6923\n",
      "Epoch 33/44\n",
      "208/208 [==============================] - 0s 560us/step - loss: 0.2177 - acc: 0.9279 - val_loss: 1.0326 - val_acc: 0.6731\n",
      "Epoch 34/44\n",
      "208/208 [==============================] - 0s 633us/step - loss: 0.2349 - acc: 0.9183 - val_loss: 0.9690 - val_acc: 0.6731\n",
      "Epoch 35/44\n",
      "208/208 [==============================] - 0s 584us/step - loss: 0.2009 - acc: 0.9567 - val_loss: 0.9853 - val_acc: 0.7115\n",
      "Epoch 36/44\n",
      "208/208 [==============================] - 0s 604us/step - loss: 0.1781 - acc: 0.9519 - val_loss: 1.0262 - val_acc: 0.6731\n",
      "Epoch 37/44\n",
      "208/208 [==============================] - 0s 583us/step - loss: 0.1782 - acc: 0.9615 - val_loss: 1.0588 - val_acc: 0.6731\n",
      "Epoch 38/44\n",
      "208/208 [==============================] - 0s 624us/step - loss: 0.1728 - acc: 0.9375 - val_loss: 1.0078 - val_acc: 0.7115\n",
      "Epoch 39/44\n",
      "208/208 [==============================] - 0s 567us/step - loss: 0.1814 - acc: 0.9375 - val_loss: 1.0687 - val_acc: 0.6923\n",
      "Epoch 40/44\n",
      "208/208 [==============================] - 0s 567us/step - loss: 0.1596 - acc: 0.9519 - val_loss: 1.1298 - val_acc: 0.6346\n",
      "Epoch 41/44\n",
      "208/208 [==============================] - 0s 546us/step - loss: 0.1464 - acc: 0.9663 - val_loss: 0.9940 - val_acc: 0.7308\n",
      "Epoch 42/44\n",
      "208/208 [==============================] - 0s 630us/step - loss: 0.1099 - acc: 0.9856 - val_loss: 1.0419 - val_acc: 0.6923\n",
      "Epoch 43/44\n",
      "208/208 [==============================] - 0s 532us/step - loss: 0.1346 - acc: 0.9615 - val_loss: 0.9901 - val_acc: 0.7500\n",
      "Epoch 44/44\n",
      "208/208 [==============================] - 0s 568us/step - loss: 0.1059 - acc: 0.9663 - val_loss: 1.0324 - val_acc: 0.7115\n",
      "Train on 208 samples, validate on 52 samples\n",
      "Epoch 1/45\n",
      "208/208 [==============================] - 11s 52ms/step - loss: 3.2605 - acc: 0.0962 - val_loss: 2.3147 - val_acc: 0.1154\n",
      "Epoch 2/45\n",
      "208/208 [==============================] - 0s 984us/step - loss: 2.3406 - acc: 0.3029 - val_loss: 1.9256 - val_acc: 0.3269\n",
      "Epoch 3/45\n",
      "208/208 [==============================] - 0s 610us/step - loss: 1.7144 - acc: 0.3942 - val_loss: 1.6005 - val_acc: 0.5000\n",
      "Epoch 4/45\n",
      "208/208 [==============================] - 0s 506us/step - loss: 1.5453 - acc: 0.4279 - val_loss: 1.6269 - val_acc: 0.5385\n",
      "Epoch 5/45\n",
      "208/208 [==============================] - 0s 616us/step - loss: 1.5589 - acc: 0.5096 - val_loss: 1.4701 - val_acc: 0.5000\n",
      "Epoch 6/45\n",
      "208/208 [==============================] - 0s 622us/step - loss: 1.1923 - acc: 0.5817 - val_loss: 1.5850 - val_acc: 0.4423\n",
      "Epoch 7/45\n",
      "208/208 [==============================] - 0s 606us/step - loss: 1.3101 - acc: 0.5577 - val_loss: 1.3253 - val_acc: 0.5769\n",
      "Epoch 8/45\n",
      "208/208 [==============================] - 0s 618us/step - loss: 0.9788 - acc: 0.6346 - val_loss: 1.2279 - val_acc: 0.5577\n",
      "Epoch 9/45\n",
      "208/208 [==============================] - 0s 672us/step - loss: 0.9347 - acc: 0.6875 - val_loss: 1.4551 - val_acc: 0.5962\n",
      "Epoch 10/45\n",
      "208/208 [==============================] - 0s 655us/step - loss: 0.8173 - acc: 0.7692 - val_loss: 1.0721 - val_acc: 0.6538\n",
      "Epoch 11/45\n",
      "208/208 [==============================] - 0s 591us/step - loss: 0.7338 - acc: 0.7644 - val_loss: 0.9995 - val_acc: 0.6731\n",
      "Epoch 12/45\n",
      "208/208 [==============================] - 0s 561us/step - loss: 0.7848 - acc: 0.7404 - val_loss: 1.0627 - val_acc: 0.6538\n",
      "Epoch 13/45\n",
      "208/208 [==============================] - 0s 533us/step - loss: 0.5478 - acc: 0.8029 - val_loss: 1.0549 - val_acc: 0.6923\n",
      "Epoch 14/45\n",
      "208/208 [==============================] - 0s 561us/step - loss: 0.5594 - acc: 0.8413 - val_loss: 1.0293 - val_acc: 0.6923\n",
      "Epoch 15/45\n",
      "208/208 [==============================] - 0s 626us/step - loss: 0.5741 - acc: 0.7837 - val_loss: 1.1345 - val_acc: 0.6731\n",
      "Epoch 16/45\n",
      "208/208 [==============================] - 0s 563us/step - loss: 0.5385 - acc: 0.8029 - val_loss: 1.0638 - val_acc: 0.6923\n",
      "Epoch 17/45\n",
      "208/208 [==============================] - 0s 523us/step - loss: 0.5599 - acc: 0.8029 - val_loss: 1.0489 - val_acc: 0.6154\n",
      "Epoch 18/45\n",
      "208/208 [==============================] - 0s 651us/step - loss: 0.4820 - acc: 0.8365 - val_loss: 0.9179 - val_acc: 0.7115\n",
      "Epoch 19/45\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "208/208 [==============================] - 0s 610us/step - loss: 0.3831 - acc: 0.8654 - val_loss: 1.2160 - val_acc: 0.5577\n",
      "Epoch 20/45\n",
      "208/208 [==============================] - 0s 579us/step - loss: 0.4140 - acc: 0.8654 - val_loss: 0.9824 - val_acc: 0.7115\n",
      "Epoch 21/45\n",
      "208/208 [==============================] - 0s 612us/step - loss: 0.3581 - acc: 0.8894 - val_loss: 0.9976 - val_acc: 0.6923\n",
      "Epoch 22/45\n",
      "208/208 [==============================] - 0s 634us/step - loss: 0.3448 - acc: 0.8798 - val_loss: 1.0837 - val_acc: 0.6731\n",
      "Epoch 23/45\n",
      "208/208 [==============================] - 0s 599us/step - loss: 0.3999 - acc: 0.8750 - val_loss: 1.0720 - val_acc: 0.6346\n",
      "Epoch 24/45\n",
      "208/208 [==============================] - 0s 595us/step - loss: 0.3250 - acc: 0.8990 - val_loss: 1.0285 - val_acc: 0.6154\n",
      "Epoch 25/45\n",
      "208/208 [==============================] - 0s 617us/step - loss: 0.3248 - acc: 0.8846 - val_loss: 0.9887 - val_acc: 0.6731\n",
      "Epoch 26/45\n",
      "208/208 [==============================] - 0s 614us/step - loss: 0.2638 - acc: 0.9038 - val_loss: 1.0640 - val_acc: 0.6346\n",
      "Epoch 27/45\n",
      "208/208 [==============================] - 0s 593us/step - loss: 0.3291 - acc: 0.8894 - val_loss: 1.1430 - val_acc: 0.5577\n",
      "Epoch 28/45\n",
      "208/208 [==============================] - 0s 624us/step - loss: 0.2221 - acc: 0.9471 - val_loss: 1.0702 - val_acc: 0.6346\n",
      "Epoch 29/45\n",
      "208/208 [==============================] - 0s 492us/step - loss: 0.1980 - acc: 0.9663 - val_loss: 1.0734 - val_acc: 0.6538\n",
      "Epoch 30/45\n",
      "208/208 [==============================] - 0s 623us/step - loss: 0.2071 - acc: 0.9471 - val_loss: 1.0994 - val_acc: 0.5962\n",
      "Epoch 31/45\n",
      "208/208 [==============================] - 0s 615us/step - loss: 0.2819 - acc: 0.9087 - val_loss: 1.0422 - val_acc: 0.7115\n",
      "Epoch 32/45\n",
      "208/208 [==============================] - 0s 600us/step - loss: 0.2193 - acc: 0.9423 - val_loss: 1.0333 - val_acc: 0.6923\n",
      "Epoch 33/45\n",
      "208/208 [==============================] - 0s 625us/step - loss: 0.2214 - acc: 0.9231 - val_loss: 1.0400 - val_acc: 0.6923\n",
      "Epoch 34/45\n",
      "208/208 [==============================] - 0s 624us/step - loss: 0.2503 - acc: 0.9087 - val_loss: 0.9757 - val_acc: 0.6923\n",
      "Epoch 35/45\n",
      "208/208 [==============================] - 0s 608us/step - loss: 0.1911 - acc: 0.9519 - val_loss: 0.9906 - val_acc: 0.7115\n",
      "Epoch 36/45\n",
      "208/208 [==============================] - 0s 512us/step - loss: 0.1766 - acc: 0.9471 - val_loss: 1.0309 - val_acc: 0.6731\n",
      "Epoch 37/45\n",
      "208/208 [==============================] - 0s 495us/step - loss: 0.1851 - acc: 0.9663 - val_loss: 1.0717 - val_acc: 0.6538\n",
      "Epoch 38/45\n",
      "208/208 [==============================] - 0s 646us/step - loss: 0.1751 - acc: 0.9519 - val_loss: 1.0157 - val_acc: 0.7115\n",
      "Epoch 39/45\n",
      "208/208 [==============================] - 0s 635us/step - loss: 0.1862 - acc: 0.9327 - val_loss: 1.0794 - val_acc: 0.6923\n",
      "Epoch 40/45\n",
      "208/208 [==============================] - 0s 664us/step - loss: 0.1578 - acc: 0.9519 - val_loss: 1.1585 - val_acc: 0.6346\n",
      "Epoch 41/45\n",
      "208/208 [==============================] - 0s 603us/step - loss: 0.1397 - acc: 0.9712 - val_loss: 0.9826 - val_acc: 0.7500\n",
      "Epoch 42/45\n",
      "208/208 [==============================] - 0s 622us/step - loss: 0.1088 - acc: 0.9904 - val_loss: 1.0603 - val_acc: 0.6923\n",
      "Epoch 43/45\n",
      "208/208 [==============================] - 0s 594us/step - loss: 0.1422 - acc: 0.9567 - val_loss: 1.0010 - val_acc: 0.7308\n",
      "Epoch 44/45\n",
      "208/208 [==============================] - 0s 574us/step - loss: 0.1012 - acc: 0.9760 - val_loss: 1.0578 - val_acc: 0.6923\n",
      "Epoch 45/45\n",
      "208/208 [==============================] - 0s 532us/step - loss: 0.1246 - acc: 0.9760 - val_loss: 0.9965 - val_acc: 0.7308\n",
      "Train on 208 samples, validate on 52 samples\n",
      "Epoch 1/46\n",
      "208/208 [==============================] - 11s 52ms/step - loss: 3.2605 - acc: 0.0962 - val_loss: 2.3147 - val_acc: 0.1154\n",
      "Epoch 2/46\n",
      "208/208 [==============================] - 0s 613us/step - loss: 2.3406 - acc: 0.3029 - val_loss: 1.9256 - val_acc: 0.3269\n",
      "Epoch 3/46\n",
      "208/208 [==============================] - 0s 584us/step - loss: 1.7144 - acc: 0.3942 - val_loss: 1.6005 - val_acc: 0.5000\n",
      "Epoch 4/46\n",
      "208/208 [==============================] - 0s 588us/step - loss: 1.5453 - acc: 0.4279 - val_loss: 1.6269 - val_acc: 0.5385\n",
      "Epoch 5/46\n",
      "208/208 [==============================] - 0s 582us/step - loss: 1.5589 - acc: 0.5096 - val_loss: 1.4701 - val_acc: 0.5000\n",
      "Epoch 6/46\n",
      "208/208 [==============================] - 0s 543us/step - loss: 1.1923 - acc: 0.5817 - val_loss: 1.5861 - val_acc: 0.4423\n",
      "Epoch 7/46\n",
      "208/208 [==============================] - 0s 582us/step - loss: 1.3219 - acc: 0.5481 - val_loss: 1.3187 - val_acc: 0.5769\n",
      "Epoch 8/46\n",
      "208/208 [==============================] - 0s 546us/step - loss: 0.9722 - acc: 0.6442 - val_loss: 1.2492 - val_acc: 0.5385\n",
      "Epoch 9/46\n",
      "208/208 [==============================] - 0s 564us/step - loss: 0.9624 - acc: 0.6779 - val_loss: 1.4877 - val_acc: 0.5577\n",
      "Epoch 10/46\n",
      "208/208 [==============================] - 0s 540us/step - loss: 0.8374 - acc: 0.7500 - val_loss: 1.0737 - val_acc: 0.6346\n",
      "Epoch 11/46\n",
      "208/208 [==============================] - 0s 502us/step - loss: 0.7549 - acc: 0.7500 - val_loss: 0.9990 - val_acc: 0.6923\n",
      "Epoch 12/46\n",
      "208/208 [==============================] - 0s 503us/step - loss: 0.7804 - acc: 0.7308 - val_loss: 0.9947 - val_acc: 0.7115\n",
      "Epoch 13/46\n",
      "208/208 [==============================] - 0s 510us/step - loss: 0.5599 - acc: 0.8125 - val_loss: 1.0137 - val_acc: 0.6923\n",
      "Epoch 14/46\n",
      "208/208 [==============================] - 0s 476us/step - loss: 0.5661 - acc: 0.8317 - val_loss: 1.0182 - val_acc: 0.6923\n",
      "Epoch 15/46\n",
      "208/208 [==============================] - 0s 490us/step - loss: 0.5660 - acc: 0.7981 - val_loss: 1.1379 - val_acc: 0.6731\n",
      "Epoch 16/46\n",
      "208/208 [==============================] - 0s 535us/step - loss: 0.5392 - acc: 0.8221 - val_loss: 1.0782 - val_acc: 0.6923\n",
      "Epoch 17/46\n",
      "208/208 [==============================] - 0s 551us/step - loss: 0.5663 - acc: 0.7981 - val_loss: 1.0799 - val_acc: 0.5962\n",
      "Epoch 18/46\n",
      "208/208 [==============================] - 0s 504us/step - loss: 0.4799 - acc: 0.8413 - val_loss: 0.9128 - val_acc: 0.7308\n",
      "Epoch 19/46\n",
      "208/208 [==============================] - 0s 490us/step - loss: 0.3651 - acc: 0.8750 - val_loss: 1.2440 - val_acc: 0.5577\n",
      "Epoch 20/46\n",
      "208/208 [==============================] - 0s 512us/step - loss: 0.4314 - acc: 0.8606 - val_loss: 1.0386 - val_acc: 0.6731\n",
      "Epoch 21/46\n",
      "208/208 [==============================] - 0s 510us/step - loss: 0.3738 - acc: 0.8846 - val_loss: 1.0485 - val_acc: 0.6731\n",
      "Epoch 22/46\n",
      "208/208 [==============================] - 0s 499us/step - loss: 0.3535 - acc: 0.8990 - val_loss: 1.0587 - val_acc: 0.6538\n",
      "Epoch 23/46\n",
      "208/208 [==============================] - 0s 490us/step - loss: 0.3583 - acc: 0.8990 - val_loss: 1.0349 - val_acc: 0.6731\n",
      "Epoch 24/46\n",
      "208/208 [==============================] - 0s 476us/step - loss: 0.3249 - acc: 0.8942 - val_loss: 1.0049 - val_acc: 0.6154\n",
      "Epoch 25/46\n",
      "208/208 [==============================] - 0s 504us/step - loss: 0.3351 - acc: 0.8894 - val_loss: 0.9501 - val_acc: 0.6923\n",
      "Epoch 26/46\n",
      "208/208 [==============================] - 0s 505us/step - loss: 0.2795 - acc: 0.9183 - val_loss: 1.0108 - val_acc: 0.6346\n",
      "Epoch 27/46\n",
      "208/208 [==============================] - 0s 477us/step - loss: 0.3165 - acc: 0.8750 - val_loss: 1.1702 - val_acc: 0.5962\n",
      "Epoch 28/46\n",
      "208/208 [==============================] - 0s 505us/step - loss: 0.2388 - acc: 0.9231 - val_loss: 1.0340 - val_acc: 0.6731\n",
      "Epoch 29/46\n",
      "208/208 [==============================] - 0s 498us/step - loss: 0.2249 - acc: 0.9375 - val_loss: 1.0799 - val_acc: 0.6346\n",
      "Epoch 30/46\n",
      "208/208 [==============================] - 0s 487us/step - loss: 0.2008 - acc: 0.9423 - val_loss: 1.1169 - val_acc: 0.5962\n",
      "Epoch 31/46\n",
      "208/208 [==============================] - 0s 498us/step - loss: 0.2796 - acc: 0.9135 - val_loss: 1.0602 - val_acc: 0.6923\n",
      "Epoch 32/46\n",
      "208/208 [==============================] - 0s 497us/step - loss: 0.2173 - acc: 0.9375 - val_loss: 1.0329 - val_acc: 0.6731\n",
      "Epoch 33/46\n",
      "208/208 [==============================] - 0s 496us/step - loss: 0.2135 - acc: 0.9327 - val_loss: 1.0381 - val_acc: 0.6923\n",
      "Epoch 34/46\n",
      "208/208 [==============================] - 0s 496us/step - loss: 0.2397 - acc: 0.9087 - val_loss: 1.0140 - val_acc: 0.6731\n",
      "Epoch 35/46\n",
      "208/208 [==============================] - 0s 519us/step - loss: 0.1958 - acc: 0.9471 - val_loss: 0.9910 - val_acc: 0.7115\n",
      "Epoch 36/46\n",
      "208/208 [==============================] - 0s 509us/step - loss: 0.1645 - acc: 0.9615 - val_loss: 1.0247 - val_acc: 0.6731\n",
      "Epoch 37/46\n",
      "208/208 [==============================] - 0s 513us/step - loss: 0.1878 - acc: 0.9375 - val_loss: 1.0315 - val_acc: 0.6923\n",
      "Epoch 38/46\n",
      "208/208 [==============================] - 0s 501us/step - loss: 0.1815 - acc: 0.9471 - val_loss: 0.9930 - val_acc: 0.7308\n",
      "Epoch 39/46\n",
      "208/208 [==============================] - 0s 482us/step - loss: 0.1704 - acc: 0.9423 - val_loss: 1.0995 - val_acc: 0.7115\n",
      "Epoch 40/46\n",
      "208/208 [==============================] - 0s 478us/step - loss: 0.1706 - acc: 0.9567 - val_loss: 1.1341 - val_acc: 0.6538\n",
      "Epoch 41/46\n",
      "208/208 [==============================] - 0s 495us/step - loss: 0.1480 - acc: 0.9760 - val_loss: 0.9797 - val_acc: 0.7308\n",
      "Epoch 42/46\n",
      "208/208 [==============================] - 0s 495us/step - loss: 0.1087 - acc: 0.9904 - val_loss: 1.0746 - val_acc: 0.6731\n",
      "Epoch 43/46\n",
      "208/208 [==============================] - 0s 501us/step - loss: 0.1515 - acc: 0.9615 - val_loss: 0.9933 - val_acc: 0.7308\n",
      "Epoch 44/46\n",
      "208/208 [==============================] - 0s 501us/step - loss: 0.1187 - acc: 0.9712 - val_loss: 1.0439 - val_acc: 0.7115\n",
      "Epoch 45/46\n",
      "208/208 [==============================] - 0s 532us/step - loss: 0.1169 - acc: 0.9808 - val_loss: 1.0082 - val_acc: 0.7500\n",
      "Epoch 46/46\n",
      "208/208 [==============================] - 0s 502us/step - loss: 0.1135 - acc: 0.9808 - val_loss: 1.0709 - val_acc: 0.7308\n",
      "Train on 208 samples, validate on 52 samples\n",
      "Epoch 1/47\n",
      "208/208 [==============================] - 11s 52ms/step - loss: 3.2605 - acc: 0.0962 - val_loss: 2.3147 - val_acc: 0.1154\n",
      "Epoch 2/47\n",
      "208/208 [==============================] - 0s 572us/step - loss: 2.3406 - acc: 0.3029 - val_loss: 1.9256 - val_acc: 0.3269\n",
      "Epoch 3/47\n",
      "208/208 [==============================] - 0s 571us/step - loss: 1.7144 - acc: 0.3942 - val_loss: 1.6005 - val_acc: 0.5000\n",
      "Epoch 4/47\n",
      "208/208 [==============================] - 0s 587us/step - loss: 1.5453 - acc: 0.4279 - val_loss: 1.6269 - val_acc: 0.5385\n",
      "Epoch 5/47\n",
      "208/208 [==============================] - 0s 579us/step - loss: 1.5589 - acc: 0.5096 - val_loss: 1.4701 - val_acc: 0.5000\n",
      "Epoch 6/47\n",
      "208/208 [==============================] - 0s 564us/step - loss: 1.1923 - acc: 0.5817 - val_loss: 1.5850 - val_acc: 0.4423\n",
      "Epoch 7/47\n",
      "208/208 [==============================] - 0s 596us/step - loss: 1.3101 - acc: 0.5577 - val_loss: 1.3253 - val_acc: 0.5769\n",
      "Epoch 8/47\n",
      "208/208 [==============================] - 0s 570us/step - loss: 0.9788 - acc: 0.6346 - val_loss: 1.2279 - val_acc: 0.5577\n",
      "Epoch 9/47\n",
      "208/208 [==============================] - 0s 579us/step - loss: 0.9346 - acc: 0.6875 - val_loss: 1.4580 - val_acc: 0.5962\n",
      "Epoch 10/47\n",
      "208/208 [==============================] - 0s 579us/step - loss: 0.8187 - acc: 0.7740 - val_loss: 1.0723 - val_acc: 0.6346\n",
      "Epoch 11/47\n",
      "208/208 [==============================] - 0s 566us/step - loss: 0.7353 - acc: 0.7596 - val_loss: 0.9954 - val_acc: 0.6731\n",
      "Epoch 12/47\n",
      "208/208 [==============================] - 0s 565us/step - loss: 0.7850 - acc: 0.7356 - val_loss: 1.0725 - val_acc: 0.5769\n",
      "Epoch 13/47\n",
      "208/208 [==============================] - 0s 567us/step - loss: 0.5560 - acc: 0.7933 - val_loss: 1.0624 - val_acc: 0.6731\n",
      "Epoch 14/47\n",
      "208/208 [==============================] - 0s 564us/step - loss: 0.5529 - acc: 0.8269 - val_loss: 1.0408 - val_acc: 0.6923\n",
      "Epoch 15/47\n",
      "208/208 [==============================] - 0s 591us/step - loss: 0.5603 - acc: 0.7933 - val_loss: 1.0985 - val_acc: 0.6923\n",
      "Epoch 16/47\n",
      "208/208 [==============================] - 0s 581us/step - loss: 0.5361 - acc: 0.8029 - val_loss: 1.0679 - val_acc: 0.6538\n",
      "Epoch 17/47\n",
      "208/208 [==============================] - 0s 583us/step - loss: 0.5668 - acc: 0.7837 - val_loss: 1.1237 - val_acc: 0.5577\n",
      "Epoch 18/47\n",
      "208/208 [==============================] - 0s 570us/step - loss: 0.4907 - acc: 0.8317 - val_loss: 0.9395 - val_acc: 0.7308\n",
      "Epoch 19/47\n",
      "208/208 [==============================] - 0s 580us/step - loss: 0.3719 - acc: 0.8798 - val_loss: 1.1862 - val_acc: 0.5962\n",
      "Epoch 20/47\n",
      "208/208 [==============================] - 0s 571us/step - loss: 0.4100 - acc: 0.8654 - val_loss: 1.0208 - val_acc: 0.6731\n",
      "Epoch 21/47\n",
      "208/208 [==============================] - 0s 579us/step - loss: 0.3812 - acc: 0.8846 - val_loss: 1.0302 - val_acc: 0.6538\n",
      "Epoch 22/47\n",
      "208/208 [==============================] - 0s 581us/step - loss: 0.3546 - acc: 0.8750 - val_loss: 1.0951 - val_acc: 0.6538\n",
      "Epoch 23/47\n",
      "208/208 [==============================] - 0s 555us/step - loss: 0.3885 - acc: 0.8798 - val_loss: 1.0732 - val_acc: 0.6346\n",
      "Epoch 24/47\n",
      "208/208 [==============================] - 0s 585us/step - loss: 0.3292 - acc: 0.8942 - val_loss: 1.0236 - val_acc: 0.6346\n",
      "Epoch 25/47\n",
      "208/208 [==============================] - 0s 567us/step - loss: 0.3349 - acc: 0.9038 - val_loss: 0.9737 - val_acc: 0.6923\n",
      "Epoch 26/47\n",
      "208/208 [==============================] - 0s 592us/step - loss: 0.2720 - acc: 0.9087 - val_loss: 1.0553 - val_acc: 0.6538\n",
      "Epoch 27/47\n",
      "208/208 [==============================] - 0s 554us/step - loss: 0.3136 - acc: 0.8990 - val_loss: 1.1312 - val_acc: 0.5385\n",
      "Epoch 28/47\n",
      "208/208 [==============================] - 0s 623us/step - loss: 0.2329 - acc: 0.9327 - val_loss: 1.0415 - val_acc: 0.6346\n",
      "Epoch 29/47\n",
      "208/208 [==============================] - 0s 603us/step - loss: 0.1998 - acc: 0.9519 - val_loss: 1.1039 - val_acc: 0.6538\n",
      "Epoch 30/47\n",
      "208/208 [==============================] - 0s 598us/step - loss: 0.1967 - acc: 0.9567 - val_loss: 1.1120 - val_acc: 0.6154\n",
      "Epoch 31/47\n",
      "208/208 [==============================] - 0s 602us/step - loss: 0.2814 - acc: 0.9183 - val_loss: 1.0436 - val_acc: 0.6731\n",
      "Epoch 32/47\n",
      "208/208 [==============================] - 0s 574us/step - loss: 0.2171 - acc: 0.9471 - val_loss: 1.0193 - val_acc: 0.6923\n",
      "Epoch 33/47\n",
      "208/208 [==============================] - 0s 577us/step - loss: 0.2199 - acc: 0.9279 - val_loss: 1.0580 - val_acc: 0.6538\n",
      "Epoch 34/47\n",
      "208/208 [==============================] - 0s 596us/step - loss: 0.2585 - acc: 0.9087 - val_loss: 0.9886 - val_acc: 0.6923\n",
      "Epoch 35/47\n",
      "208/208 [==============================] - 0s 607us/step - loss: 0.1948 - acc: 0.9615 - val_loss: 0.9996 - val_acc: 0.7115\n",
      "Epoch 36/47\n",
      "208/208 [==============================] - 0s 566us/step - loss: 0.1650 - acc: 0.9519 - val_loss: 1.0361 - val_acc: 0.6731\n",
      "Epoch 37/47\n",
      "208/208 [==============================] - 0s 571us/step - loss: 0.1739 - acc: 0.9615 - val_loss: 1.0737 - val_acc: 0.6731\n",
      "Epoch 38/47\n",
      "208/208 [==============================] - 0s 579us/step - loss: 0.1783 - acc: 0.9375 - val_loss: 1.0069 - val_acc: 0.7500\n",
      "Epoch 39/47\n",
      "208/208 [==============================] - 0s 581us/step - loss: 0.1865 - acc: 0.9279 - val_loss: 1.0680 - val_acc: 0.6923\n",
      "Epoch 40/47\n",
      "208/208 [==============================] - 0s 579us/step - loss: 0.1586 - acc: 0.9567 - val_loss: 1.1353 - val_acc: 0.6346\n",
      "Epoch 41/47\n",
      "208/208 [==============================] - 0s 615us/step - loss: 0.1509 - acc: 0.9712 - val_loss: 0.9822 - val_acc: 0.7500\n",
      "Epoch 42/47\n",
      "208/208 [==============================] - 0s 651us/step - loss: 0.1104 - acc: 0.9856 - val_loss: 1.0351 - val_acc: 0.6923\n",
      "Epoch 43/47\n",
      "208/208 [==============================] - 0s 718us/step - loss: 0.1380 - acc: 0.9615 - val_loss: 0.9828 - val_acc: 0.7500\n",
      "Epoch 44/47\n",
      "208/208 [==============================] - 0s 707us/step - loss: 0.1063 - acc: 0.9663 - val_loss: 1.0274 - val_acc: 0.7115\n",
      "Epoch 45/47\n",
      "208/208 [==============================] - 0s 732us/step - loss: 0.1276 - acc: 0.9663 - val_loss: 0.9651 - val_acc: 0.7500\n",
      "Epoch 46/47\n",
      "208/208 [==============================] - 0s 671us/step - loss: 0.1217 - acc: 0.9615 - val_loss: 1.0496 - val_acc: 0.6923\n",
      "Epoch 47/47\n",
      "208/208 [==============================] - 0s 706us/step - loss: 0.1058 - acc: 0.9760 - val_loss: 1.0242 - val_acc: 0.7308\n",
      "Train on 208 samples, validate on 52 samples\n",
      "Epoch 1/48\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "208/208 [==============================] - 11s 53ms/step - loss: 3.2605 - acc: 0.0962 - val_loss: 2.3147 - val_acc: 0.1154\n",
      "Epoch 2/48\n",
      "208/208 [==============================] - 0s 647us/step - loss: 2.3441 - acc: 0.2981 - val_loss: 1.9212 - val_acc: 0.3462\n",
      "Epoch 3/48\n",
      "208/208 [==============================] - 0s 577us/step - loss: 1.7272 - acc: 0.3990 - val_loss: 1.6247 - val_acc: 0.4615\n",
      "Epoch 4/48\n",
      "208/208 [==============================] - 0s 587us/step - loss: 1.5589 - acc: 0.4231 - val_loss: 1.6562 - val_acc: 0.5192\n",
      "Epoch 5/48\n",
      "208/208 [==============================] - 0s 611us/step - loss: 1.5899 - acc: 0.4808 - val_loss: 1.6591 - val_acc: 0.4038\n",
      "Epoch 6/48\n",
      "208/208 [==============================] - 0s 565us/step - loss: 1.2972 - acc: 0.5529 - val_loss: 1.5566 - val_acc: 0.4423\n",
      "Epoch 7/48\n",
      "208/208 [==============================] - 0s 634us/step - loss: 1.2514 - acc: 0.5721 - val_loss: 1.4993 - val_acc: 0.5385\n",
      "Epoch 8/48\n",
      "208/208 [==============================] - 0s 568us/step - loss: 1.0726 - acc: 0.6202 - val_loss: 1.2585 - val_acc: 0.5769\n",
      "Epoch 9/48\n",
      "208/208 [==============================] - 0s 611us/step - loss: 0.9344 - acc: 0.6923 - val_loss: 1.3242 - val_acc: 0.5962\n",
      "Epoch 10/48\n",
      "208/208 [==============================] - 0s 586us/step - loss: 0.7463 - acc: 0.7981 - val_loss: 1.0784 - val_acc: 0.6538\n",
      "Epoch 11/48\n",
      "208/208 [==============================] - 0s 636us/step - loss: 0.7461 - acc: 0.7548 - val_loss: 1.0268 - val_acc: 0.6538\n",
      "Epoch 12/48\n",
      "208/208 [==============================] - 0s 569us/step - loss: 0.7766 - acc: 0.7115 - val_loss: 1.0667 - val_acc: 0.6154\n",
      "Epoch 13/48\n",
      "208/208 [==============================] - 0s 615us/step - loss: 0.6038 - acc: 0.7981 - val_loss: 1.0750 - val_acc: 0.6538\n",
      "Epoch 14/48\n",
      "208/208 [==============================] - 0s 597us/step - loss: 0.5544 - acc: 0.8413 - val_loss: 1.0086 - val_acc: 0.6731\n",
      "Epoch 15/48\n",
      "208/208 [==============================] - 0s 615us/step - loss: 0.5596 - acc: 0.7981 - val_loss: 1.0921 - val_acc: 0.6346\n",
      "Epoch 16/48\n",
      "208/208 [==============================] - 0s 575us/step - loss: 0.5452 - acc: 0.7981 - val_loss: 1.0006 - val_acc: 0.6731\n",
      "Epoch 17/48\n",
      "208/208 [==============================] - 0s 622us/step - loss: 0.5313 - acc: 0.8029 - val_loss: 1.1286 - val_acc: 0.5577\n",
      "Epoch 18/48\n",
      "208/208 [==============================] - 0s 572us/step - loss: 0.5008 - acc: 0.8269 - val_loss: 0.9030 - val_acc: 0.7308\n",
      "Epoch 19/48\n",
      "208/208 [==============================] - 0s 608us/step - loss: 0.3692 - acc: 0.8654 - val_loss: 1.1827 - val_acc: 0.5962\n",
      "Epoch 20/48\n",
      "208/208 [==============================] - 0s 560us/step - loss: 0.4100 - acc: 0.8654 - val_loss: 0.9994 - val_acc: 0.6731\n",
      "Epoch 21/48\n",
      "208/208 [==============================] - 0s 612us/step - loss: 0.3910 - acc: 0.8942 - val_loss: 1.0095 - val_acc: 0.6731\n",
      "Epoch 22/48\n",
      "208/208 [==============================] - 0s 589us/step - loss: 0.3575 - acc: 0.8894 - val_loss: 1.0654 - val_acc: 0.6154\n",
      "Epoch 23/48\n",
      "208/208 [==============================] - 0s 628us/step - loss: 0.3834 - acc: 0.8654 - val_loss: 1.0279 - val_acc: 0.6346\n",
      "Epoch 24/48\n",
      "208/208 [==============================] - 0s 565us/step - loss: 0.3332 - acc: 0.8990 - val_loss: 0.9874 - val_acc: 0.6538\n",
      "Epoch 25/48\n",
      "208/208 [==============================] - 0s 601us/step - loss: 0.3435 - acc: 0.8894 - val_loss: 0.9526 - val_acc: 0.7115\n",
      "Epoch 26/48\n",
      "208/208 [==============================] - 0s 559us/step - loss: 0.2631 - acc: 0.9231 - val_loss: 1.0070 - val_acc: 0.6346\n",
      "Epoch 27/48\n",
      "208/208 [==============================] - 0s 584us/step - loss: 0.3165 - acc: 0.8894 - val_loss: 1.1084 - val_acc: 0.6346\n",
      "Epoch 28/48\n",
      "208/208 [==============================] - 0s 600us/step - loss: 0.2350 - acc: 0.9231 - val_loss: 1.0732 - val_acc: 0.6346\n",
      "Epoch 29/48\n",
      "208/208 [==============================] - 0s 674us/step - loss: 0.2085 - acc: 0.9471 - val_loss: 1.1655 - val_acc: 0.6154\n",
      "Epoch 30/48\n",
      "208/208 [==============================] - 0s 620us/step - loss: 0.2170 - acc: 0.9327 - val_loss: 1.1832 - val_acc: 0.5769\n",
      "Epoch 31/48\n",
      "208/208 [==============================] - 0s 634us/step - loss: 0.2988 - acc: 0.8942 - val_loss: 1.0909 - val_acc: 0.6731\n",
      "Epoch 32/48\n",
      "208/208 [==============================] - 0s 590us/step - loss: 0.2340 - acc: 0.9231 - val_loss: 1.0368 - val_acc: 0.6731\n",
      "Epoch 33/48\n",
      "208/208 [==============================] - 0s 649us/step - loss: 0.2290 - acc: 0.9279 - val_loss: 1.1229 - val_acc: 0.6538\n",
      "Epoch 34/48\n",
      "208/208 [==============================] - 0s 628us/step - loss: 0.2324 - acc: 0.9183 - val_loss: 1.0172 - val_acc: 0.6923\n",
      "Epoch 35/48\n",
      "208/208 [==============================] - 0s 629us/step - loss: 0.1953 - acc: 0.9567 - val_loss: 0.9955 - val_acc: 0.7115\n",
      "Epoch 36/48\n",
      "208/208 [==============================] - 0s 626us/step - loss: 0.1730 - acc: 0.9615 - val_loss: 1.0903 - val_acc: 0.6346\n",
      "Epoch 37/48\n",
      "208/208 [==============================] - 0s 602us/step - loss: 0.2037 - acc: 0.9375 - val_loss: 1.1015 - val_acc: 0.6731\n",
      "Epoch 38/48\n",
      "208/208 [==============================] - 0s 627us/step - loss: 0.1752 - acc: 0.9471 - val_loss: 1.0425 - val_acc: 0.7115\n",
      "Epoch 39/48\n",
      "208/208 [==============================] - 0s 603us/step - loss: 0.1955 - acc: 0.9375 - val_loss: 1.1556 - val_acc: 0.6923\n",
      "Epoch 40/48\n",
      "208/208 [==============================] - 0s 585us/step - loss: 0.1596 - acc: 0.9519 - val_loss: 1.2011 - val_acc: 0.6346\n",
      "Epoch 41/48\n",
      "208/208 [==============================] - 0s 662us/step - loss: 0.1508 - acc: 0.9615 - val_loss: 1.0179 - val_acc: 0.7115\n",
      "Epoch 42/48\n",
      "208/208 [==============================] - 0s 704us/step - loss: 0.1023 - acc: 0.9904 - val_loss: 1.0613 - val_acc: 0.6923\n",
      "Epoch 43/48\n",
      "208/208 [==============================] - 0s 759us/step - loss: 0.1450 - acc: 0.9663 - val_loss: 1.0084 - val_acc: 0.7115\n",
      "Epoch 44/48\n",
      "208/208 [==============================] - 0s 623us/step - loss: 0.0997 - acc: 0.9663 - val_loss: 1.0661 - val_acc: 0.6923\n",
      "Epoch 45/48\n",
      "208/208 [==============================] - 0s 589us/step - loss: 0.1200 - acc: 0.9760 - val_loss: 1.0040 - val_acc: 0.7115\n",
      "Epoch 46/48\n",
      "208/208 [==============================] - 0s 634us/step - loss: 0.1136 - acc: 0.9712 - val_loss: 1.0652 - val_acc: 0.7115\n",
      "Epoch 47/48\n",
      "208/208 [==============================] - 0s 577us/step - loss: 0.1061 - acc: 0.9712 - val_loss: 1.0257 - val_acc: 0.7308\n",
      "Epoch 48/48\n",
      "208/208 [==============================] - 0s 636us/step - loss: 0.1127 - acc: 0.9615 - val_loss: 1.0488 - val_acc: 0.7115\n",
      "Train on 208 samples, validate on 52 samples\n",
      "Epoch 1/49\n",
      "208/208 [==============================] - 11s 54ms/step - loss: 3.2605 - acc: 0.0962 - val_loss: 2.3147 - val_acc: 0.1154\n",
      "Epoch 2/49\n",
      "208/208 [==============================] - 0s 662us/step - loss: 2.3406 - acc: 0.3029 - val_loss: 1.9153 - val_acc: 0.3269\n",
      "Epoch 3/49\n",
      "208/208 [==============================] - 0s 709us/step - loss: 1.7166 - acc: 0.3894 - val_loss: 1.6255 - val_acc: 0.4808\n",
      "Epoch 4/49\n",
      "208/208 [==============================] - 0s 602us/step - loss: 1.5497 - acc: 0.4279 - val_loss: 1.6066 - val_acc: 0.5769\n",
      "Epoch 5/49\n",
      "208/208 [==============================] - 0s 613us/step - loss: 1.5778 - acc: 0.5288 - val_loss: 1.5619 - val_acc: 0.4808\n",
      "Epoch 6/49\n",
      "208/208 [==============================] - 0s 633us/step - loss: 1.2419 - acc: 0.5577 - val_loss: 1.5282 - val_acc: 0.4615\n",
      "Epoch 7/49\n",
      "208/208 [==============================] - 0s 637us/step - loss: 1.2892 - acc: 0.5577 - val_loss: 1.3572 - val_acc: 0.5962\n",
      "Epoch 8/49\n",
      "208/208 [==============================] - 0s 650us/step - loss: 1.0215 - acc: 0.6250 - val_loss: 1.2697 - val_acc: 0.5385\n",
      "Epoch 9/49\n",
      "208/208 [==============================] - 0s 695us/step - loss: 0.9090 - acc: 0.6971 - val_loss: 1.4225 - val_acc: 0.5577\n",
      "Epoch 10/49\n",
      "208/208 [==============================] - 0s 721us/step - loss: 0.8035 - acc: 0.7452 - val_loss: 1.0446 - val_acc: 0.6731\n",
      "Epoch 11/49\n",
      "208/208 [==============================] - 0s 710us/step - loss: 0.7521 - acc: 0.7788 - val_loss: 0.9675 - val_acc: 0.7308\n",
      "Epoch 12/49\n",
      "208/208 [==============================] - 0s 660us/step - loss: 0.7486 - acc: 0.7356 - val_loss: 0.9851 - val_acc: 0.6923\n",
      "Epoch 13/49\n",
      "208/208 [==============================] - 0s 664us/step - loss: 0.5683 - acc: 0.8029 - val_loss: 1.0165 - val_acc: 0.6923\n",
      "Epoch 14/49\n",
      "208/208 [==============================] - 0s 648us/step - loss: 0.5521 - acc: 0.8413 - val_loss: 1.0215 - val_acc: 0.7115\n",
      "Epoch 15/49\n",
      "208/208 [==============================] - 0s 555us/step - loss: 0.5627 - acc: 0.8029 - val_loss: 1.0824 - val_acc: 0.6731\n",
      "Epoch 16/49\n",
      "208/208 [==============================] - 0s 664us/step - loss: 0.5240 - acc: 0.8173 - val_loss: 1.0146 - val_acc: 0.6923\n",
      "Epoch 17/49\n",
      "208/208 [==============================] - 0s 658us/step - loss: 0.5584 - acc: 0.8077 - val_loss: 1.0933 - val_acc: 0.5577\n",
      "Epoch 18/49\n",
      "208/208 [==============================] - 0s 641us/step - loss: 0.4820 - acc: 0.8221 - val_loss: 0.9359 - val_acc: 0.7115\n",
      "Epoch 19/49\n",
      "208/208 [==============================] - 0s 572us/step - loss: 0.3531 - acc: 0.9038 - val_loss: 1.2361 - val_acc: 0.5962\n",
      "Epoch 20/49\n",
      "208/208 [==============================] - 0s 666us/step - loss: 0.4479 - acc: 0.8317 - val_loss: 1.1432 - val_acc: 0.6538\n",
      "Epoch 21/49\n",
      "208/208 [==============================] - 1s 4ms/step - loss: 0.4930 - acc: 0.8606 - val_loss: 1.1294 - val_acc: 0.5962\n",
      "Epoch 22/49\n",
      "208/208 [==============================] - 0s 638us/step - loss: 0.3602 - acc: 0.8846 - val_loss: 1.0820 - val_acc: 0.6346\n",
      "Epoch 23/49\n",
      "208/208 [==============================] - 0s 594us/step - loss: 0.3835 - acc: 0.8654 - val_loss: 1.0614 - val_acc: 0.6154\n",
      "Epoch 24/49\n",
      "208/208 [==============================] - 0s 641us/step - loss: 0.3401 - acc: 0.8894 - val_loss: 1.0142 - val_acc: 0.6731\n",
      "Epoch 25/49\n",
      "208/208 [==============================] - 0s 591us/step - loss: 0.3244 - acc: 0.9087 - val_loss: 0.9447 - val_acc: 0.6923\n",
      "Epoch 26/49\n",
      "208/208 [==============================] - 0s 560us/step - loss: 0.2425 - acc: 0.9375 - val_loss: 1.0349 - val_acc: 0.6538\n",
      "Epoch 27/49\n",
      "208/208 [==============================] - 0s 617us/step - loss: 0.3104 - acc: 0.8942 - val_loss: 1.1429 - val_acc: 0.5577\n",
      "Epoch 28/49\n",
      "208/208 [==============================] - 0s 573us/step - loss: 0.2205 - acc: 0.9519 - val_loss: 1.0479 - val_acc: 0.6731\n",
      "Epoch 29/49\n",
      "208/208 [==============================] - 0s 689us/step - loss: 0.1891 - acc: 0.9567 - val_loss: 1.1267 - val_acc: 0.6346\n",
      "Epoch 30/49\n",
      "208/208 [==============================] - 0s 653us/step - loss: 0.2013 - acc: 0.9471 - val_loss: 1.1386 - val_acc: 0.6154\n",
      "Epoch 31/49\n",
      "208/208 [==============================] - 0s 658us/step - loss: 0.2859 - acc: 0.9087 - val_loss: 1.0805 - val_acc: 0.6538\n",
      "Epoch 32/49\n",
      "208/208 [==============================] - 0s 645us/step - loss: 0.2229 - acc: 0.9231 - val_loss: 1.0101 - val_acc: 0.6731\n",
      "Epoch 33/49\n",
      "208/208 [==============================] - 0s 649us/step - loss: 0.2271 - acc: 0.9327 - val_loss: 1.0346 - val_acc: 0.7308\n",
      "Epoch 34/49\n",
      "208/208 [==============================] - 0s 683us/step - loss: 0.2460 - acc: 0.9183 - val_loss: 1.0069 - val_acc: 0.6923\n",
      "Epoch 35/49\n",
      "208/208 [==============================] - 0s 628us/step - loss: 0.1888 - acc: 0.9615 - val_loss: 1.0032 - val_acc: 0.7500\n",
      "Epoch 36/49\n",
      "208/208 [==============================] - 0s 661us/step - loss: 0.1755 - acc: 0.9519 - val_loss: 1.0599 - val_acc: 0.6923\n",
      "Epoch 37/49\n",
      "208/208 [==============================] - 0s 635us/step - loss: 0.1941 - acc: 0.9471 - val_loss: 1.0812 - val_acc: 0.7115\n",
      "Epoch 38/49\n",
      "208/208 [==============================] - 0s 649us/step - loss: 0.1704 - acc: 0.9327 - val_loss: 1.0314 - val_acc: 0.7115\n",
      "Epoch 39/49\n",
      "208/208 [==============================] - 0s 590us/step - loss: 0.1896 - acc: 0.9279 - val_loss: 1.1280 - val_acc: 0.7115\n",
      "Epoch 40/49\n",
      "208/208 [==============================] - 0s 630us/step - loss: 0.1593 - acc: 0.9567 - val_loss: 1.1287 - val_acc: 0.6731\n",
      "Epoch 41/49\n",
      "208/208 [==============================] - 0s 638us/step - loss: 0.1264 - acc: 0.9760 - val_loss: 1.0113 - val_acc: 0.7308\n",
      "Epoch 42/49\n",
      "208/208 [==============================] - 0s 595us/step - loss: 0.1098 - acc: 0.9760 - val_loss: 1.0724 - val_acc: 0.7115\n",
      "Epoch 43/49\n",
      "208/208 [==============================] - 0s 629us/step - loss: 0.1346 - acc: 0.9567 - val_loss: 1.0302 - val_acc: 0.7308\n",
      "Epoch 44/49\n",
      "208/208 [==============================] - 0s 598us/step - loss: 0.0966 - acc: 0.9760 - val_loss: 1.0773 - val_acc: 0.7115\n",
      "Epoch 45/49\n",
      "208/208 [==============================] - 0s 618us/step - loss: 0.1260 - acc: 0.9712 - val_loss: 1.0313 - val_acc: 0.7308\n",
      "Epoch 46/49\n",
      "208/208 [==============================] - 0s 661us/step - loss: 0.1161 - acc: 0.9519 - val_loss: 1.1027 - val_acc: 0.7308\n",
      "Epoch 47/49\n",
      "208/208 [==============================] - 0s 573us/step - loss: 0.1006 - acc: 0.9760 - val_loss: 1.0553 - val_acc: 0.7500\n",
      "Epoch 48/49\n",
      "208/208 [==============================] - 0s 604us/step - loss: 0.1213 - acc: 0.9567 - val_loss: 1.0408 - val_acc: 0.7308\n",
      "Epoch 49/49\n",
      "208/208 [==============================] - 0s 567us/step - loss: 0.1118 - acc: 0.9760 - val_loss: 1.1187 - val_acc: 0.6731\n",
      "Train on 208 samples, validate on 52 samples\n",
      "Epoch 1/50\n",
      "208/208 [==============================] - 11s 53ms/step - loss: 3.2605 - acc: 0.0962 - val_loss: 2.3147 - val_acc: 0.1154\n",
      "Epoch 2/50\n",
      "208/208 [==============================] - 0s 578us/step - loss: 2.3406 - acc: 0.3029 - val_loss: 1.9256 - val_acc: 0.3269\n",
      "Epoch 3/50\n",
      "208/208 [==============================] - 0s 584us/step - loss: 1.7144 - acc: 0.3942 - val_loss: 1.6005 - val_acc: 0.5000\n",
      "Epoch 4/50\n",
      "208/208 [==============================] - 0s 586us/step - loss: 1.5453 - acc: 0.4279 - val_loss: 1.6269 - val_acc: 0.5385\n",
      "Epoch 5/50\n",
      "208/208 [==============================] - 0s 597us/step - loss: 1.5589 - acc: 0.5096 - val_loss: 1.4701 - val_acc: 0.5000\n",
      "Epoch 6/50\n",
      "208/208 [==============================] - 0s 564us/step - loss: 1.1923 - acc: 0.5817 - val_loss: 1.5850 - val_acc: 0.4423\n",
      "Epoch 7/50\n",
      "208/208 [==============================] - 0s 564us/step - loss: 1.3101 - acc: 0.5577 - val_loss: 1.3253 - val_acc: 0.5769\n",
      "Epoch 8/50\n",
      "208/208 [==============================] - 0s 582us/step - loss: 0.9788 - acc: 0.6346 - val_loss: 1.2279 - val_acc: 0.5577\n",
      "Epoch 9/50\n",
      "208/208 [==============================] - 0s 573us/step - loss: 0.9346 - acc: 0.6875 - val_loss: 1.4580 - val_acc: 0.5962\n",
      "Epoch 10/50\n",
      "208/208 [==============================] - 0s 563us/step - loss: 0.8187 - acc: 0.7740 - val_loss: 1.0723 - val_acc: 0.6346\n",
      "Epoch 11/50\n",
      "208/208 [==============================] - 0s 562us/step - loss: 0.7353 - acc: 0.7596 - val_loss: 0.9954 - val_acc: 0.6731\n",
      "Epoch 12/50\n",
      "208/208 [==============================] - 0s 620us/step - loss: 0.7850 - acc: 0.7356 - val_loss: 1.0725 - val_acc: 0.5769\n",
      "Epoch 13/50\n",
      "208/208 [==============================] - 0s 595us/step - loss: 0.5560 - acc: 0.7933 - val_loss: 1.0624 - val_acc: 0.6731\n",
      "Epoch 14/50\n",
      "208/208 [==============================] - 0s 552us/step - loss: 0.5528 - acc: 0.8269 - val_loss: 1.0404 - val_acc: 0.6923\n",
      "Epoch 15/50\n",
      "208/208 [==============================] - 0s 578us/step - loss: 0.5593 - acc: 0.7885 - val_loss: 1.0953 - val_acc: 0.6923\n",
      "Epoch 16/50\n",
      "208/208 [==============================] - 0s 580us/step - loss: 0.5367 - acc: 0.8029 - val_loss: 1.0774 - val_acc: 0.6538\n",
      "Epoch 17/50\n",
      "208/208 [==============================] - 0s 568us/step - loss: 0.5675 - acc: 0.7885 - val_loss: 1.1222 - val_acc: 0.5577\n",
      "Epoch 18/50\n",
      "208/208 [==============================] - 0s 547us/step - loss: 0.4930 - acc: 0.8221 - val_loss: 0.9414 - val_acc: 0.7308\n",
      "Epoch 19/50\n",
      "208/208 [==============================] - 0s 610us/step - loss: 0.3706 - acc: 0.8798 - val_loss: 1.1944 - val_acc: 0.5769\n",
      "Epoch 20/50\n",
      "208/208 [==============================] - 0s 579us/step - loss: 0.4193 - acc: 0.8654 - val_loss: 1.0358 - val_acc: 0.6731\n",
      "Epoch 21/50\n",
      "208/208 [==============================] - 0s 574us/step - loss: 0.3843 - acc: 0.8798 - val_loss: 1.0398 - val_acc: 0.6731\n",
      "Epoch 22/50\n",
      "208/208 [==============================] - 0s 578us/step - loss: 0.3499 - acc: 0.8846 - val_loss: 1.0967 - val_acc: 0.6538\n",
      "Epoch 23/50\n",
      "208/208 [==============================] - 0s 588us/step - loss: 0.3756 - acc: 0.8846 - val_loss: 1.0502 - val_acc: 0.6346\n",
      "Epoch 24/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "208/208 [==============================] - 0s 591us/step - loss: 0.3208 - acc: 0.9038 - val_loss: 1.0037 - val_acc: 0.6538\n",
      "Epoch 25/50\n",
      "208/208 [==============================] - 0s 574us/step - loss: 0.3328 - acc: 0.9135 - val_loss: 0.9661 - val_acc: 0.6731\n",
      "Epoch 26/50\n",
      "208/208 [==============================] - 0s 583us/step - loss: 0.2630 - acc: 0.9135 - val_loss: 1.0296 - val_acc: 0.6346\n",
      "Epoch 27/50\n",
      "208/208 [==============================] - 0s 547us/step - loss: 0.3162 - acc: 0.9038 - val_loss: 1.1386 - val_acc: 0.5385\n",
      "Epoch 28/50\n",
      "208/208 [==============================] - 0s 531us/step - loss: 0.2284 - acc: 0.9519 - val_loss: 1.0425 - val_acc: 0.6346\n",
      "Epoch 29/50\n",
      "208/208 [==============================] - 0s 551us/step - loss: 0.2003 - acc: 0.9375 - val_loss: 1.1107 - val_acc: 0.6346\n",
      "Epoch 30/50\n",
      "208/208 [==============================] - 0s 551us/step - loss: 0.2084 - acc: 0.9471 - val_loss: 1.1170 - val_acc: 0.5962\n",
      "Epoch 31/50\n",
      "208/208 [==============================] - 0s 566us/step - loss: 0.2852 - acc: 0.9135 - val_loss: 1.0340 - val_acc: 0.6923\n",
      "Epoch 32/50\n",
      "208/208 [==============================] - 0s 570us/step - loss: 0.2169 - acc: 0.9423 - val_loss: 1.0292 - val_acc: 0.7115\n",
      "Epoch 33/50\n",
      "208/208 [==============================] - 0s 560us/step - loss: 0.2252 - acc: 0.9231 - val_loss: 1.0604 - val_acc: 0.7115\n",
      "Epoch 34/50\n",
      "208/208 [==============================] - 0s 564us/step - loss: 0.2510 - acc: 0.9135 - val_loss: 0.9785 - val_acc: 0.7115\n",
      "Epoch 35/50\n",
      "208/208 [==============================] - 0s 572us/step - loss: 0.2005 - acc: 0.9519 - val_loss: 0.9934 - val_acc: 0.6923\n",
      "Epoch 36/50\n",
      "208/208 [==============================] - 0s 566us/step - loss: 0.1707 - acc: 0.9471 - val_loss: 1.0380 - val_acc: 0.6923\n",
      "Epoch 37/50\n",
      "208/208 [==============================] - 0s 572us/step - loss: 0.1786 - acc: 0.9567 - val_loss: 1.0664 - val_acc: 0.6731\n",
      "Epoch 38/50\n",
      "208/208 [==============================] - 0s 555us/step - loss: 0.1787 - acc: 0.9471 - val_loss: 1.0043 - val_acc: 0.6923\n",
      "Epoch 39/50\n",
      "208/208 [==============================] - 0s 575us/step - loss: 0.1833 - acc: 0.9327 - val_loss: 1.0840 - val_acc: 0.6923\n",
      "Epoch 40/50\n",
      "208/208 [==============================] - 0s 559us/step - loss: 0.1597 - acc: 0.9615 - val_loss: 1.1222 - val_acc: 0.6346\n",
      "Epoch 41/50\n",
      "208/208 [==============================] - 0s 566us/step - loss: 0.1421 - acc: 0.9663 - val_loss: 0.9937 - val_acc: 0.7308\n",
      "Epoch 42/50\n",
      "208/208 [==============================] - 0s 556us/step - loss: 0.1031 - acc: 0.9952 - val_loss: 1.0519 - val_acc: 0.6731\n",
      "Epoch 43/50\n",
      "208/208 [==============================] - 0s 579us/step - loss: 0.1405 - acc: 0.9519 - val_loss: 0.9845 - val_acc: 0.7500\n",
      "Epoch 44/50\n",
      "208/208 [==============================] - 0s 564us/step - loss: 0.0987 - acc: 0.9760 - val_loss: 1.0334 - val_acc: 0.6923\n",
      "Epoch 45/50\n",
      "208/208 [==============================] - 0s 550us/step - loss: 0.1189 - acc: 0.9760 - val_loss: 0.9676 - val_acc: 0.7500\n",
      "Epoch 46/50\n",
      "208/208 [==============================] - 0s 569us/step - loss: 0.1202 - acc: 0.9567 - val_loss: 1.0481 - val_acc: 0.6923\n",
      "Epoch 47/50\n",
      "208/208 [==============================] - 0s 569us/step - loss: 0.1031 - acc: 0.9760 - val_loss: 1.0183 - val_acc: 0.7500\n",
      "Epoch 48/50\n",
      "208/208 [==============================] - 0s 551us/step - loss: 0.1080 - acc: 0.9663 - val_loss: 1.0136 - val_acc: 0.7115\n",
      "Epoch 49/50\n",
      "208/208 [==============================] - 0s 599us/step - loss: 0.0966 - acc: 0.9712 - val_loss: 1.0580 - val_acc: 0.7115\n",
      "Epoch 50/50\n",
      "208/208 [==============================] - 0s 567us/step - loss: 0.0871 - acc: 0.9760 - val_loss: 1.0378 - val_acc: 0.7308\n",
      "Train on 208 samples, validate on 52 samples\n",
      "Epoch 1/51\n",
      "208/208 [==============================] - 11s 53ms/step - loss: 3.2605 - acc: 0.0962 - val_loss: 2.3147 - val_acc: 0.1154\n",
      "Epoch 2/51\n",
      "208/208 [==============================] - 0s 597us/step - loss: 2.3406 - acc: 0.3029 - val_loss: 1.9256 - val_acc: 0.3269\n",
      "Epoch 3/51\n",
      "208/208 [==============================] - 0s 618us/step - loss: 1.7144 - acc: 0.3942 - val_loss: 1.6005 - val_acc: 0.5000\n",
      "Epoch 4/51\n",
      "208/208 [==============================] - 0s 579us/step - loss: 1.5453 - acc: 0.4279 - val_loss: 1.6269 - val_acc: 0.5385\n",
      "Epoch 5/51\n",
      "208/208 [==============================] - 0s 589us/step - loss: 1.5589 - acc: 0.5096 - val_loss: 1.4701 - val_acc: 0.5000\n",
      "Epoch 6/51\n",
      "208/208 [==============================] - 0s 642us/step - loss: 1.1926 - acc: 0.5769 - val_loss: 1.5901 - val_acc: 0.4423\n",
      "Epoch 7/51\n",
      "208/208 [==============================] - 0s 553us/step - loss: 1.3129 - acc: 0.5577 - val_loss: 1.3100 - val_acc: 0.5962\n",
      "Epoch 8/51\n",
      "208/208 [==============================] - 0s 606us/step - loss: 0.9708 - acc: 0.6490 - val_loss: 1.2524 - val_acc: 0.5769\n",
      "Epoch 9/51\n",
      "208/208 [==============================] - 0s 555us/step - loss: 0.9562 - acc: 0.6827 - val_loss: 1.5269 - val_acc: 0.5769\n",
      "Epoch 10/51\n",
      "208/208 [==============================] - 0s 592us/step - loss: 0.8683 - acc: 0.7596 - val_loss: 1.0570 - val_acc: 0.6731\n",
      "Epoch 11/51\n",
      "208/208 [==============================] - 0s 570us/step - loss: 0.7474 - acc: 0.7692 - val_loss: 1.0139 - val_acc: 0.6731\n",
      "Epoch 12/51\n",
      "208/208 [==============================] - 0s 574us/step - loss: 0.8234 - acc: 0.7163 - val_loss: 1.0309 - val_acc: 0.5962\n",
      "Epoch 13/51\n",
      "208/208 [==============================] - 0s 576us/step - loss: 0.5738 - acc: 0.8029 - val_loss: 1.0152 - val_acc: 0.6923\n",
      "Epoch 14/51\n",
      "208/208 [==============================] - 0s 571us/step - loss: 0.5733 - acc: 0.8365 - val_loss: 1.0053 - val_acc: 0.6923\n",
      "Epoch 15/51\n",
      "208/208 [==============================] - 0s 568us/step - loss: 0.5586 - acc: 0.7885 - val_loss: 1.0871 - val_acc: 0.6731\n",
      "Epoch 16/51\n",
      "208/208 [==============================] - 0s 582us/step - loss: 0.5359 - acc: 0.8173 - val_loss: 1.0153 - val_acc: 0.6923\n",
      "Epoch 17/51\n",
      "208/208 [==============================] - 0s 594us/step - loss: 0.5466 - acc: 0.7981 - val_loss: 1.0964 - val_acc: 0.5962\n",
      "Epoch 18/51\n",
      "208/208 [==============================] - 0s 573us/step - loss: 0.4732 - acc: 0.8413 - val_loss: 0.9364 - val_acc: 0.7308\n",
      "Epoch 19/51\n",
      "208/208 [==============================] - 0s 575us/step - loss: 0.3642 - acc: 0.8750 - val_loss: 1.2389 - val_acc: 0.5577\n",
      "Epoch 20/51\n",
      "208/208 [==============================] - 0s 566us/step - loss: 0.4289 - acc: 0.8606 - val_loss: 1.0646 - val_acc: 0.6731\n",
      "Epoch 21/51\n",
      "208/208 [==============================] - 0s 593us/step - loss: 0.4453 - acc: 0.8702 - val_loss: 1.0849 - val_acc: 0.6346\n",
      "Epoch 22/51\n",
      "208/208 [==============================] - 0s 582us/step - loss: 0.3753 - acc: 0.8798 - val_loss: 1.0763 - val_acc: 0.6538\n",
      "Epoch 23/51\n",
      "208/208 [==============================] - 0s 662us/step - loss: 0.3519 - acc: 0.8846 - val_loss: 1.0235 - val_acc: 0.6923\n",
      "Epoch 24/51\n",
      "208/208 [==============================] - 0s 620us/step - loss: 0.3457 - acc: 0.8798 - val_loss: 1.0160 - val_acc: 0.6538\n",
      "Epoch 25/51\n",
      "208/208 [==============================] - 0s 649us/step - loss: 0.3339 - acc: 0.8990 - val_loss: 0.9534 - val_acc: 0.6731\n",
      "Epoch 26/51\n",
      "208/208 [==============================] - 0s 743us/step - loss: 0.2526 - acc: 0.9279 - val_loss: 0.9785 - val_acc: 0.6731\n",
      "Epoch 27/51\n",
      "208/208 [==============================] - 0s 729us/step - loss: 0.3152 - acc: 0.8846 - val_loss: 1.1367 - val_acc: 0.5769\n",
      "Epoch 28/51\n",
      "208/208 [==============================] - 0s 700us/step - loss: 0.2320 - acc: 0.9423 - val_loss: 1.0159 - val_acc: 0.6731\n",
      "Epoch 29/51\n",
      "208/208 [==============================] - 0s 694us/step - loss: 0.2030 - acc: 0.9519 - val_loss: 1.1010 - val_acc: 0.6154\n",
      "Epoch 30/51\n",
      "208/208 [==============================] - 0s 649us/step - loss: 0.2061 - acc: 0.9423 - val_loss: 1.0927 - val_acc: 0.6154\n",
      "Epoch 31/51\n",
      "208/208 [==============================] - 0s 591us/step - loss: 0.2866 - acc: 0.9087 - val_loss: 1.0438 - val_acc: 0.6923\n",
      "Epoch 32/51\n",
      "208/208 [==============================] - 0s 622us/step - loss: 0.2243 - acc: 0.9279 - val_loss: 1.0269 - val_acc: 0.6731\n",
      "Epoch 33/51\n",
      "208/208 [==============================] - 0s 635us/step - loss: 0.2190 - acc: 0.9231 - val_loss: 1.0459 - val_acc: 0.6731\n",
      "Epoch 34/51\n",
      "208/208 [==============================] - 0s 757us/step - loss: 0.2480 - acc: 0.9135 - val_loss: 0.9713 - val_acc: 0.7115\n",
      "Epoch 35/51\n",
      "208/208 [==============================] - 0s 661us/step - loss: 0.1947 - acc: 0.9663 - val_loss: 0.9862 - val_acc: 0.6923\n",
      "Epoch 36/51\n",
      "208/208 [==============================] - 0s 613us/step - loss: 0.1794 - acc: 0.9519 - val_loss: 1.0168 - val_acc: 0.6923\n",
      "Epoch 37/51\n",
      "208/208 [==============================] - 0s 605us/step - loss: 0.1866 - acc: 0.9567 - val_loss: 1.0495 - val_acc: 0.6731\n",
      "Epoch 38/51\n",
      "208/208 [==============================] - 0s 593us/step - loss: 0.1628 - acc: 0.9519 - val_loss: 0.9996 - val_acc: 0.7500\n",
      "Epoch 39/51\n",
      "208/208 [==============================] - 0s 647us/step - loss: 0.1746 - acc: 0.9423 - val_loss: 1.0429 - val_acc: 0.7115\n",
      "Epoch 40/51\n",
      "208/208 [==============================] - 0s 721us/step - loss: 0.1383 - acc: 0.9712 - val_loss: 1.1008 - val_acc: 0.6538\n",
      "Epoch 41/51\n",
      "208/208 [==============================] - 0s 804us/step - loss: 0.1318 - acc: 0.9712 - val_loss: 0.9816 - val_acc: 0.7500\n",
      "Epoch 42/51\n",
      "208/208 [==============================] - 0s 713us/step - loss: 0.1092 - acc: 0.9856 - val_loss: 1.0460 - val_acc: 0.6923\n",
      "Epoch 43/51\n",
      "208/208 [==============================] - 0s 617us/step - loss: 0.1370 - acc: 0.9615 - val_loss: 0.9869 - val_acc: 0.7308\n",
      "Epoch 44/51\n",
      "208/208 [==============================] - 0s 884us/step - loss: 0.1019 - acc: 0.9760 - val_loss: 1.0161 - val_acc: 0.7115\n",
      "Epoch 45/51\n",
      "208/208 [==============================] - 0s 590us/step - loss: 0.1239 - acc: 0.9760 - val_loss: 0.9895 - val_acc: 0.7308\n",
      "Epoch 46/51\n",
      "208/208 [==============================] - 0s 599us/step - loss: 0.1143 - acc: 0.9712 - val_loss: 1.0463 - val_acc: 0.7308\n",
      "Epoch 47/51\n",
      "208/208 [==============================] - 0s 613us/step - loss: 0.0985 - acc: 0.9808 - val_loss: 1.0119 - val_acc: 0.7308\n",
      "Epoch 48/51\n",
      "208/208 [==============================] - 0s 561us/step - loss: 0.1243 - acc: 0.9423 - val_loss: 1.0623 - val_acc: 0.7308\n",
      "Epoch 49/51\n",
      "208/208 [==============================] - 0s 605us/step - loss: 0.1264 - acc: 0.9519 - val_loss: 1.1023 - val_acc: 0.7115\n",
      "Epoch 50/51\n",
      "208/208 [==============================] - 0s 610us/step - loss: 0.0867 - acc: 0.9808 - val_loss: 1.0696 - val_acc: 0.7500\n",
      "Epoch 51/51\n",
      "208/208 [==============================] - 0s 641us/step - loss: 0.1341 - acc: 0.9567 - val_loss: 1.2187 - val_acc: 0.6538\n",
      "Train on 208 samples, validate on 52 samples\n",
      "Epoch 1/52\n",
      "208/208 [==============================] - 11s 54ms/step - loss: 3.2605 - acc: 0.0962 - val_loss: 2.3147 - val_acc: 0.1154\n",
      "Epoch 2/52\n",
      "208/208 [==============================] - 0s 671us/step - loss: 2.3406 - acc: 0.3029 - val_loss: 1.9256 - val_acc: 0.3269\n",
      "Epoch 3/52\n",
      "208/208 [==============================] - 0s 500us/step - loss: 1.7144 - acc: 0.3942 - val_loss: 1.6005 - val_acc: 0.5000\n",
      "Epoch 4/52\n",
      "208/208 [==============================] - 0s 505us/step - loss: 1.5453 - acc: 0.4279 - val_loss: 1.6269 - val_acc: 0.5385\n",
      "Epoch 5/52\n",
      "208/208 [==============================] - 0s 500us/step - loss: 1.5589 - acc: 0.5096 - val_loss: 1.4701 - val_acc: 0.5000\n",
      "Epoch 6/52\n",
      "208/208 [==============================] - 0s 498us/step - loss: 1.1923 - acc: 0.5817 - val_loss: 1.5850 - val_acc: 0.4423\n",
      "Epoch 7/52\n",
      "208/208 [==============================] - 0s 523us/step - loss: 1.3101 - acc: 0.5577 - val_loss: 1.3253 - val_acc: 0.5769\n",
      "Epoch 8/52\n",
      "208/208 [==============================] - 0s 514us/step - loss: 0.9788 - acc: 0.6346 - val_loss: 1.2279 - val_acc: 0.5577\n",
      "Epoch 9/52\n",
      "208/208 [==============================] - 0s 495us/step - loss: 0.9346 - acc: 0.6875 - val_loss: 1.4580 - val_acc: 0.5962\n",
      "Epoch 10/52\n",
      "208/208 [==============================] - 0s 491us/step - loss: 0.8187 - acc: 0.7740 - val_loss: 1.0723 - val_acc: 0.6346\n",
      "Epoch 11/52\n",
      "208/208 [==============================] - 0s 542us/step - loss: 0.7353 - acc: 0.7596 - val_loss: 0.9954 - val_acc: 0.6731\n",
      "Epoch 12/52\n",
      "208/208 [==============================] - 0s 514us/step - loss: 0.7850 - acc: 0.7356 - val_loss: 1.0725 - val_acc: 0.5769\n",
      "Epoch 13/52\n",
      "208/208 [==============================] - 0s 574us/step - loss: 0.5560 - acc: 0.7933 - val_loss: 1.0624 - val_acc: 0.6731\n",
      "Epoch 14/52\n",
      "208/208 [==============================] - 0s 555us/step - loss: 0.5528 - acc: 0.8269 - val_loss: 1.0404 - val_acc: 0.6923\n",
      "Epoch 15/52\n",
      "208/208 [==============================] - 0s 542us/step - loss: 0.5593 - acc: 0.7885 - val_loss: 1.0953 - val_acc: 0.6923\n",
      "Epoch 16/52\n",
      "208/208 [==============================] - 0s 632us/step - loss: 0.5367 - acc: 0.8029 - val_loss: 1.0774 - val_acc: 0.6538\n",
      "Epoch 17/52\n",
      "208/208 [==============================] - 0s 541us/step - loss: 0.5675 - acc: 0.7885 - val_loss: 1.1222 - val_acc: 0.5577\n",
      "Epoch 18/52\n",
      "208/208 [==============================] - 0s 534us/step - loss: 0.4930 - acc: 0.8221 - val_loss: 0.9414 - val_acc: 0.7308\n",
      "Epoch 19/52\n",
      "208/208 [==============================] - 0s 580us/step - loss: 0.3706 - acc: 0.8798 - val_loss: 1.1944 - val_acc: 0.5769\n",
      "Epoch 20/52\n",
      "208/208 [==============================] - 0s 553us/step - loss: 0.4193 - acc: 0.8654 - val_loss: 1.0358 - val_acc: 0.6731\n",
      "Epoch 21/52\n",
      "208/208 [==============================] - 0s 511us/step - loss: 0.3843 - acc: 0.8798 - val_loss: 1.0398 - val_acc: 0.6731\n",
      "Epoch 22/52\n",
      "208/208 [==============================] - 0s 505us/step - loss: 0.3499 - acc: 0.8846 - val_loss: 1.0967 - val_acc: 0.6538\n",
      "Epoch 23/52\n",
      "208/208 [==============================] - 0s 496us/step - loss: 0.3756 - acc: 0.8846 - val_loss: 1.0502 - val_acc: 0.6346\n",
      "Epoch 24/52\n",
      "208/208 [==============================] - 0s 499us/step - loss: 0.3208 - acc: 0.9038 - val_loss: 1.0037 - val_acc: 0.6538\n",
      "Epoch 25/52\n",
      "208/208 [==============================] - 0s 562us/step - loss: 0.3328 - acc: 0.9135 - val_loss: 0.9661 - val_acc: 0.6731\n",
      "Epoch 26/52\n",
      "208/208 [==============================] - 0s 525us/step - loss: 0.2630 - acc: 0.9135 - val_loss: 1.0296 - val_acc: 0.6346\n",
      "Epoch 27/52\n",
      "208/208 [==============================] - 0s 534us/step - loss: 0.3162 - acc: 0.9038 - val_loss: 1.1386 - val_acc: 0.5385\n",
      "Epoch 28/52\n",
      "208/208 [==============================] - 0s 510us/step - loss: 0.2284 - acc: 0.9519 - val_loss: 1.0425 - val_acc: 0.6346\n",
      "Epoch 29/52\n",
      "208/208 [==============================] - 0s 517us/step - loss: 0.2003 - acc: 0.9375 - val_loss: 1.1107 - val_acc: 0.6346\n",
      "Epoch 30/52\n",
      "208/208 [==============================] - 0s 518us/step - loss: 0.2084 - acc: 0.9471 - val_loss: 1.1170 - val_acc: 0.5962\n",
      "Epoch 31/52\n",
      "208/208 [==============================] - 0s 523us/step - loss: 0.2852 - acc: 0.9135 - val_loss: 1.0340 - val_acc: 0.6923\n",
      "Epoch 32/52\n",
      "208/208 [==============================] - 0s 536us/step - loss: 0.2169 - acc: 0.9423 - val_loss: 1.0292 - val_acc: 0.7115\n",
      "Epoch 33/52\n",
      "208/208 [==============================] - 0s 593us/step - loss: 0.2252 - acc: 0.9231 - val_loss: 1.0604 - val_acc: 0.7115\n",
      "Epoch 34/52\n",
      "208/208 [==============================] - 0s 508us/step - loss: 0.2510 - acc: 0.9135 - val_loss: 0.9785 - val_acc: 0.7115\n",
      "Epoch 35/52\n",
      "208/208 [==============================] - 0s 494us/step - loss: 0.2005 - acc: 0.9519 - val_loss: 0.9934 - val_acc: 0.6923\n",
      "Epoch 36/52\n",
      "208/208 [==============================] - 0s 503us/step - loss: 0.1707 - acc: 0.9471 - val_loss: 1.0380 - val_acc: 0.6923\n",
      "Epoch 37/52\n",
      "208/208 [==============================] - 0s 490us/step - loss: 0.1786 - acc: 0.9567 - val_loss: 1.0664 - val_acc: 0.6731\n",
      "Epoch 38/52\n",
      "208/208 [==============================] - 0s 482us/step - loss: 0.1787 - acc: 0.9471 - val_loss: 1.0043 - val_acc: 0.6923\n",
      "Epoch 39/52\n",
      "208/208 [==============================] - 0s 481us/step - loss: 0.1833 - acc: 0.9327 - val_loss: 1.0840 - val_acc: 0.6923\n",
      "Epoch 40/52\n",
      "208/208 [==============================] - 0s 501us/step - loss: 0.1597 - acc: 0.9615 - val_loss: 1.1222 - val_acc: 0.6346\n",
      "Epoch 41/52\n",
      "208/208 [==============================] - 0s 494us/step - loss: 0.1421 - acc: 0.9663 - val_loss: 0.9937 - val_acc: 0.7308\n",
      "Epoch 42/52\n",
      "208/208 [==============================] - 0s 494us/step - loss: 0.1031 - acc: 0.9952 - val_loss: 1.0519 - val_acc: 0.6731\n",
      "Epoch 43/52\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "208/208 [==============================] - 0s 489us/step - loss: 0.1405 - acc: 0.9519 - val_loss: 0.9845 - val_acc: 0.7500\n",
      "Epoch 44/52\n",
      "208/208 [==============================] - 0s 556us/step - loss: 0.0987 - acc: 0.9760 - val_loss: 1.0334 - val_acc: 0.6923\n",
      "Epoch 45/52\n",
      "208/208 [==============================] - 0s 507us/step - loss: 0.1189 - acc: 0.9760 - val_loss: 0.9676 - val_acc: 0.7500\n",
      "Epoch 46/52\n",
      "208/208 [==============================] - 0s 534us/step - loss: 0.1202 - acc: 0.9567 - val_loss: 1.0481 - val_acc: 0.6923\n",
      "Epoch 47/52\n",
      "208/208 [==============================] - 0s 583us/step - loss: 0.1031 - acc: 0.9760 - val_loss: 1.0183 - val_acc: 0.7500\n",
      "Epoch 48/52\n",
      "208/208 [==============================] - 0s 588us/step - loss: 0.1080 - acc: 0.9663 - val_loss: 1.0136 - val_acc: 0.7115\n",
      "Epoch 49/52\n",
      "208/208 [==============================] - 0s 499us/step - loss: 0.0966 - acc: 0.9712 - val_loss: 1.0580 - val_acc: 0.7115\n",
      "Epoch 50/52\n",
      "208/208 [==============================] - 0s 528us/step - loss: 0.0871 - acc: 0.9760 - val_loss: 1.0378 - val_acc: 0.7308\n",
      "Epoch 51/52\n",
      "208/208 [==============================] - 0s 653us/step - loss: 0.1279 - acc: 0.9615 - val_loss: 1.2068 - val_acc: 0.6346\n",
      "Epoch 52/52\n",
      "208/208 [==============================] - 0s 609us/step - loss: 0.1963 - acc: 0.9423 - val_loss: 1.2403 - val_acc: 0.6538\n",
      "Train on 208 samples, validate on 52 samples\n",
      "Epoch 1/53\n",
      "208/208 [==============================] - 11s 53ms/step - loss: 3.2605 - acc: 0.0962 - val_loss: 2.3147 - val_acc: 0.1154\n",
      "Epoch 2/53\n",
      "208/208 [==============================] - 0s 571us/step - loss: 2.3406 - acc: 0.3029 - val_loss: 1.9256 - val_acc: 0.3269\n",
      "Epoch 3/53\n",
      "208/208 [==============================] - 0s 629us/step - loss: 1.7144 - acc: 0.3942 - val_loss: 1.6005 - val_acc: 0.5000\n",
      "Epoch 4/53\n",
      "208/208 [==============================] - 0s 592us/step - loss: 1.5453 - acc: 0.4279 - val_loss: 1.6269 - val_acc: 0.5385\n",
      "Epoch 5/53\n",
      "208/208 [==============================] - 0s 554us/step - loss: 1.5589 - acc: 0.5096 - val_loss: 1.4701 - val_acc: 0.5000\n",
      "Epoch 6/53\n",
      "208/208 [==============================] - 0s 571us/step - loss: 1.1923 - acc: 0.5817 - val_loss: 1.5850 - val_acc: 0.4423\n",
      "Epoch 7/53\n",
      "208/208 [==============================] - 0s 670us/step - loss: 1.3101 - acc: 0.5577 - val_loss: 1.3253 - val_acc: 0.5769\n",
      "Epoch 8/53\n",
      "208/208 [==============================] - 0s 708us/step - loss: 0.9788 - acc: 0.6346 - val_loss: 1.2279 - val_acc: 0.5577\n",
      "Epoch 9/53\n",
      "208/208 [==============================] - 0s 688us/step - loss: 0.9346 - acc: 0.6875 - val_loss: 1.4580 - val_acc: 0.5962\n",
      "Epoch 10/53\n",
      "208/208 [==============================] - 0s 694us/step - loss: 0.8187 - acc: 0.7740 - val_loss: 1.0723 - val_acc: 0.6346\n",
      "Epoch 11/53\n",
      "208/208 [==============================] - 0s 620us/step - loss: 0.7353 - acc: 0.7596 - val_loss: 0.9954 - val_acc: 0.6731\n",
      "Epoch 12/53\n",
      "208/208 [==============================] - 0s 642us/step - loss: 0.7850 - acc: 0.7356 - val_loss: 1.0725 - val_acc: 0.5769\n",
      "Epoch 13/53\n",
      "208/208 [==============================] - 0s 589us/step - loss: 0.5560 - acc: 0.7933 - val_loss: 1.0624 - val_acc: 0.6731\n",
      "Epoch 14/53\n",
      "208/208 [==============================] - 0s 608us/step - loss: 0.5528 - acc: 0.8269 - val_loss: 1.0404 - val_acc: 0.6923\n",
      "Epoch 15/53\n",
      "208/208 [==============================] - 0s 576us/step - loss: 0.5593 - acc: 0.7885 - val_loss: 1.0953 - val_acc: 0.6923\n",
      "Epoch 16/53\n",
      "208/208 [==============================] - 0s 623us/step - loss: 0.5367 - acc: 0.8029 - val_loss: 1.0774 - val_acc: 0.6538\n",
      "Epoch 17/53\n",
      "208/208 [==============================] - 0s 571us/step - loss: 0.5675 - acc: 0.7885 - val_loss: 1.1225 - val_acc: 0.5577\n",
      "Epoch 18/53\n",
      "208/208 [==============================] - 0s 645us/step - loss: 0.4936 - acc: 0.8221 - val_loss: 0.9451 - val_acc: 0.7308\n",
      "Epoch 19/53\n",
      "208/208 [==============================] - 0s 576us/step - loss: 0.3704 - acc: 0.8798 - val_loss: 1.1971 - val_acc: 0.5769\n",
      "Epoch 20/53\n",
      "208/208 [==============================] - 0s 618us/step - loss: 0.4187 - acc: 0.8606 - val_loss: 1.0398 - val_acc: 0.6731\n",
      "Epoch 21/53\n",
      "208/208 [==============================] - 0s 579us/step - loss: 0.3846 - acc: 0.8894 - val_loss: 1.0369 - val_acc: 0.6538\n",
      "Epoch 22/53\n",
      "208/208 [==============================] - 0s 624us/step - loss: 0.3495 - acc: 0.8894 - val_loss: 1.1146 - val_acc: 0.6538\n",
      "Epoch 23/53\n",
      "208/208 [==============================] - 0s 571us/step - loss: 0.3885 - acc: 0.8798 - val_loss: 1.0846 - val_acc: 0.6154\n",
      "Epoch 24/53\n",
      "208/208 [==============================] - 0s 618us/step - loss: 0.3319 - acc: 0.8990 - val_loss: 0.9779 - val_acc: 0.6538\n",
      "Epoch 25/53\n",
      "208/208 [==============================] - 0s 579us/step - loss: 0.3375 - acc: 0.8990 - val_loss: 0.9754 - val_acc: 0.6731\n",
      "Epoch 26/53\n",
      "208/208 [==============================] - 0s 636us/step - loss: 0.2661 - acc: 0.9183 - val_loss: 1.0438 - val_acc: 0.6538\n",
      "Epoch 27/53\n",
      "208/208 [==============================] - 0s 572us/step - loss: 0.3220 - acc: 0.8942 - val_loss: 1.1978 - val_acc: 0.5577\n",
      "Epoch 28/53\n",
      "208/208 [==============================] - 0s 621us/step - loss: 0.2317 - acc: 0.9423 - val_loss: 1.0334 - val_acc: 0.6538\n",
      "Epoch 29/53\n",
      "208/208 [==============================] - 0s 569us/step - loss: 0.2004 - acc: 0.9327 - val_loss: 1.1047 - val_acc: 0.6538\n",
      "Epoch 30/53\n",
      "208/208 [==============================] - 0s 606us/step - loss: 0.1983 - acc: 0.9519 - val_loss: 1.1081 - val_acc: 0.5962\n",
      "Epoch 31/53\n",
      "208/208 [==============================] - 0s 579us/step - loss: 0.2912 - acc: 0.9183 - val_loss: 1.0324 - val_acc: 0.6923\n",
      "Epoch 32/53\n",
      "208/208 [==============================] - 0s 610us/step - loss: 0.2195 - acc: 0.9327 - val_loss: 1.0232 - val_acc: 0.6731\n",
      "Epoch 33/53\n",
      "208/208 [==============================] - 0s 566us/step - loss: 0.2180 - acc: 0.9327 - val_loss: 1.0545 - val_acc: 0.6731\n",
      "Epoch 34/53\n",
      "208/208 [==============================] - 0s 627us/step - loss: 0.2490 - acc: 0.9231 - val_loss: 0.9920 - val_acc: 0.6923\n",
      "Epoch 35/53\n",
      "208/208 [==============================] - 0s 584us/step - loss: 0.1949 - acc: 0.9615 - val_loss: 0.9886 - val_acc: 0.7115\n",
      "Epoch 36/53\n",
      "208/208 [==============================] - 0s 633us/step - loss: 0.1736 - acc: 0.9327 - val_loss: 1.0452 - val_acc: 0.6731\n",
      "Epoch 37/53\n",
      "208/208 [==============================] - 0s 579us/step - loss: 0.1722 - acc: 0.9567 - val_loss: 1.0585 - val_acc: 0.6731\n",
      "Epoch 38/53\n",
      "208/208 [==============================] - 0s 642us/step - loss: 0.1797 - acc: 0.9375 - val_loss: 0.9950 - val_acc: 0.7115\n",
      "Epoch 39/53\n",
      "208/208 [==============================] - 0s 586us/step - loss: 0.1787 - acc: 0.9279 - val_loss: 1.0791 - val_acc: 0.6923\n",
      "Epoch 40/53\n",
      "208/208 [==============================] - 0s 588us/step - loss: 0.1585 - acc: 0.9615 - val_loss: 1.1363 - val_acc: 0.6346\n",
      "Epoch 41/53\n",
      "208/208 [==============================] - 0s 645us/step - loss: 0.1415 - acc: 0.9712 - val_loss: 0.9897 - val_acc: 0.7308\n",
      "Epoch 42/53\n",
      "208/208 [==============================] - 0s 671us/step - loss: 0.1121 - acc: 0.9808 - val_loss: 1.0800 - val_acc: 0.6923\n",
      "Epoch 43/53\n",
      "208/208 [==============================] - 0s 619us/step - loss: 0.1443 - acc: 0.9663 - val_loss: 0.9961 - val_acc: 0.7308\n",
      "Epoch 44/53\n",
      "208/208 [==============================] - 0s 628us/step - loss: 0.1072 - acc: 0.9712 - val_loss: 1.0601 - val_acc: 0.6923\n",
      "Epoch 45/53\n",
      "208/208 [==============================] - 0s 575us/step - loss: 0.1264 - acc: 0.9760 - val_loss: 0.9884 - val_acc: 0.7308\n",
      "Epoch 46/53\n",
      "208/208 [==============================] - 0s 721us/step - loss: 0.1168 - acc: 0.9567 - val_loss: 1.0704 - val_acc: 0.6923\n",
      "Epoch 47/53\n",
      "208/208 [==============================] - 0s 650us/step - loss: 0.1033 - acc: 0.9808 - val_loss: 1.0251 - val_acc: 0.7308\n",
      "Epoch 48/53\n",
      "208/208 [==============================] - 0s 655us/step - loss: 0.1051 - acc: 0.9567 - val_loss: 1.0447 - val_acc: 0.7115\n",
      "Epoch 49/53\n",
      "208/208 [==============================] - 0s 626us/step - loss: 0.0953 - acc: 0.9760 - val_loss: 1.0685 - val_acc: 0.7115\n",
      "Epoch 50/53\n",
      "208/208 [==============================] - 0s 597us/step - loss: 0.0883 - acc: 0.9712 - val_loss: 1.0443 - val_acc: 0.7692\n",
      "Epoch 51/53\n",
      "208/208 [==============================] - 0s 641us/step - loss: 0.1293 - acc: 0.9567 - val_loss: 1.2013 - val_acc: 0.6346\n",
      "Epoch 52/53\n",
      "208/208 [==============================] - 0s 624us/step - loss: 0.1836 - acc: 0.9375 - val_loss: 1.2206 - val_acc: 0.6346\n",
      "Epoch 53/53\n",
      "208/208 [==============================] - 0s 583us/step - loss: 0.0815 - acc: 0.9760 - val_loss: 1.1395 - val_acc: 0.6923\n",
      "Train on 208 samples, validate on 52 samples\n",
      "Epoch 1/54\n",
      "208/208 [==============================] - 11s 54ms/step - loss: 3.2605 - acc: 0.0962 - val_loss: 2.3147 - val_acc: 0.1154\n",
      "Epoch 2/54\n",
      "208/208 [==============================] - 0s 587us/step - loss: 2.3406 - acc: 0.3029 - val_loss: 1.9256 - val_acc: 0.3269\n",
      "Epoch 3/54\n",
      "208/208 [==============================] - 0s 586us/step - loss: 1.7144 - acc: 0.3942 - val_loss: 1.6005 - val_acc: 0.5000\n",
      "Epoch 4/54\n",
      "208/208 [==============================] - 0s 565us/step - loss: 1.5453 - acc: 0.4279 - val_loss: 1.6269 - val_acc: 0.5385\n",
      "Epoch 5/54\n",
      "208/208 [==============================] - 0s 570us/step - loss: 1.5589 - acc: 0.5096 - val_loss: 1.4701 - val_acc: 0.5000\n",
      "Epoch 6/54\n",
      "208/208 [==============================] - 0s 590us/step - loss: 1.1923 - acc: 0.5817 - val_loss: 1.5850 - val_acc: 0.4423\n",
      "Epoch 7/54\n",
      "208/208 [==============================] - 0s 571us/step - loss: 1.3101 - acc: 0.5577 - val_loss: 1.3253 - val_acc: 0.5769\n",
      "Epoch 8/54\n",
      "208/208 [==============================] - 0s 564us/step - loss: 0.9788 - acc: 0.6346 - val_loss: 1.2279 - val_acc: 0.5577\n",
      "Epoch 9/54\n",
      "208/208 [==============================] - 0s 556us/step - loss: 0.9346 - acc: 0.6875 - val_loss: 1.4580 - val_acc: 0.5962\n",
      "Epoch 10/54\n",
      "208/208 [==============================] - 0s 561us/step - loss: 0.8187 - acc: 0.7740 - val_loss: 1.0723 - val_acc: 0.6346\n",
      "Epoch 11/54\n",
      "208/208 [==============================] - 0s 570us/step - loss: 0.7353 - acc: 0.7596 - val_loss: 0.9954 - val_acc: 0.6731\n",
      "Epoch 12/54\n",
      "208/208 [==============================] - 0s 586us/step - loss: 0.7850 - acc: 0.7356 - val_loss: 1.0725 - val_acc: 0.5769\n",
      "Epoch 13/54\n",
      "208/208 [==============================] - 0s 574us/step - loss: 0.5560 - acc: 0.7933 - val_loss: 1.0624 - val_acc: 0.6731\n",
      "Epoch 14/54\n",
      "208/208 [==============================] - 0s 580us/step - loss: 0.5528 - acc: 0.8269 - val_loss: 1.0404 - val_acc: 0.6923\n",
      "Epoch 15/54\n",
      "208/208 [==============================] - 0s 569us/step - loss: 0.5593 - acc: 0.7885 - val_loss: 1.0953 - val_acc: 0.6923\n",
      "Epoch 16/54\n",
      "208/208 [==============================] - 0s 565us/step - loss: 0.5367 - acc: 0.8029 - val_loss: 1.0774 - val_acc: 0.6538\n",
      "Epoch 17/54\n",
      "208/208 [==============================] - 0s 589us/step - loss: 0.5675 - acc: 0.7885 - val_loss: 1.1222 - val_acc: 0.5577\n",
      "Epoch 18/54\n",
      "208/208 [==============================] - 0s 599us/step - loss: 0.4930 - acc: 0.8221 - val_loss: 0.9414 - val_acc: 0.7308\n",
      "Epoch 19/54\n",
      "208/208 [==============================] - 0s 570us/step - loss: 0.3706 - acc: 0.8798 - val_loss: 1.1944 - val_acc: 0.5769\n",
      "Epoch 20/54\n",
      "208/208 [==============================] - 0s 603us/step - loss: 0.4193 - acc: 0.8654 - val_loss: 1.0358 - val_acc: 0.6731\n",
      "Epoch 21/54\n",
      "208/208 [==============================] - 0s 562us/step - loss: 0.3844 - acc: 0.8798 - val_loss: 1.0436 - val_acc: 0.6731\n",
      "Epoch 22/54\n",
      "208/208 [==============================] - 0s 584us/step - loss: 0.3488 - acc: 0.8846 - val_loss: 1.1057 - val_acc: 0.6154\n",
      "Epoch 23/54\n",
      "208/208 [==============================] - 0s 575us/step - loss: 0.3807 - acc: 0.8798 - val_loss: 1.0535 - val_acc: 0.6346\n",
      "Epoch 24/54\n",
      "208/208 [==============================] - 0s 588us/step - loss: 0.3218 - acc: 0.9038 - val_loss: 1.0007 - val_acc: 0.6731\n",
      "Epoch 25/54\n",
      "208/208 [==============================] - 0s 578us/step - loss: 0.3324 - acc: 0.9183 - val_loss: 0.9672 - val_acc: 0.6731\n",
      "Epoch 26/54\n",
      "208/208 [==============================] - 0s 554us/step - loss: 0.2645 - acc: 0.9135 - val_loss: 1.0407 - val_acc: 0.6346\n",
      "Epoch 27/54\n",
      "208/208 [==============================] - 0s 586us/step - loss: 0.3180 - acc: 0.8990 - val_loss: 1.1485 - val_acc: 0.5385\n",
      "Epoch 28/54\n",
      "208/208 [==============================] - 0s 564us/step - loss: 0.2251 - acc: 0.9375 - val_loss: 1.0424 - val_acc: 0.6346\n",
      "Epoch 29/54\n",
      "208/208 [==============================] - 0s 619us/step - loss: 0.1981 - acc: 0.9423 - val_loss: 1.1209 - val_acc: 0.5962\n",
      "Epoch 30/54\n",
      "208/208 [==============================] - 0s 586us/step - loss: 0.2058 - acc: 0.9519 - val_loss: 1.1351 - val_acc: 0.5962\n",
      "Epoch 31/54\n",
      "208/208 [==============================] - 0s 567us/step - loss: 0.2863 - acc: 0.9135 - val_loss: 1.0462 - val_acc: 0.7115\n",
      "Epoch 32/54\n",
      "208/208 [==============================] - 0s 583us/step - loss: 0.2226 - acc: 0.9279 - val_loss: 1.0333 - val_acc: 0.6731\n",
      "Epoch 33/54\n",
      "208/208 [==============================] - 0s 626us/step - loss: 0.2265 - acc: 0.9231 - val_loss: 1.0667 - val_acc: 0.6923\n",
      "Epoch 34/54\n",
      "208/208 [==============================] - 0s 577us/step - loss: 0.2518 - acc: 0.9038 - val_loss: 0.9895 - val_acc: 0.7115\n",
      "Epoch 35/54\n",
      "208/208 [==============================] - 0s 572us/step - loss: 0.1955 - acc: 0.9519 - val_loss: 0.9815 - val_acc: 0.6923\n",
      "Epoch 36/54\n",
      "208/208 [==============================] - 0s 590us/step - loss: 0.1678 - acc: 0.9471 - val_loss: 1.0357 - val_acc: 0.6731\n",
      "Epoch 37/54\n",
      "208/208 [==============================] - 0s 592us/step - loss: 0.1787 - acc: 0.9471 - val_loss: 1.0594 - val_acc: 0.6731\n",
      "Epoch 38/54\n",
      "208/208 [==============================] - 0s 587us/step - loss: 0.1795 - acc: 0.9423 - val_loss: 1.0132 - val_acc: 0.7308\n",
      "Epoch 39/54\n",
      "208/208 [==============================] - 0s 579us/step - loss: 0.1848 - acc: 0.9327 - val_loss: 1.0931 - val_acc: 0.6923\n",
      "Epoch 40/54\n",
      "208/208 [==============================] - 0s 589us/step - loss: 0.1593 - acc: 0.9519 - val_loss: 1.1173 - val_acc: 0.6538\n",
      "Epoch 41/54\n",
      "208/208 [==============================] - 0s 567us/step - loss: 0.1398 - acc: 0.9663 - val_loss: 0.9913 - val_acc: 0.7308\n",
      "Epoch 42/54\n",
      "208/208 [==============================] - 0s 561us/step - loss: 0.1084 - acc: 0.9952 - val_loss: 1.0650 - val_acc: 0.6731\n",
      "Epoch 43/54\n",
      "208/208 [==============================] - 0s 570us/step - loss: 0.1379 - acc: 0.9712 - val_loss: 1.0149 - val_acc: 0.7115\n",
      "Epoch 44/54\n",
      "208/208 [==============================] - 0s 589us/step - loss: 0.1081 - acc: 0.9663 - val_loss: 1.0575 - val_acc: 0.6923\n",
      "Epoch 45/54\n",
      "208/208 [==============================] - 0s 572us/step - loss: 0.1223 - acc: 0.9760 - val_loss: 0.9843 - val_acc: 0.7500\n",
      "Epoch 46/54\n",
      "208/208 [==============================] - 0s 589us/step - loss: 0.1259 - acc: 0.9471 - val_loss: 1.0734 - val_acc: 0.7115\n",
      "Epoch 47/54\n",
      "208/208 [==============================] - 0s 580us/step - loss: 0.1064 - acc: 0.9808 - val_loss: 1.0363 - val_acc: 0.7115\n",
      "Epoch 48/54\n",
      "208/208 [==============================] - 0s 584us/step - loss: 0.0994 - acc: 0.9760 - val_loss: 1.0315 - val_acc: 0.7115\n",
      "Epoch 49/54\n",
      "208/208 [==============================] - 0s 585us/step - loss: 0.0978 - acc: 0.9760 - val_loss: 1.0646 - val_acc: 0.7115\n",
      "Epoch 50/54\n",
      "208/208 [==============================] - 0s 562us/step - loss: 0.0921 - acc: 0.9712 - val_loss: 1.0330 - val_acc: 0.7692\n",
      "Epoch 51/54\n",
      "208/208 [==============================] - 0s 593us/step - loss: 0.1304 - acc: 0.9615 - val_loss: 1.1851 - val_acc: 0.6346\n",
      "Epoch 52/54\n",
      "208/208 [==============================] - 0s 569us/step - loss: 0.1867 - acc: 0.9375 - val_loss: 1.1740 - val_acc: 0.6731\n",
      "Epoch 53/54\n",
      "208/208 [==============================] - 0s 599us/step - loss: 0.0831 - acc: 0.9760 - val_loss: 1.1278 - val_acc: 0.6923\n",
      "Epoch 54/54\n",
      "208/208 [==============================] - 0s 598us/step - loss: 0.0971 - acc: 0.9712 - val_loss: 1.0704 - val_acc: 0.6731\n",
      "Train on 208 samples, validate on 52 samples\n",
      "Epoch 1/55\n",
      "208/208 [==============================] - 11s 54ms/step - loss: 3.2605 - acc: 0.0962 - val_loss: 2.3147 - val_acc: 0.1154\n",
      "Epoch 2/55\n",
      "208/208 [==============================] - 0s 589us/step - loss: 2.3406 - acc: 0.3029 - val_loss: 1.9256 - val_acc: 0.3269\n",
      "Epoch 3/55\n",
      "208/208 [==============================] - 0s 632us/step - loss: 1.7144 - acc: 0.3942 - val_loss: 1.6005 - val_acc: 0.5000\n",
      "Epoch 4/55\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "208/208 [==============================] - 0s 644us/step - loss: 1.5453 - acc: 0.4279 - val_loss: 1.6269 - val_acc: 0.5385\n",
      "Epoch 5/55\n",
      "208/208 [==============================] - 0s 627us/step - loss: 1.5589 - acc: 0.5096 - val_loss: 1.4701 - val_acc: 0.5000\n",
      "Epoch 6/55\n",
      "208/208 [==============================] - 0s 676us/step - loss: 1.1923 - acc: 0.5817 - val_loss: 1.5850 - val_acc: 0.4423\n",
      "Epoch 7/55\n",
      "208/208 [==============================] - 0s 585us/step - loss: 1.3101 - acc: 0.5577 - val_loss: 1.3253 - val_acc: 0.5769\n",
      "Epoch 8/55\n",
      "208/208 [==============================] - 0s 627us/step - loss: 0.9788 - acc: 0.6346 - val_loss: 1.2279 - val_acc: 0.5577\n",
      "Epoch 9/55\n",
      "208/208 [==============================] - 0s 807us/step - loss: 0.9346 - acc: 0.6875 - val_loss: 1.4580 - val_acc: 0.5962\n",
      "Epoch 10/55\n",
      "208/208 [==============================] - 0s 653us/step - loss: 0.8187 - acc: 0.7740 - val_loss: 1.0723 - val_acc: 0.6346\n",
      "Epoch 11/55\n",
      "208/208 [==============================] - 0s 672us/step - loss: 0.7353 - acc: 0.7596 - val_loss: 0.9954 - val_acc: 0.6731\n",
      "Epoch 12/55\n",
      "208/208 [==============================] - 0s 645us/step - loss: 0.7850 - acc: 0.7356 - val_loss: 1.0725 - val_acc: 0.5769\n",
      "Epoch 13/55\n",
      "208/208 [==============================] - 0s 579us/step - loss: 0.5560 - acc: 0.7933 - val_loss: 1.0624 - val_acc: 0.6731\n",
      "Epoch 14/55\n",
      "208/208 [==============================] - 0s 589us/step - loss: 0.5528 - acc: 0.8269 - val_loss: 1.0404 - val_acc: 0.6923\n",
      "Epoch 15/55\n",
      "208/208 [==============================] - 0s 632us/step - loss: 0.5593 - acc: 0.7885 - val_loss: 1.0953 - val_acc: 0.6923\n",
      "Epoch 16/55\n",
      "208/208 [==============================] - 0s 599us/step - loss: 0.5367 - acc: 0.8029 - val_loss: 1.0769 - val_acc: 0.6538\n",
      "Epoch 17/55\n",
      "208/208 [==============================] - 0s 654us/step - loss: 0.5666 - acc: 0.7885 - val_loss: 1.1224 - val_acc: 0.5577\n",
      "Epoch 18/55\n",
      "208/208 [==============================] - 0s 600us/step - loss: 0.4906 - acc: 0.8317 - val_loss: 0.9441 - val_acc: 0.7308\n",
      "Epoch 19/55\n",
      "208/208 [==============================] - 0s 660us/step - loss: 0.3663 - acc: 0.8846 - val_loss: 1.1912 - val_acc: 0.5769\n",
      "Epoch 20/55\n",
      "208/208 [==============================] - 0s 629us/step - loss: 0.4194 - acc: 0.8558 - val_loss: 1.0388 - val_acc: 0.6731\n",
      "Epoch 21/55\n",
      "208/208 [==============================] - 0s 638us/step - loss: 0.3789 - acc: 0.8846 - val_loss: 1.0419 - val_acc: 0.6538\n",
      "Epoch 22/55\n",
      "208/208 [==============================] - 0s 637us/step - loss: 0.3481 - acc: 0.8846 - val_loss: 1.1116 - val_acc: 0.6346\n",
      "Epoch 23/55\n",
      "208/208 [==============================] - 0s 634us/step - loss: 0.3811 - acc: 0.8750 - val_loss: 1.0658 - val_acc: 0.6154\n",
      "Epoch 24/55\n",
      "208/208 [==============================] - 0s 640us/step - loss: 0.3287 - acc: 0.9087 - val_loss: 1.0140 - val_acc: 0.6538\n",
      "Epoch 25/55\n",
      "208/208 [==============================] - 0s 659us/step - loss: 0.3323 - acc: 0.9135 - val_loss: 0.9898 - val_acc: 0.6731\n",
      "Epoch 26/55\n",
      "208/208 [==============================] - 0s 642us/step - loss: 0.2648 - acc: 0.9135 - val_loss: 1.0726 - val_acc: 0.6346\n",
      "Epoch 27/55\n",
      "208/208 [==============================] - 0s 617us/step - loss: 0.3287 - acc: 0.8846 - val_loss: 1.1590 - val_acc: 0.5385\n",
      "Epoch 28/55\n",
      "208/208 [==============================] - 0s 575us/step - loss: 0.2239 - acc: 0.9471 - val_loss: 1.0578 - val_acc: 0.6538\n",
      "Epoch 29/55\n",
      "208/208 [==============================] - 0s 550us/step - loss: 0.2009 - acc: 0.9279 - val_loss: 1.1132 - val_acc: 0.5962\n",
      "Epoch 30/55\n",
      "208/208 [==============================] - 0s 625us/step - loss: 0.2062 - acc: 0.9471 - val_loss: 1.1262 - val_acc: 0.5962\n",
      "Epoch 31/55\n",
      "208/208 [==============================] - 0s 662us/step - loss: 0.2789 - acc: 0.9183 - val_loss: 1.0692 - val_acc: 0.6731\n",
      "Epoch 32/55\n",
      "208/208 [==============================] - 0s 639us/step - loss: 0.2184 - acc: 0.9279 - val_loss: 1.0240 - val_acc: 0.6923\n",
      "Epoch 33/55\n",
      "208/208 [==============================] - 0s 627us/step - loss: 0.2189 - acc: 0.9327 - val_loss: 1.0646 - val_acc: 0.6731\n",
      "Epoch 34/55\n",
      "208/208 [==============================] - 0s 620us/step - loss: 0.2436 - acc: 0.9087 - val_loss: 0.9771 - val_acc: 0.6923\n",
      "Epoch 35/55\n",
      "208/208 [==============================] - 0s 573us/step - loss: 0.1942 - acc: 0.9567 - val_loss: 0.9814 - val_acc: 0.7115\n",
      "Epoch 36/55\n",
      "208/208 [==============================] - 0s 506us/step - loss: 0.1729 - acc: 0.9471 - val_loss: 1.0366 - val_acc: 0.6923\n",
      "Epoch 37/55\n",
      "208/208 [==============================] - 0s 519us/step - loss: 0.1804 - acc: 0.9519 - val_loss: 1.0569 - val_acc: 0.6731\n",
      "Epoch 38/55\n",
      "208/208 [==============================] - 0s 542us/step - loss: 0.1790 - acc: 0.9423 - val_loss: 1.0230 - val_acc: 0.6923\n",
      "Epoch 39/55\n",
      "208/208 [==============================] - 0s 556us/step - loss: 0.1718 - acc: 0.9471 - val_loss: 1.0703 - val_acc: 0.6923\n",
      "Epoch 40/55\n",
      "208/208 [==============================] - 0s 559us/step - loss: 0.1560 - acc: 0.9615 - val_loss: 1.1218 - val_acc: 0.6538\n",
      "Epoch 41/55\n",
      "208/208 [==============================] - 0s 615us/step - loss: 0.1338 - acc: 0.9808 - val_loss: 1.0289 - val_acc: 0.7308\n",
      "Epoch 42/55\n",
      "208/208 [==============================] - 0s 658us/step - loss: 0.1118 - acc: 0.9808 - val_loss: 1.0646 - val_acc: 0.6923\n",
      "Epoch 43/55\n",
      "208/208 [==============================] - 0s 617us/step - loss: 0.1375 - acc: 0.9663 - val_loss: 0.9974 - val_acc: 0.7308\n",
      "Epoch 44/55\n",
      "208/208 [==============================] - 0s 599us/step - loss: 0.1040 - acc: 0.9663 - val_loss: 1.0409 - val_acc: 0.6923\n",
      "Epoch 45/55\n",
      "208/208 [==============================] - 0s 638us/step - loss: 0.1217 - acc: 0.9712 - val_loss: 0.9842 - val_acc: 0.7308\n",
      "Epoch 46/55\n",
      "208/208 [==============================] - 0s 625us/step - loss: 0.1188 - acc: 0.9615 - val_loss: 1.0770 - val_acc: 0.6731\n",
      "Epoch 47/55\n",
      "208/208 [==============================] - 0s 621us/step - loss: 0.1018 - acc: 0.9808 - val_loss: 1.0334 - val_acc: 0.7308\n",
      "Epoch 48/55\n",
      "208/208 [==============================] - 0s 509us/step - loss: 0.1050 - acc: 0.9615 - val_loss: 1.0330 - val_acc: 0.7115\n",
      "Epoch 49/55\n",
      "208/208 [==============================] - 0s 547us/step - loss: 0.1066 - acc: 0.9712 - val_loss: 1.0798 - val_acc: 0.7115\n",
      "Epoch 50/55\n",
      "208/208 [==============================] - 0s 507us/step - loss: 0.0848 - acc: 0.9760 - val_loss: 1.0494 - val_acc: 0.7500\n",
      "Epoch 51/55\n",
      "208/208 [==============================] - 0s 676us/step - loss: 0.1288 - acc: 0.9663 - val_loss: 1.1887 - val_acc: 0.6538\n",
      "Epoch 52/55\n",
      "208/208 [==============================] - 0s 651us/step - loss: 0.1816 - acc: 0.9471 - val_loss: 1.2006 - val_acc: 0.6538\n",
      "Epoch 53/55\n",
      "208/208 [==============================] - 0s 634us/step - loss: 0.0859 - acc: 0.9808 - val_loss: 1.1409 - val_acc: 0.6923\n",
      "Epoch 54/55\n",
      "208/208 [==============================] - 0s 656us/step - loss: 0.0973 - acc: 0.9712 - val_loss: 1.0908 - val_acc: 0.6538\n",
      "Epoch 55/55\n",
      "208/208 [==============================] - 0s 685us/step - loss: 0.1009 - acc: 0.9760 - val_loss: 1.1053 - val_acc: 0.6731\n",
      "Train on 208 samples, validate on 52 samples\n",
      "Epoch 1/56\n",
      "208/208 [==============================] - 13s 62ms/step - loss: 3.2605 - acc: 0.0962 - val_loss: 2.3147 - val_acc: 0.1154\n",
      "Epoch 2/56\n",
      "208/208 [==============================] - 0s 498us/step - loss: 2.3406 - acc: 0.3029 - val_loss: 1.9256 - val_acc: 0.3269\n",
      "Epoch 3/56\n",
      "208/208 [==============================] - 0s 510us/step - loss: 1.7144 - acc: 0.3942 - val_loss: 1.6005 - val_acc: 0.5000\n",
      "Epoch 4/56\n",
      "208/208 [==============================] - 0s 570us/step - loss: 1.5453 - acc: 0.4279 - val_loss: 1.6269 - val_acc: 0.5385\n",
      "Epoch 5/56\n",
      "208/208 [==============================] - 0s 732us/step - loss: 1.5589 - acc: 0.5096 - val_loss: 1.4701 - val_acc: 0.5000\n",
      "Epoch 6/56\n",
      "208/208 [==============================] - 0s 938us/step - loss: 1.1923 - acc: 0.5817 - val_loss: 1.5861 - val_acc: 0.4423\n",
      "Epoch 7/56\n",
      "208/208 [==============================] - 0s 784us/step - loss: 1.3219 - acc: 0.5481 - val_loss: 1.3187 - val_acc: 0.5769\n",
      "Epoch 8/56\n",
      "208/208 [==============================] - 0s 818us/step - loss: 0.9722 - acc: 0.6442 - val_loss: 1.2494 - val_acc: 0.5385\n",
      "Epoch 9/56\n",
      "208/208 [==============================] - 0s 513us/step - loss: 0.9625 - acc: 0.6779 - val_loss: 1.4892 - val_acc: 0.5577\n",
      "Epoch 10/56\n",
      "208/208 [==============================] - 0s 504us/step - loss: 0.8382 - acc: 0.7500 - val_loss: 1.0773 - val_acc: 0.6346\n",
      "Epoch 11/56\n",
      "208/208 [==============================] - 0s 548us/step - loss: 0.7580 - acc: 0.7500 - val_loss: 0.9931 - val_acc: 0.7115\n",
      "Epoch 12/56\n",
      "208/208 [==============================] - 0s 575us/step - loss: 0.7801 - acc: 0.7260 - val_loss: 0.9947 - val_acc: 0.6923\n",
      "Epoch 13/56\n",
      "208/208 [==============================] - 0s 572us/step - loss: 0.5582 - acc: 0.7981 - val_loss: 1.0114 - val_acc: 0.6731\n",
      "Epoch 14/56\n",
      "208/208 [==============================] - 0s 606us/step - loss: 0.5624 - acc: 0.8413 - val_loss: 1.0143 - val_acc: 0.6731\n",
      "Epoch 15/56\n",
      "208/208 [==============================] - 0s 603us/step - loss: 0.5435 - acc: 0.8029 - val_loss: 1.1428 - val_acc: 0.6731\n",
      "Epoch 16/56\n",
      "208/208 [==============================] - 0s 576us/step - loss: 0.5309 - acc: 0.8173 - val_loss: 1.0679 - val_acc: 0.6923\n",
      "Epoch 17/56\n",
      "208/208 [==============================] - 0s 584us/step - loss: 0.5639 - acc: 0.7981 - val_loss: 1.0722 - val_acc: 0.6154\n",
      "Epoch 18/56\n",
      "208/208 [==============================] - 0s 583us/step - loss: 0.4680 - acc: 0.8558 - val_loss: 0.9244 - val_acc: 0.7308\n",
      "Epoch 19/56\n",
      "208/208 [==============================] - 0s 584us/step - loss: 0.3742 - acc: 0.8798 - val_loss: 1.2505 - val_acc: 0.5962\n",
      "Epoch 20/56\n",
      "208/208 [==============================] - 0s 518us/step - loss: 0.4280 - acc: 0.8654 - val_loss: 1.0473 - val_acc: 0.6538\n",
      "Epoch 21/56\n",
      "208/208 [==============================] - 0s 510us/step - loss: 0.3755 - acc: 0.8750 - val_loss: 1.0565 - val_acc: 0.6538\n",
      "Epoch 22/56\n",
      "208/208 [==============================] - 0s 512us/step - loss: 0.3389 - acc: 0.8894 - val_loss: 1.0448 - val_acc: 0.6731\n",
      "Epoch 23/56\n",
      "208/208 [==============================] - 0s 493us/step - loss: 0.3681 - acc: 0.8702 - val_loss: 1.0520 - val_acc: 0.6731\n",
      "Epoch 24/56\n",
      "208/208 [==============================] - 0s 495us/step - loss: 0.3329 - acc: 0.8894 - val_loss: 0.9772 - val_acc: 0.6538\n",
      "Epoch 25/56\n",
      "208/208 [==============================] - 0s 515us/step - loss: 0.3314 - acc: 0.9038 - val_loss: 0.9664 - val_acc: 0.6923\n",
      "Epoch 26/56\n",
      "208/208 [==============================] - 0s 497us/step - loss: 0.2690 - acc: 0.9183 - val_loss: 1.0211 - val_acc: 0.6154\n",
      "Epoch 27/56\n",
      "208/208 [==============================] - 0s 512us/step - loss: 0.3156 - acc: 0.8894 - val_loss: 1.1731 - val_acc: 0.5769\n",
      "Epoch 28/56\n",
      "208/208 [==============================] - 0s 539us/step - loss: 0.2343 - acc: 0.9423 - val_loss: 1.0553 - val_acc: 0.6538\n",
      "Epoch 29/56\n",
      "208/208 [==============================] - 0s 624us/step - loss: 0.2106 - acc: 0.9423 - val_loss: 1.0916 - val_acc: 0.6154\n",
      "Epoch 30/56\n",
      "208/208 [==============================] - 0s 613us/step - loss: 0.2092 - acc: 0.9375 - val_loss: 1.1297 - val_acc: 0.5962\n",
      "Epoch 31/56\n",
      "208/208 [==============================] - 0s 542us/step - loss: 0.2862 - acc: 0.9087 - val_loss: 1.0854 - val_acc: 0.6923\n",
      "Epoch 32/56\n",
      "208/208 [==============================] - 0s 572us/step - loss: 0.2238 - acc: 0.9279 - val_loss: 1.0514 - val_acc: 0.6923\n",
      "Epoch 33/56\n",
      "208/208 [==============================] - 0s 522us/step - loss: 0.2183 - acc: 0.9231 - val_loss: 1.0584 - val_acc: 0.6923\n",
      "Epoch 34/56\n",
      "208/208 [==============================] - 0s 513us/step - loss: 0.2282 - acc: 0.9231 - val_loss: 1.0095 - val_acc: 0.6731\n",
      "Epoch 35/56\n",
      "208/208 [==============================] - 0s 509us/step - loss: 0.1926 - acc: 0.9567 - val_loss: 0.9813 - val_acc: 0.7308\n",
      "Epoch 36/56\n",
      "208/208 [==============================] - 0s 563us/step - loss: 0.1729 - acc: 0.9519 - val_loss: 1.0404 - val_acc: 0.6731\n",
      "Epoch 37/56\n",
      "208/208 [==============================] - 0s 538us/step - loss: 0.1896 - acc: 0.9615 - val_loss: 1.0847 - val_acc: 0.6923\n",
      "Epoch 38/56\n",
      "208/208 [==============================] - 0s 510us/step - loss: 0.1704 - acc: 0.9519 - val_loss: 1.0338 - val_acc: 0.7500\n",
      "Epoch 39/56\n",
      "208/208 [==============================] - 0s 505us/step - loss: 0.1750 - acc: 0.9375 - val_loss: 1.0947 - val_acc: 0.6923\n",
      "Epoch 40/56\n",
      "208/208 [==============================] - 0s 524us/step - loss: 0.1556 - acc: 0.9615 - val_loss: 1.1441 - val_acc: 0.6538\n",
      "Epoch 41/56\n",
      "208/208 [==============================] - 0s 515us/step - loss: 0.1422 - acc: 0.9712 - val_loss: 1.0238 - val_acc: 0.7115\n",
      "Epoch 42/56\n",
      "208/208 [==============================] - 0s 513us/step - loss: 0.1034 - acc: 0.9856 - val_loss: 1.0888 - val_acc: 0.6731\n",
      "Epoch 43/56\n",
      "208/208 [==============================] - 0s 494us/step - loss: 0.1495 - acc: 0.9712 - val_loss: 1.0019 - val_acc: 0.7308\n",
      "Epoch 44/56\n",
      "208/208 [==============================] - 0s 516us/step - loss: 0.1071 - acc: 0.9712 - val_loss: 1.0413 - val_acc: 0.6923\n",
      "Epoch 45/56\n",
      "208/208 [==============================] - 0s 520us/step - loss: 0.1200 - acc: 0.9760 - val_loss: 0.9984 - val_acc: 0.7308\n",
      "Epoch 46/56\n",
      "208/208 [==============================] - 0s 506us/step - loss: 0.1151 - acc: 0.9663 - val_loss: 1.0610 - val_acc: 0.7308\n",
      "Epoch 47/56\n",
      "208/208 [==============================] - 0s 510us/step - loss: 0.0997 - acc: 0.9760 - val_loss: 1.0633 - val_acc: 0.7308\n",
      "Epoch 48/56\n",
      "208/208 [==============================] - 0s 533us/step - loss: 0.1223 - acc: 0.9519 - val_loss: 1.0101 - val_acc: 0.7308\n",
      "Epoch 49/56\n",
      "208/208 [==============================] - 0s 512us/step - loss: 0.1091 - acc: 0.9615 - val_loss: 1.1109 - val_acc: 0.6731\n",
      "Epoch 50/56\n",
      "208/208 [==============================] - 0s 566us/step - loss: 0.0818 - acc: 0.9904 - val_loss: 1.0568 - val_acc: 0.7500\n",
      "Epoch 51/56\n",
      "208/208 [==============================] - 0s 582us/step - loss: 0.1247 - acc: 0.9567 - val_loss: 1.1178 - val_acc: 0.7115\n",
      "Epoch 52/56\n",
      "208/208 [==============================] - 0s 567us/step - loss: 0.1516 - acc: 0.9567 - val_loss: 1.2887 - val_acc: 0.6346\n",
      "Epoch 53/56\n",
      "208/208 [==============================] - 0s 591us/step - loss: 0.0916 - acc: 0.9808 - val_loss: 1.1408 - val_acc: 0.7115\n",
      "Epoch 54/56\n",
      "208/208 [==============================] - 0s 579us/step - loss: 0.1385 - acc: 0.9567 - val_loss: 1.1055 - val_acc: 0.6923\n",
      "Epoch 55/56\n",
      "208/208 [==============================] - 0s 554us/step - loss: 0.1102 - acc: 0.9663 - val_loss: 1.1422 - val_acc: 0.6731\n",
      "Epoch 56/56\n",
      "208/208 [==============================] - 0s 538us/step - loss: 0.1105 - acc: 0.9615 - val_loss: 1.2013 - val_acc: 0.6731\n",
      "Train on 208 samples, validate on 52 samples\n",
      "Epoch 1/57\n",
      "208/208 [==============================] - 12s 58ms/step - loss: 3.2605 - acc: 0.0962 - val_loss: 2.3147 - val_acc: 0.1154\n",
      "Epoch 2/57\n",
      "208/208 [==============================] - 0s 708us/step - loss: 2.3406 - acc: 0.3029 - val_loss: 1.9256 - val_acc: 0.3269\n",
      "Epoch 3/57\n",
      "208/208 [==============================] - 0s 733us/step - loss: 1.7144 - acc: 0.3942 - val_loss: 1.6005 - val_acc: 0.5000\n",
      "Epoch 4/57\n",
      "208/208 [==============================] - 0s 744us/step - loss: 1.5455 - acc: 0.4231 - val_loss: 1.6431 - val_acc: 0.5000\n",
      "Epoch 5/57\n",
      "208/208 [==============================] - 0s 708us/step - loss: 1.5772 - acc: 0.5096 - val_loss: 1.4689 - val_acc: 0.5000\n",
      "Epoch 6/57\n",
      "208/208 [==============================] - 0s 724us/step - loss: 1.1651 - acc: 0.5865 - val_loss: 1.5270 - val_acc: 0.5000\n",
      "Epoch 7/57\n",
      "208/208 [==============================] - 0s 627us/step - loss: 1.2974 - acc: 0.5288 - val_loss: 1.3276 - val_acc: 0.5769\n",
      "Epoch 8/57\n",
      "208/208 [==============================] - 0s 672us/step - loss: 1.0425 - acc: 0.6250 - val_loss: 1.2728 - val_acc: 0.5769\n",
      "Epoch 9/57\n",
      "208/208 [==============================] - 0s 669us/step - loss: 0.9139 - acc: 0.7115 - val_loss: 1.3234 - val_acc: 0.5769\n",
      "Epoch 10/57\n",
      "208/208 [==============================] - 0s 791us/step - loss: 0.7263 - acc: 0.7837 - val_loss: 1.0496 - val_acc: 0.6538\n",
      "Epoch 11/57\n",
      "208/208 [==============================] - 0s 756us/step - loss: 0.7456 - acc: 0.7692 - val_loss: 0.9746 - val_acc: 0.7115\n",
      "Epoch 12/57\n",
      "208/208 [==============================] - 0s 848us/step - loss: 0.7591 - acc: 0.7452 - val_loss: 1.0729 - val_acc: 0.6154\n",
      "Epoch 13/57\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "208/208 [==============================] - 0s 721us/step - loss: 0.5968 - acc: 0.7885 - val_loss: 1.0990 - val_acc: 0.6154\n",
      "Epoch 14/57\n",
      "208/208 [==============================] - 0s 544us/step - loss: 0.5958 - acc: 0.8029 - val_loss: 1.0548 - val_acc: 0.6923\n",
      "Epoch 15/57\n",
      "208/208 [==============================] - 0s 574us/step - loss: 0.5670 - acc: 0.8125 - val_loss: 1.1252 - val_acc: 0.6346\n",
      "Epoch 16/57\n",
      "208/208 [==============================] - 0s 518us/step - loss: 0.5396 - acc: 0.8317 - val_loss: 1.0311 - val_acc: 0.7115\n",
      "Epoch 17/57\n",
      "208/208 [==============================] - 0s 529us/step - loss: 0.5489 - acc: 0.8173 - val_loss: 1.0898 - val_acc: 0.5962\n",
      "Epoch 18/57\n",
      "208/208 [==============================] - 0s 660us/step - loss: 0.4960 - acc: 0.8413 - val_loss: 0.9509 - val_acc: 0.6923\n",
      "Epoch 19/57\n",
      "208/208 [==============================] - 0s 840us/step - loss: 0.3421 - acc: 0.8990 - val_loss: 1.2420 - val_acc: 0.5577\n",
      "Epoch 20/57\n",
      "208/208 [==============================] - 0s 527us/step - loss: 0.4094 - acc: 0.8654 - val_loss: 1.0372 - val_acc: 0.6923\n",
      "Epoch 21/57\n",
      "208/208 [==============================] - 0s 505us/step - loss: 0.3905 - acc: 0.8798 - val_loss: 1.0584 - val_acc: 0.6538\n",
      "Epoch 22/57\n",
      "208/208 [==============================] - 0s 513us/step - loss: 0.3513 - acc: 0.8846 - val_loss: 1.1051 - val_acc: 0.6538\n",
      "Epoch 23/57\n",
      "208/208 [==============================] - 0s 593us/step - loss: 0.3707 - acc: 0.8798 - val_loss: 1.0145 - val_acc: 0.6731\n",
      "Epoch 24/57\n",
      "208/208 [==============================] - 0s 617us/step - loss: 0.3473 - acc: 0.8942 - val_loss: 1.1175 - val_acc: 0.5962\n",
      "Epoch 25/57\n",
      "208/208 [==============================] - 0s 1ms/step - loss: 0.3478 - acc: 0.8990 - val_loss: 0.9794 - val_acc: 0.6731\n",
      "Epoch 26/57\n",
      "208/208 [==============================] - 0s 583us/step - loss: 0.2796 - acc: 0.8942 - val_loss: 1.0272 - val_acc: 0.6731\n",
      "Epoch 27/57\n",
      "208/208 [==============================] - 0s 886us/step - loss: 0.3011 - acc: 0.9087 - val_loss: 1.1754 - val_acc: 0.5769\n",
      "Epoch 28/57\n",
      "208/208 [==============================] - 0s 600us/step - loss: 0.2246 - acc: 0.9375 - val_loss: 1.0412 - val_acc: 0.6538\n",
      "Epoch 29/57\n",
      "208/208 [==============================] - 0s 520us/step - loss: 0.2048 - acc: 0.9423 - val_loss: 1.1133 - val_acc: 0.5962\n",
      "Epoch 30/57\n",
      "208/208 [==============================] - 0s 530us/step - loss: 0.1900 - acc: 0.9567 - val_loss: 1.1145 - val_acc: 0.5962\n",
      "Epoch 31/57\n",
      "208/208 [==============================] - 0s 546us/step - loss: 0.2661 - acc: 0.9038 - val_loss: 1.0528 - val_acc: 0.7115\n",
      "Epoch 32/57\n",
      "208/208 [==============================] - 0s 689us/step - loss: 0.2248 - acc: 0.9231 - val_loss: 1.0293 - val_acc: 0.6731\n",
      "Epoch 33/57\n",
      "208/208 [==============================] - 0s 591us/step - loss: 0.2259 - acc: 0.9375 - val_loss: 1.0910 - val_acc: 0.6923\n",
      "Epoch 34/57\n",
      "208/208 [==============================] - 0s 827us/step - loss: 0.2427 - acc: 0.9135 - val_loss: 1.0317 - val_acc: 0.6731\n",
      "Epoch 35/57\n",
      "208/208 [==============================] - 0s 842us/step - loss: 0.1832 - acc: 0.9567 - val_loss: 1.0092 - val_acc: 0.7308\n",
      "Epoch 36/57\n",
      "208/208 [==============================] - 0s 698us/step - loss: 0.1582 - acc: 0.9663 - val_loss: 1.0725 - val_acc: 0.6538\n",
      "Epoch 37/57\n",
      "208/208 [==============================] - 0s 672us/step - loss: 0.1789 - acc: 0.9663 - val_loss: 1.0778 - val_acc: 0.6731\n",
      "Epoch 38/57\n",
      "208/208 [==============================] - 0s 827us/step - loss: 0.1775 - acc: 0.9519 - val_loss: 1.0288 - val_acc: 0.7500\n",
      "Epoch 39/57\n",
      "208/208 [==============================] - 0s 792us/step - loss: 0.1821 - acc: 0.9183 - val_loss: 1.1018 - val_acc: 0.6731\n",
      "Epoch 40/57\n",
      "208/208 [==============================] - 0s 911us/step - loss: 0.1570 - acc: 0.9471 - val_loss: 1.1202 - val_acc: 0.6538\n",
      "Epoch 41/57\n",
      "208/208 [==============================] - 0s 792us/step - loss: 0.1348 - acc: 0.9712 - val_loss: 1.0370 - val_acc: 0.7308\n",
      "Epoch 42/57\n",
      "208/208 [==============================] - 0s 701us/step - loss: 0.1073 - acc: 0.9808 - val_loss: 1.0728 - val_acc: 0.6731\n",
      "Epoch 43/57\n",
      "208/208 [==============================] - 0s 778us/step - loss: 0.1344 - acc: 0.9615 - val_loss: 1.0417 - val_acc: 0.7115\n",
      "Epoch 44/57\n",
      "208/208 [==============================] - 0s 935us/step - loss: 0.0971 - acc: 0.9760 - val_loss: 1.0703 - val_acc: 0.7115\n",
      "Epoch 45/57\n",
      "208/208 [==============================] - 0s 1ms/step - loss: 0.1194 - acc: 0.9760 - val_loss: 1.0191 - val_acc: 0.7115\n",
      "Epoch 46/57\n",
      "208/208 [==============================] - 0s 729us/step - loss: 0.1182 - acc: 0.9663 - val_loss: 1.0997 - val_acc: 0.6923\n",
      "Epoch 47/57\n",
      "208/208 [==============================] - 0s 757us/step - loss: 0.1051 - acc: 0.9760 - val_loss: 1.0481 - val_acc: 0.7308\n",
      "Epoch 48/57\n",
      "208/208 [==============================] - 0s 721us/step - loss: 0.1170 - acc: 0.9567 - val_loss: 1.0620 - val_acc: 0.7308\n",
      "Epoch 49/57\n",
      "208/208 [==============================] - 0s 848us/step - loss: 0.1066 - acc: 0.9663 - val_loss: 1.1413 - val_acc: 0.6731\n",
      "Epoch 50/57\n",
      "208/208 [==============================] - 0s 894us/step - loss: 0.0850 - acc: 0.9808 - val_loss: 1.0950 - val_acc: 0.7308\n",
      "Epoch 51/57\n",
      "208/208 [==============================] - 0s 770us/step - loss: 0.1322 - acc: 0.9615 - val_loss: 1.2235 - val_acc: 0.6154\n",
      "Epoch 52/57\n",
      "208/208 [==============================] - 0s 675us/step - loss: 0.1725 - acc: 0.9519 - val_loss: 1.2561 - val_acc: 0.6538\n",
      "Epoch 53/57\n",
      "208/208 [==============================] - 0s 823us/step - loss: 0.0838 - acc: 0.9856 - val_loss: 1.1701 - val_acc: 0.7115\n",
      "Epoch 54/57\n",
      "208/208 [==============================] - 0s 813us/step - loss: 0.1130 - acc: 0.9712 - val_loss: 1.1336 - val_acc: 0.6923\n",
      "Epoch 55/57\n",
      "208/208 [==============================] - 0s 793us/step - loss: 0.1020 - acc: 0.9615 - val_loss: 1.1599 - val_acc: 0.6923\n",
      "Epoch 56/57\n",
      "208/208 [==============================] - 0s 753us/step - loss: 0.0976 - acc: 0.9663 - val_loss: 1.1998 - val_acc: 0.6731\n",
      "Epoch 57/57\n",
      "208/208 [==============================] - 0s 709us/step - loss: 0.0926 - acc: 0.9760 - val_loss: 1.2274 - val_acc: 0.6346\n",
      "Train on 208 samples, validate on 52 samples\n",
      "Epoch 1/58\n",
      "208/208 [==============================] - 13s 61ms/step - loss: 3.2605 - acc: 0.0962 - val_loss: 2.3147 - val_acc: 0.1154\n",
      "Epoch 2/58\n",
      "208/208 [==============================] - 0s 785us/step - loss: 2.3406 - acc: 0.3029 - val_loss: 1.9256 - val_acc: 0.3269\n",
      "Epoch 3/58\n",
      "208/208 [==============================] - 0s 900us/step - loss: 1.7144 - acc: 0.3942 - val_loss: 1.6005 - val_acc: 0.5000\n",
      "Epoch 4/58\n",
      "208/208 [==============================] - 0s 809us/step - loss: 1.5453 - acc: 0.4279 - val_loss: 1.6269 - val_acc: 0.5385\n",
      "Epoch 5/58\n",
      "208/208 [==============================] - 0s 507us/step - loss: 1.5589 - acc: 0.5096 - val_loss: 1.4701 - val_acc: 0.5000\n",
      "Epoch 6/58\n",
      "208/208 [==============================] - 0s 502us/step - loss: 1.1923 - acc: 0.5817 - val_loss: 1.5850 - val_acc: 0.4423\n",
      "Epoch 7/58\n",
      "208/208 [==============================] - 0s 557us/step - loss: 1.3101 - acc: 0.5577 - val_loss: 1.3253 - val_acc: 0.5769\n",
      "Epoch 8/58\n",
      "208/208 [==============================] - 0s 512us/step - loss: 0.9784 - acc: 0.6346 - val_loss: 1.2231 - val_acc: 0.5577\n",
      "Epoch 9/58\n",
      "208/208 [==============================] - 0s 518us/step - loss: 0.9378 - acc: 0.6875 - val_loss: 1.4788 - val_acc: 0.5962\n",
      "Epoch 10/58\n",
      "208/208 [==============================] - 0s 538us/step - loss: 0.8412 - acc: 0.7644 - val_loss: 1.0737 - val_acc: 0.6731\n",
      "Epoch 11/58\n",
      "208/208 [==============================] - 0s 573us/step - loss: 0.7359 - acc: 0.7644 - val_loss: 0.9912 - val_acc: 0.6731\n",
      "Epoch 12/58\n",
      "208/208 [==============================] - 0s 533us/step - loss: 0.7783 - acc: 0.7212 - val_loss: 1.0613 - val_acc: 0.6346\n",
      "Epoch 13/58\n",
      "208/208 [==============================] - 0s 572us/step - loss: 0.5550 - acc: 0.7981 - val_loss: 1.0383 - val_acc: 0.6731\n",
      "Epoch 14/58\n",
      "208/208 [==============================] - 0s 533us/step - loss: 0.5591 - acc: 0.8269 - val_loss: 1.0219 - val_acc: 0.6923\n",
      "Epoch 15/58\n",
      "208/208 [==============================] - 0s 662us/step - loss: 0.5610 - acc: 0.7981 - val_loss: 1.1052 - val_acc: 0.6731\n",
      "Epoch 16/58\n",
      "208/208 [==============================] - 0s 678us/step - loss: 0.5347 - acc: 0.8077 - val_loss: 1.0539 - val_acc: 0.6923\n",
      "Epoch 17/58\n",
      "208/208 [==============================] - 0s 647us/step - loss: 0.5492 - acc: 0.7788 - val_loss: 1.1258 - val_acc: 0.5769\n",
      "Epoch 18/58\n",
      "208/208 [==============================] - 0s 553us/step - loss: 0.4777 - acc: 0.8462 - val_loss: 0.9395 - val_acc: 0.7308\n",
      "Epoch 19/58\n",
      "208/208 [==============================] - 0s 622us/step - loss: 0.3823 - acc: 0.8750 - val_loss: 1.2133 - val_acc: 0.5769\n",
      "Epoch 20/58\n",
      "208/208 [==============================] - 0s 572us/step - loss: 0.4180 - acc: 0.8654 - val_loss: 1.0180 - val_acc: 0.6923\n",
      "Epoch 21/58\n",
      "208/208 [==============================] - 0s 605us/step - loss: 0.3784 - acc: 0.8750 - val_loss: 1.0430 - val_acc: 0.6731\n",
      "Epoch 22/58\n",
      "208/208 [==============================] - 0s 585us/step - loss: 0.3449 - acc: 0.8942 - val_loss: 1.0623 - val_acc: 0.6538\n",
      "Epoch 23/58\n",
      "208/208 [==============================] - 0s 629us/step - loss: 0.3622 - acc: 0.9038 - val_loss: 1.0593 - val_acc: 0.6346\n",
      "Epoch 24/58\n",
      "208/208 [==============================] - 0s 590us/step - loss: 0.3218 - acc: 0.8942 - val_loss: 0.9777 - val_acc: 0.6731\n",
      "Epoch 25/58\n",
      "208/208 [==============================] - 0s 628us/step - loss: 0.3497 - acc: 0.8894 - val_loss: 0.9874 - val_acc: 0.6923\n",
      "Epoch 26/58\n",
      "208/208 [==============================] - 0s 581us/step - loss: 0.2712 - acc: 0.9038 - val_loss: 1.0343 - val_acc: 0.6154\n",
      "Epoch 27/58\n",
      "208/208 [==============================] - 0s 609us/step - loss: 0.3171 - acc: 0.8846 - val_loss: 1.1591 - val_acc: 0.5769\n",
      "Epoch 28/58\n",
      "208/208 [==============================] - 0s 559us/step - loss: 0.2419 - acc: 0.9423 - val_loss: 1.0511 - val_acc: 0.6538\n",
      "Epoch 29/58\n",
      "208/208 [==============================] - 0s 635us/step - loss: 0.2076 - acc: 0.9519 - val_loss: 1.1050 - val_acc: 0.6154\n",
      "Epoch 30/58\n",
      "208/208 [==============================] - 0s 579us/step - loss: 0.2072 - acc: 0.9279 - val_loss: 1.1202 - val_acc: 0.5962\n",
      "Epoch 31/58\n",
      "208/208 [==============================] - 0s 622us/step - loss: 0.2718 - acc: 0.9135 - val_loss: 1.0803 - val_acc: 0.6923\n",
      "Epoch 32/58\n",
      "208/208 [==============================] - 0s 577us/step - loss: 0.2277 - acc: 0.9327 - val_loss: 1.0434 - val_acc: 0.6923\n",
      "Epoch 33/58\n",
      "208/208 [==============================] - 0s 610us/step - loss: 0.2277 - acc: 0.9279 - val_loss: 1.0874 - val_acc: 0.6346\n",
      "Epoch 34/58\n",
      "208/208 [==============================] - 0s 567us/step - loss: 0.2366 - acc: 0.9135 - val_loss: 0.9903 - val_acc: 0.7115\n",
      "Epoch 35/58\n",
      "208/208 [==============================] - 0s 626us/step - loss: 0.2080 - acc: 0.9519 - val_loss: 0.9911 - val_acc: 0.7308\n",
      "Epoch 36/58\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 0.1730 - acc: 0.9423 - val_loss: 1.0443 - val_acc: 0.6923\n",
      "Epoch 37/58\n",
      "208/208 [==============================] - 0s 581us/step - loss: 0.1789 - acc: 0.9712 - val_loss: 1.0724 - val_acc: 0.6923\n",
      "Epoch 38/58\n",
      "208/208 [==============================] - 0s 600us/step - loss: 0.1757 - acc: 0.9471 - val_loss: 1.0261 - val_acc: 0.7308\n",
      "Epoch 39/58\n",
      "208/208 [==============================] - 0s 583us/step - loss: 0.1860 - acc: 0.9279 - val_loss: 1.0939 - val_acc: 0.6731\n",
      "Epoch 40/58\n",
      "208/208 [==============================] - 0s 621us/step - loss: 0.1633 - acc: 0.9615 - val_loss: 1.1517 - val_acc: 0.6346\n",
      "Epoch 41/58\n",
      "208/208 [==============================] - 0s 582us/step - loss: 0.1419 - acc: 0.9808 - val_loss: 1.0002 - val_acc: 0.7308\n",
      "Epoch 42/58\n",
      "208/208 [==============================] - 0s 614us/step - loss: 0.1081 - acc: 0.9952 - val_loss: 1.0813 - val_acc: 0.6731\n",
      "Epoch 43/58\n",
      "208/208 [==============================] - 0s 584us/step - loss: 0.1497 - acc: 0.9567 - val_loss: 0.9908 - val_acc: 0.7115\n",
      "Epoch 44/58\n",
      "208/208 [==============================] - 0s 626us/step - loss: 0.0988 - acc: 0.9712 - val_loss: 1.0554 - val_acc: 0.6923\n",
      "Epoch 45/58\n",
      "208/208 [==============================] - 0s 569us/step - loss: 0.1233 - acc: 0.9808 - val_loss: 0.9934 - val_acc: 0.7115\n",
      "Epoch 46/58\n",
      "208/208 [==============================] - 0s 630us/step - loss: 0.1168 - acc: 0.9663 - val_loss: 1.0626 - val_acc: 0.7115\n",
      "Epoch 47/58\n",
      "208/208 [==============================] - 0s 580us/step - loss: 0.1046 - acc: 0.9856 - val_loss: 1.0368 - val_acc: 0.7500\n",
      "Epoch 48/58\n",
      "208/208 [==============================] - 0s 580us/step - loss: 0.1100 - acc: 0.9519 - val_loss: 1.0449 - val_acc: 0.7115\n",
      "Epoch 49/58\n",
      "208/208 [==============================] - 0s 571us/step - loss: 0.1091 - acc: 0.9615 - val_loss: 1.0963 - val_acc: 0.7115\n",
      "Epoch 50/58\n",
      "208/208 [==============================] - 0s 609us/step - loss: 0.0797 - acc: 0.9856 - val_loss: 1.0547 - val_acc: 0.7308\n",
      "Epoch 51/58\n",
      "208/208 [==============================] - 0s 591us/step - loss: 0.1250 - acc: 0.9663 - val_loss: 1.1390 - val_acc: 0.7115\n",
      "Epoch 52/58\n",
      "208/208 [==============================] - 0s 637us/step - loss: 0.1562 - acc: 0.9519 - val_loss: 1.2474 - val_acc: 0.6538\n",
      "Epoch 53/58\n",
      "208/208 [==============================] - 0s 597us/step - loss: 0.0920 - acc: 0.9760 - val_loss: 1.1572 - val_acc: 0.6923\n",
      "Epoch 54/58\n",
      "208/208 [==============================] - 0s 624us/step - loss: 0.1249 - acc: 0.9663 - val_loss: 1.1328 - val_acc: 0.6731\n",
      "Epoch 55/58\n",
      "208/208 [==============================] - 0s 580us/step - loss: 0.1077 - acc: 0.9663 - val_loss: 1.1455 - val_acc: 0.6731\n",
      "Epoch 56/58\n",
      "208/208 [==============================] - 0s 581us/step - loss: 0.1125 - acc: 0.9663 - val_loss: 1.1747 - val_acc: 0.6731\n",
      "Epoch 57/58\n",
      "208/208 [==============================] - 0s 601us/step - loss: 0.1025 - acc: 0.9712 - val_loss: 1.2061 - val_acc: 0.6538\n",
      "Epoch 58/58\n",
      "208/208 [==============================] - 0s 626us/step - loss: 0.0788 - acc: 0.9808 - val_loss: 1.1317 - val_acc: 0.6923\n",
      "Train on 208 samples, validate on 52 samples\n",
      "Epoch 1/59\n",
      "208/208 [==============================] - 12s 58ms/step - loss: 3.2605 - acc: 0.0962 - val_loss: 2.3147 - val_acc: 0.1154\n",
      "Epoch 2/59\n",
      "208/208 [==============================] - 0s 595us/step - loss: 2.3406 - acc: 0.3029 - val_loss: 1.9256 - val_acc: 0.3269\n",
      "Epoch 3/59\n",
      "208/208 [==============================] - 0s 628us/step - loss: 1.7144 - acc: 0.3942 - val_loss: 1.6005 - val_acc: 0.5000\n",
      "Epoch 4/59\n",
      "208/208 [==============================] - 0s 618us/step - loss: 1.5453 - acc: 0.4279 - val_loss: 1.6269 - val_acc: 0.5385\n",
      "Epoch 5/59\n",
      "208/208 [==============================] - 0s 604us/step - loss: 1.5589 - acc: 0.5096 - val_loss: 1.4702 - val_acc: 0.5000\n",
      "Epoch 6/59\n",
      "208/208 [==============================] - 0s 606us/step - loss: 1.1923 - acc: 0.5817 - val_loss: 1.5855 - val_acc: 0.4423\n",
      "Epoch 7/59\n",
      "208/208 [==============================] - 0s 597us/step - loss: 1.3104 - acc: 0.5577 - val_loss: 1.3251 - val_acc: 0.5769\n",
      "Epoch 8/59\n",
      "208/208 [==============================] - 0s 568us/step - loss: 0.9784 - acc: 0.6346 - val_loss: 1.2250 - val_acc: 0.5769\n",
      "Epoch 9/59\n",
      "208/208 [==============================] - 0s 600us/step - loss: 0.9322 - acc: 0.6923 - val_loss: 1.4578 - val_acc: 0.5769\n",
      "Epoch 10/59\n",
      "208/208 [==============================] - 0s 596us/step - loss: 0.8167 - acc: 0.7740 - val_loss: 1.0824 - val_acc: 0.6538\n",
      "Epoch 11/59\n",
      "208/208 [==============================] - 0s 583us/step - loss: 0.7380 - acc: 0.7692 - val_loss: 1.0001 - val_acc: 0.6538\n",
      "Epoch 12/59\n",
      "208/208 [==============================] - 0s 585us/step - loss: 0.7847 - acc: 0.7212 - val_loss: 1.0838 - val_acc: 0.6346\n",
      "Epoch 13/59\n",
      "208/208 [==============================] - 0s 591us/step - loss: 0.5521 - acc: 0.8077 - val_loss: 1.0559 - val_acc: 0.6538\n",
      "Epoch 14/59\n",
      "208/208 [==============================] - 0s 581us/step - loss: 0.5514 - acc: 0.8317 - val_loss: 1.0236 - val_acc: 0.6923\n",
      "Epoch 15/59\n",
      "208/208 [==============================] - 0s 572us/step - loss: 0.5764 - acc: 0.7885 - val_loss: 1.1103 - val_acc: 0.6731\n",
      "Epoch 16/59\n",
      "208/208 [==============================] - 0s 540us/step - loss: 0.5401 - acc: 0.8029 - val_loss: 1.0535 - val_acc: 0.6923\n",
      "Epoch 17/59\n",
      "208/208 [==============================] - 0s 564us/step - loss: 0.5590 - acc: 0.8125 - val_loss: 1.0642 - val_acc: 0.5962\n",
      "Epoch 18/59\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "208/208 [==============================] - 0s 575us/step - loss: 0.4699 - acc: 0.8558 - val_loss: 0.9295 - val_acc: 0.7115\n",
      "Epoch 19/59\n",
      "208/208 [==============================] - 0s 593us/step - loss: 0.3824 - acc: 0.8846 - val_loss: 1.2110 - val_acc: 0.5769\n",
      "Epoch 20/59\n",
      "208/208 [==============================] - 0s 584us/step - loss: 0.4201 - acc: 0.8606 - val_loss: 1.0219 - val_acc: 0.6923\n",
      "Epoch 21/59\n",
      "208/208 [==============================] - 0s 585us/step - loss: 0.3873 - acc: 0.8846 - val_loss: 1.0464 - val_acc: 0.6731\n",
      "Epoch 22/59\n",
      "208/208 [==============================] - 0s 565us/step - loss: 0.3447 - acc: 0.8894 - val_loss: 1.1319 - val_acc: 0.6154\n",
      "Epoch 23/59\n",
      "208/208 [==============================] - 0s 560us/step - loss: 0.4162 - acc: 0.8606 - val_loss: 1.0956 - val_acc: 0.5962\n",
      "Epoch 24/59\n",
      "208/208 [==============================] - 0s 561us/step - loss: 0.3356 - acc: 0.8942 - val_loss: 0.9753 - val_acc: 0.6538\n",
      "Epoch 25/59\n",
      "208/208 [==============================] - 0s 578us/step - loss: 0.3298 - acc: 0.8942 - val_loss: 0.9692 - val_acc: 0.6923\n",
      "Epoch 26/59\n",
      "208/208 [==============================] - 0s 569us/step - loss: 0.2706 - acc: 0.9087 - val_loss: 1.0264 - val_acc: 0.6346\n",
      "Epoch 27/59\n",
      "208/208 [==============================] - 0s 579us/step - loss: 0.3196 - acc: 0.8798 - val_loss: 1.1694 - val_acc: 0.5385\n",
      "Epoch 28/59\n",
      "208/208 [==============================] - 0s 588us/step - loss: 0.2346 - acc: 0.9423 - val_loss: 1.0692 - val_acc: 0.6538\n",
      "Epoch 29/59\n",
      "208/208 [==============================] - 0s 562us/step - loss: 0.2051 - acc: 0.9375 - val_loss: 1.1044 - val_acc: 0.6154\n",
      "Epoch 30/59\n",
      "208/208 [==============================] - 0s 569us/step - loss: 0.2087 - acc: 0.9471 - val_loss: 1.1212 - val_acc: 0.5769\n",
      "Epoch 31/59\n",
      "208/208 [==============================] - 0s 589us/step - loss: 0.2870 - acc: 0.9087 - val_loss: 1.0489 - val_acc: 0.6923\n",
      "Epoch 32/59\n",
      "208/208 [==============================] - 0s 589us/step - loss: 0.2255 - acc: 0.9183 - val_loss: 1.0170 - val_acc: 0.6731\n",
      "Epoch 33/59\n",
      "208/208 [==============================] - 0s 572us/step - loss: 0.2187 - acc: 0.9327 - val_loss: 1.0635 - val_acc: 0.6538\n",
      "Epoch 34/59\n",
      "208/208 [==============================] - 0s 572us/step - loss: 0.2324 - acc: 0.9183 - val_loss: 0.9835 - val_acc: 0.7115\n",
      "Epoch 35/59\n",
      "208/208 [==============================] - 0s 574us/step - loss: 0.1926 - acc: 0.9519 - val_loss: 0.9555 - val_acc: 0.7500\n",
      "Epoch 36/59\n",
      "208/208 [==============================] - 0s 578us/step - loss: 0.1786 - acc: 0.9567 - val_loss: 1.0181 - val_acc: 0.6538\n",
      "Epoch 37/59\n",
      "208/208 [==============================] - 0s 601us/step - loss: 0.1701 - acc: 0.9663 - val_loss: 1.0450 - val_acc: 0.6923\n",
      "Epoch 38/59\n",
      "208/208 [==============================] - 0s 566us/step - loss: 0.1707 - acc: 0.9519 - val_loss: 1.0027 - val_acc: 0.7500\n",
      "Epoch 39/59\n",
      "208/208 [==============================] - 0s 586us/step - loss: 0.2017 - acc: 0.9279 - val_loss: 1.0995 - val_acc: 0.6923\n",
      "Epoch 40/59\n",
      "208/208 [==============================] - 0s 595us/step - loss: 0.1604 - acc: 0.9567 - val_loss: 1.1982 - val_acc: 0.6154\n",
      "Epoch 41/59\n",
      "208/208 [==============================] - 0s 593us/step - loss: 0.1515 - acc: 0.9567 - val_loss: 1.0006 - val_acc: 0.7308\n",
      "Epoch 42/59\n",
      "208/208 [==============================] - 0s 587us/step - loss: 0.1041 - acc: 0.9856 - val_loss: 1.0862 - val_acc: 0.6923\n",
      "Epoch 43/59\n",
      "208/208 [==============================] - 0s 577us/step - loss: 0.1430 - acc: 0.9615 - val_loss: 1.0115 - val_acc: 0.7500\n",
      "Epoch 44/59\n",
      "208/208 [==============================] - 0s 594us/step - loss: 0.1037 - acc: 0.9663 - val_loss: 1.0507 - val_acc: 0.6923\n",
      "Epoch 45/59\n",
      "208/208 [==============================] - 0s 592us/step - loss: 0.1250 - acc: 0.9712 - val_loss: 1.0040 - val_acc: 0.7308\n",
      "Epoch 46/59\n",
      "208/208 [==============================] - 0s 596us/step - loss: 0.1208 - acc: 0.9663 - val_loss: 1.1001 - val_acc: 0.7115\n",
      "Epoch 47/59\n",
      "208/208 [==============================] - 0s 596us/step - loss: 0.1033 - acc: 0.9760 - val_loss: 1.0442 - val_acc: 0.7115\n",
      "Epoch 48/59\n",
      "208/208 [==============================] - 0s 648us/step - loss: 0.1173 - acc: 0.9663 - val_loss: 1.0691 - val_acc: 0.7115\n",
      "Epoch 49/59\n",
      "208/208 [==============================] - 0s 742us/step - loss: 0.1170 - acc: 0.9663 - val_loss: 1.1031 - val_acc: 0.6923\n",
      "Epoch 50/59\n",
      "208/208 [==============================] - 0s 558us/step - loss: 0.0846 - acc: 0.9808 - val_loss: 1.0720 - val_acc: 0.7500\n",
      "Epoch 51/59\n",
      "208/208 [==============================] - 0s 520us/step - loss: 0.1279 - acc: 0.9615 - val_loss: 1.2466 - val_acc: 0.6346\n",
      "Epoch 52/59\n",
      "208/208 [==============================] - 0s 522us/step - loss: 0.2016 - acc: 0.9327 - val_loss: 1.2773 - val_acc: 0.6538\n",
      "Epoch 53/59\n",
      "208/208 [==============================] - 0s 546us/step - loss: 0.0953 - acc: 0.9712 - val_loss: 1.1482 - val_acc: 0.7115\n",
      "Epoch 54/59\n",
      "208/208 [==============================] - 0s 646us/step - loss: 0.1339 - acc: 0.9712 - val_loss: 1.1093 - val_acc: 0.6731\n",
      "Epoch 55/59\n",
      "208/208 [==============================] - 0s 644us/step - loss: 0.0987 - acc: 0.9663 - val_loss: 1.1152 - val_acc: 0.6923\n",
      "Epoch 56/59\n",
      "208/208 [==============================] - 0s 603us/step - loss: 0.1115 - acc: 0.9615 - val_loss: 1.1622 - val_acc: 0.6731\n",
      "Epoch 57/59\n",
      "208/208 [==============================] - 0s 611us/step - loss: 0.0861 - acc: 0.9856 - val_loss: 1.2082 - val_acc: 0.6731\n",
      "Epoch 58/59\n",
      "208/208 [==============================] - 0s 617us/step - loss: 0.0827 - acc: 0.9808 - val_loss: 1.1662 - val_acc: 0.6923\n",
      "Epoch 59/59\n",
      "208/208 [==============================] - 0s 634us/step - loss: 0.0919 - acc: 0.9712 - val_loss: 1.1227 - val_acc: 0.7308\n",
      "Train on 208 samples, validate on 52 samples\n",
      "Epoch 1/60\n",
      "208/208 [==============================] - 11s 54ms/step - loss: 3.2605 - acc: 0.0962 - val_loss: 2.3147 - val_acc: 0.1154\n",
      "Epoch 2/60\n",
      "208/208 [==============================] - 0s 574us/step - loss: 2.3406 - acc: 0.3029 - val_loss: 1.9256 - val_acc: 0.3269\n",
      "Epoch 3/60\n",
      "208/208 [==============================] - 0s 581us/step - loss: 1.7144 - acc: 0.3942 - val_loss: 1.6005 - val_acc: 0.5000\n",
      "Epoch 4/60\n",
      "208/208 [==============================] - 0s 586us/step - loss: 1.5453 - acc: 0.4279 - val_loss: 1.6269 - val_acc: 0.5385\n",
      "Epoch 5/60\n",
      "208/208 [==============================] - 0s 567us/step - loss: 1.5589 - acc: 0.5096 - val_loss: 1.4701 - val_acc: 0.5000\n",
      "Epoch 6/60\n",
      "208/208 [==============================] - 0s 579us/step - loss: 1.1923 - acc: 0.5817 - val_loss: 1.5850 - val_acc: 0.4423\n",
      "Epoch 7/60\n",
      "208/208 [==============================] - 0s 582us/step - loss: 1.3101 - acc: 0.5577 - val_loss: 1.3253 - val_acc: 0.5769\n",
      "Epoch 8/60\n",
      "208/208 [==============================] - 0s 595us/step - loss: 0.9788 - acc: 0.6346 - val_loss: 1.2258 - val_acc: 0.5577\n",
      "Epoch 9/60\n",
      "208/208 [==============================] - 0s 573us/step - loss: 0.9350 - acc: 0.6827 - val_loss: 1.4462 - val_acc: 0.5962\n",
      "Epoch 10/60\n",
      "208/208 [==============================] - 0s 586us/step - loss: 0.8181 - acc: 0.7692 - val_loss: 1.0751 - val_acc: 0.6538\n",
      "Epoch 11/60\n",
      "208/208 [==============================] - 0s 596us/step - loss: 0.7389 - acc: 0.7500 - val_loss: 1.0062 - val_acc: 0.6538\n",
      "Epoch 12/60\n",
      "208/208 [==============================] - 0s 596us/step - loss: 0.7782 - acc: 0.7260 - val_loss: 1.0763 - val_acc: 0.6346\n",
      "Epoch 13/60\n",
      "208/208 [==============================] - 0s 571us/step - loss: 0.5532 - acc: 0.8029 - val_loss: 1.0471 - val_acc: 0.6731\n",
      "Epoch 14/60\n",
      "208/208 [==============================] - 0s 597us/step - loss: 0.5493 - acc: 0.8317 - val_loss: 1.0406 - val_acc: 0.6923\n",
      "Epoch 15/60\n",
      "208/208 [==============================] - 0s 584us/step - loss: 0.5723 - acc: 0.7981 - val_loss: 1.1243 - val_acc: 0.6923\n",
      "Epoch 16/60\n",
      "208/208 [==============================] - 0s 599us/step - loss: 0.5309 - acc: 0.8077 - val_loss: 1.0517 - val_acc: 0.6731\n",
      "Epoch 17/60\n",
      "208/208 [==============================] - 0s 590us/step - loss: 0.5693 - acc: 0.7981 - val_loss: 1.0786 - val_acc: 0.5577\n",
      "Epoch 18/60\n",
      "208/208 [==============================] - 0s 583us/step - loss: 0.4804 - acc: 0.8462 - val_loss: 0.9266 - val_acc: 0.7308\n",
      "Epoch 19/60\n",
      "208/208 [==============================] - 0s 569us/step - loss: 0.3789 - acc: 0.8558 - val_loss: 1.2336 - val_acc: 0.5577\n",
      "Epoch 20/60\n",
      "208/208 [==============================] - 0s 573us/step - loss: 0.4395 - acc: 0.8654 - val_loss: 1.0490 - val_acc: 0.6731\n",
      "Epoch 21/60\n",
      "208/208 [==============================] - 0s 580us/step - loss: 0.3926 - acc: 0.8798 - val_loss: 1.0434 - val_acc: 0.6538\n",
      "Epoch 22/60\n",
      "208/208 [==============================] - 0s 565us/step - loss: 0.3487 - acc: 0.8942 - val_loss: 1.0607 - val_acc: 0.6731\n",
      "Epoch 23/60\n",
      "208/208 [==============================] - 0s 578us/step - loss: 0.3505 - acc: 0.8846 - val_loss: 1.0550 - val_acc: 0.6538\n",
      "Epoch 24/60\n",
      "208/208 [==============================] - 0s 558us/step - loss: 0.3231 - acc: 0.9087 - val_loss: 1.0424 - val_acc: 0.6154\n",
      "Epoch 25/60\n",
      "208/208 [==============================] - 0s 584us/step - loss: 0.3342 - acc: 0.8894 - val_loss: 0.9872 - val_acc: 0.6923\n",
      "Epoch 26/60\n",
      "208/208 [==============================] - 0s 585us/step - loss: 0.2738 - acc: 0.8990 - val_loss: 1.0386 - val_acc: 0.6346\n",
      "Epoch 27/60\n",
      "208/208 [==============================] - 0s 568us/step - loss: 0.3132 - acc: 0.8798 - val_loss: 1.1033 - val_acc: 0.5962\n",
      "Epoch 28/60\n",
      "208/208 [==============================] - 0s 553us/step - loss: 0.2343 - acc: 0.9375 - val_loss: 1.0419 - val_acc: 0.6538\n",
      "Epoch 29/60\n",
      "208/208 [==============================] - 0s 573us/step - loss: 0.2000 - acc: 0.9519 - val_loss: 1.0991 - val_acc: 0.6154\n",
      "Epoch 30/60\n",
      "208/208 [==============================] - 0s 587us/step - loss: 0.2047 - acc: 0.9471 - val_loss: 1.0894 - val_acc: 0.6346\n",
      "Epoch 31/60\n",
      "208/208 [==============================] - 0s 570us/step - loss: 0.2842 - acc: 0.9087 - val_loss: 1.0692 - val_acc: 0.6923\n",
      "Epoch 32/60\n",
      "208/208 [==============================] - 0s 555us/step - loss: 0.2245 - acc: 0.9231 - val_loss: 1.0295 - val_acc: 0.6923\n",
      "Epoch 33/60\n",
      "208/208 [==============================] - 0s 583us/step - loss: 0.2287 - acc: 0.9231 - val_loss: 1.0609 - val_acc: 0.7115\n",
      "Epoch 34/60\n",
      "208/208 [==============================] - 0s 585us/step - loss: 0.2318 - acc: 0.9183 - val_loss: 1.0062 - val_acc: 0.7115\n",
      "Epoch 35/60\n",
      "208/208 [==============================] - 0s 574us/step - loss: 0.1971 - acc: 0.9567 - val_loss: 0.9986 - val_acc: 0.6923\n",
      "Epoch 36/60\n",
      "208/208 [==============================] - 0s 581us/step - loss: 0.1860 - acc: 0.9471 - val_loss: 1.0512 - val_acc: 0.6731\n",
      "Epoch 37/60\n",
      "208/208 [==============================] - 0s 569us/step - loss: 0.1791 - acc: 0.9663 - val_loss: 1.0501 - val_acc: 0.6731\n",
      "Epoch 38/60\n",
      "208/208 [==============================] - 0s 565us/step - loss: 0.1677 - acc: 0.9519 - val_loss: 1.0260 - val_acc: 0.7115\n",
      "Epoch 39/60\n",
      "208/208 [==============================] - 0s 584us/step - loss: 0.1876 - acc: 0.9231 - val_loss: 1.1305 - val_acc: 0.6731\n",
      "Epoch 40/60\n",
      "208/208 [==============================] - 0s 570us/step - loss: 0.1620 - acc: 0.9519 - val_loss: 1.1783 - val_acc: 0.6346\n",
      "Epoch 41/60\n",
      "208/208 [==============================] - 0s 605us/step - loss: 0.1396 - acc: 0.9808 - val_loss: 1.0332 - val_acc: 0.7308\n",
      "Epoch 42/60\n",
      "208/208 [==============================] - 0s 573us/step - loss: 0.1054 - acc: 0.9808 - val_loss: 1.0996 - val_acc: 0.6923\n",
      "Epoch 43/60\n",
      "208/208 [==============================] - 0s 576us/step - loss: 0.1417 - acc: 0.9663 - val_loss: 1.0257 - val_acc: 0.7115\n",
      "Epoch 44/60\n",
      "208/208 [==============================] - 0s 573us/step - loss: 0.1013 - acc: 0.9712 - val_loss: 1.0852 - val_acc: 0.6923\n",
      "Epoch 45/60\n",
      "208/208 [==============================] - 0s 576us/step - loss: 0.1242 - acc: 0.9808 - val_loss: 0.9954 - val_acc: 0.7115\n",
      "Epoch 46/60\n",
      "208/208 [==============================] - 0s 600us/step - loss: 0.1153 - acc: 0.9663 - val_loss: 1.0916 - val_acc: 0.6923\n",
      "Epoch 47/60\n",
      "208/208 [==============================] - 0s 581us/step - loss: 0.1018 - acc: 0.9808 - val_loss: 1.0544 - val_acc: 0.7308\n",
      "Epoch 48/60\n",
      "208/208 [==============================] - 0s 568us/step - loss: 0.1107 - acc: 0.9567 - val_loss: 1.0571 - val_acc: 0.7115\n",
      "Epoch 49/60\n",
      "208/208 [==============================] - 0s 576us/step - loss: 0.1094 - acc: 0.9615 - val_loss: 1.0881 - val_acc: 0.6923\n",
      "Epoch 50/60\n",
      "208/208 [==============================] - 0s 566us/step - loss: 0.0775 - acc: 0.9904 - val_loss: 1.0714 - val_acc: 0.7500\n",
      "Epoch 51/60\n",
      "208/208 [==============================] - 0s 608us/step - loss: 0.1257 - acc: 0.9663 - val_loss: 1.2260 - val_acc: 0.6346\n",
      "Epoch 52/60\n",
      "208/208 [==============================] - 0s 578us/step - loss: 0.2010 - acc: 0.9231 - val_loss: 1.2902 - val_acc: 0.6538\n",
      "Epoch 53/60\n",
      "208/208 [==============================] - 0s 584us/step - loss: 0.0944 - acc: 0.9760 - val_loss: 1.1247 - val_acc: 0.7115\n",
      "Epoch 54/60\n",
      "208/208 [==============================] - 0s 573us/step - loss: 0.1075 - acc: 0.9712 - val_loss: 1.1161 - val_acc: 0.6538\n",
      "Epoch 55/60\n",
      "208/208 [==============================] - 0s 570us/step - loss: 0.0947 - acc: 0.9856 - val_loss: 1.1171 - val_acc: 0.6923\n",
      "Epoch 56/60\n",
      "208/208 [==============================] - 0s 577us/step - loss: 0.1008 - acc: 0.9760 - val_loss: 1.1319 - val_acc: 0.6923\n",
      "Epoch 57/60\n",
      "208/208 [==============================] - 0s 580us/step - loss: 0.0917 - acc: 0.9760 - val_loss: 1.1594 - val_acc: 0.6538\n",
      "Epoch 58/60\n",
      "208/208 [==============================] - 0s 591us/step - loss: 0.0743 - acc: 0.9904 - val_loss: 1.1378 - val_acc: 0.7115\n",
      "Epoch 59/60\n",
      "208/208 [==============================] - 0s 581us/step - loss: 0.0925 - acc: 0.9615 - val_loss: 1.1561 - val_acc: 0.6731\n",
      "Epoch 60/60\n",
      "208/208 [==============================] - 0s 576us/step - loss: 0.1138 - acc: 0.9808 - val_loss: 1.0809 - val_acc: 0.7308\n",
      "Train on 208 samples, validate on 52 samples\n",
      "Epoch 1/61\n",
      "208/208 [==============================] - 11s 54ms/step - loss: 3.2605 - acc: 0.0962 - val_loss: 2.3147 - val_acc: 0.1154\n",
      "Epoch 2/61\n",
      "208/208 [==============================] - 0s 585us/step - loss: 2.3406 - acc: 0.3029 - val_loss: 1.9256 - val_acc: 0.3269\n",
      "Epoch 3/61\n",
      "208/208 [==============================] - 0s 582us/step - loss: 1.7144 - acc: 0.3942 - val_loss: 1.6005 - val_acc: 0.5000\n",
      "Epoch 4/61\n",
      "208/208 [==============================] - 0s 590us/step - loss: 1.5453 - acc: 0.4279 - val_loss: 1.6269 - val_acc: 0.5385\n",
      "Epoch 5/61\n",
      "208/208 [==============================] - 0s 576us/step - loss: 1.5589 - acc: 0.5096 - val_loss: 1.4701 - val_acc: 0.5000\n",
      "Epoch 6/61\n",
      "208/208 [==============================] - 0s 607us/step - loss: 1.1923 - acc: 0.5817 - val_loss: 1.5850 - val_acc: 0.4423\n",
      "Epoch 7/61\n",
      "208/208 [==============================] - 0s 585us/step - loss: 1.3101 - acc: 0.5577 - val_loss: 1.3253 - val_acc: 0.5769\n",
      "Epoch 8/61\n",
      "208/208 [==============================] - 0s 598us/step - loss: 0.9788 - acc: 0.6346 - val_loss: 1.2279 - val_acc: 0.5577\n",
      "Epoch 9/61\n",
      "208/208 [==============================] - 0s 601us/step - loss: 0.9346 - acc: 0.6875 - val_loss: 1.4580 - val_acc: 0.5962\n",
      "Epoch 10/61\n",
      "208/208 [==============================] - 0s 597us/step - loss: 0.8187 - acc: 0.7740 - val_loss: 1.0723 - val_acc: 0.6346\n",
      "Epoch 11/61\n",
      "208/208 [==============================] - 0s 598us/step - loss: 0.7353 - acc: 0.7596 - val_loss: 0.9954 - val_acc: 0.6731\n",
      "Epoch 12/61\n",
      "208/208 [==============================] - 0s 581us/step - loss: 0.7850 - acc: 0.7356 - val_loss: 1.0725 - val_acc: 0.5769\n",
      "Epoch 13/61\n",
      "208/208 [==============================] - 0s 576us/step - loss: 0.5560 - acc: 0.7933 - val_loss: 1.0624 - val_acc: 0.6731\n",
      "Epoch 14/61\n",
      "208/208 [==============================] - 0s 585us/step - loss: 0.5528 - acc: 0.8269 - val_loss: 1.0404 - val_acc: 0.6923\n",
      "Epoch 15/61\n",
      "208/208 [==============================] - 0s 597us/step - loss: 0.5594 - acc: 0.7885 - val_loss: 1.0953 - val_acc: 0.6923\n",
      "Epoch 16/61\n",
      "208/208 [==============================] - 0s 609us/step - loss: 0.5367 - acc: 0.8029 - val_loss: 1.0775 - val_acc: 0.6538\n",
      "Epoch 17/61\n",
      "208/208 [==============================] - 0s 577us/step - loss: 0.5675 - acc: 0.7837 - val_loss: 1.1222 - val_acc: 0.5577\n",
      "Epoch 18/61\n",
      "208/208 [==============================] - 0s 588us/step - loss: 0.4929 - acc: 0.8221 - val_loss: 0.9414 - val_acc: 0.7308\n",
      "Epoch 19/61\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "208/208 [==============================] - 0s 594us/step - loss: 0.3709 - acc: 0.8798 - val_loss: 1.1934 - val_acc: 0.5769\n",
      "Epoch 20/61\n",
      "208/208 [==============================] - 0s 568us/step - loss: 0.4191 - acc: 0.8654 - val_loss: 1.0380 - val_acc: 0.6731\n",
      "Epoch 21/61\n",
      "208/208 [==============================] - 0s 594us/step - loss: 0.3867 - acc: 0.8750 - val_loss: 1.0427 - val_acc: 0.6731\n",
      "Epoch 22/61\n",
      "208/208 [==============================] - 0s 613us/step - loss: 0.3519 - acc: 0.8894 - val_loss: 1.0876 - val_acc: 0.6538\n",
      "Epoch 23/61\n",
      "208/208 [==============================] - 0s 564us/step - loss: 0.3765 - acc: 0.8894 - val_loss: 1.0501 - val_acc: 0.6346\n",
      "Epoch 24/61\n",
      "208/208 [==============================] - 0s 584us/step - loss: 0.3244 - acc: 0.8990 - val_loss: 0.9909 - val_acc: 0.6538\n",
      "Epoch 25/61\n",
      "208/208 [==============================] - 0s 568us/step - loss: 0.3338 - acc: 0.9135 - val_loss: 0.9618 - val_acc: 0.6731\n",
      "Epoch 26/61\n",
      "208/208 [==============================] - 0s 556us/step - loss: 0.2662 - acc: 0.9135 - val_loss: 1.0199 - val_acc: 0.6538\n",
      "Epoch 27/61\n",
      "208/208 [==============================] - 0s 581us/step - loss: 0.3131 - acc: 0.8942 - val_loss: 1.1563 - val_acc: 0.5385\n",
      "Epoch 28/61\n",
      "208/208 [==============================] - 0s 590us/step - loss: 0.2275 - acc: 0.9423 - val_loss: 1.0381 - val_acc: 0.6346\n",
      "Epoch 29/61\n",
      "208/208 [==============================] - 0s 575us/step - loss: 0.1979 - acc: 0.9423 - val_loss: 1.1046 - val_acc: 0.6154\n",
      "Epoch 30/61\n",
      "208/208 [==============================] - 0s 568us/step - loss: 0.2034 - acc: 0.9519 - val_loss: 1.1212 - val_acc: 0.5962\n",
      "Epoch 31/61\n",
      "208/208 [==============================] - 0s 590us/step - loss: 0.2882 - acc: 0.9087 - val_loss: 1.0432 - val_acc: 0.6923\n",
      "Epoch 32/61\n",
      "208/208 [==============================] - 0s 578us/step - loss: 0.2168 - acc: 0.9327 - val_loss: 1.0271 - val_acc: 0.6923\n",
      "Epoch 33/61\n",
      "208/208 [==============================] - 0s 569us/step - loss: 0.2224 - acc: 0.9231 - val_loss: 1.0559 - val_acc: 0.7115\n",
      "Epoch 34/61\n",
      "208/208 [==============================] - 0s 577us/step - loss: 0.2480 - acc: 0.9183 - val_loss: 0.9937 - val_acc: 0.6731\n",
      "Epoch 35/61\n",
      "208/208 [==============================] - 0s 586us/step - loss: 0.1975 - acc: 0.9519 - val_loss: 0.9964 - val_acc: 0.6923\n",
      "Epoch 36/61\n",
      "208/208 [==============================] - 0s 597us/step - loss: 0.1838 - acc: 0.9327 - val_loss: 1.0363 - val_acc: 0.6731\n",
      "Epoch 37/61\n",
      "208/208 [==============================] - 0s 578us/step - loss: 0.1755 - acc: 0.9567 - val_loss: 1.0645 - val_acc: 0.6731\n",
      "Epoch 38/61\n",
      "208/208 [==============================] - 0s 568us/step - loss: 0.1813 - acc: 0.9423 - val_loss: 1.0081 - val_acc: 0.7115\n",
      "Epoch 39/61\n",
      "208/208 [==============================] - 0s 556us/step - loss: 0.1772 - acc: 0.9423 - val_loss: 1.0618 - val_acc: 0.6923\n",
      "Epoch 40/61\n",
      "208/208 [==============================] - 0s 577us/step - loss: 0.1559 - acc: 0.9615 - val_loss: 1.1046 - val_acc: 0.6538\n",
      "Epoch 41/61\n",
      "208/208 [==============================] - 0s 591us/step - loss: 0.1360 - acc: 0.9712 - val_loss: 0.9946 - val_acc: 0.7308\n",
      "Epoch 42/61\n",
      "208/208 [==============================] - 0s 582us/step - loss: 0.1104 - acc: 0.9952 - val_loss: 1.0593 - val_acc: 0.6538\n",
      "Epoch 43/61\n",
      "208/208 [==============================] - 0s 575us/step - loss: 0.1396 - acc: 0.9615 - val_loss: 1.0080 - val_acc: 0.7115\n",
      "Epoch 44/61\n",
      "208/208 [==============================] - 0s 577us/step - loss: 0.1040 - acc: 0.9760 - val_loss: 1.0477 - val_acc: 0.6923\n",
      "Epoch 45/61\n",
      "208/208 [==============================] - 0s 579us/step - loss: 0.1226 - acc: 0.9712 - val_loss: 0.9894 - val_acc: 0.7308\n",
      "Epoch 46/61\n",
      "208/208 [==============================] - 0s 581us/step - loss: 0.1135 - acc: 0.9615 - val_loss: 1.0658 - val_acc: 0.6923\n",
      "Epoch 47/61\n",
      "208/208 [==============================] - 0s 616us/step - loss: 0.1017 - acc: 0.9856 - val_loss: 1.0189 - val_acc: 0.7500\n",
      "Epoch 48/61\n",
      "208/208 [==============================] - 0s 608us/step - loss: 0.1019 - acc: 0.9615 - val_loss: 1.0189 - val_acc: 0.7115\n",
      "Epoch 49/61\n",
      "208/208 [==============================] - 0s 597us/step - loss: 0.0973 - acc: 0.9712 - val_loss: 1.0610 - val_acc: 0.7500\n",
      "Epoch 50/61\n",
      "208/208 [==============================] - 0s 588us/step - loss: 0.0861 - acc: 0.9808 - val_loss: 1.0380 - val_acc: 0.7308\n",
      "Epoch 51/61\n",
      "208/208 [==============================] - 0s 591us/step - loss: 0.1312 - acc: 0.9567 - val_loss: 1.1822 - val_acc: 0.6346\n",
      "Epoch 52/61\n",
      "208/208 [==============================] - 0s 584us/step - loss: 0.1918 - acc: 0.9327 - val_loss: 1.2308 - val_acc: 0.6731\n",
      "Epoch 53/61\n",
      "208/208 [==============================] - 0s 593us/step - loss: 0.0911 - acc: 0.9808 - val_loss: 1.1196 - val_acc: 0.7115\n",
      "Epoch 54/61\n",
      "208/208 [==============================] - 0s 579us/step - loss: 0.1307 - acc: 0.9663 - val_loss: 1.0671 - val_acc: 0.6923\n",
      "Epoch 55/61\n",
      "208/208 [==============================] - 0s 604us/step - loss: 0.1062 - acc: 0.9663 - val_loss: 1.1267 - val_acc: 0.6923\n",
      "Epoch 56/61\n",
      "208/208 [==============================] - 0s 576us/step - loss: 0.1027 - acc: 0.9808 - val_loss: 1.1412 - val_acc: 0.6731\n",
      "Epoch 57/61\n",
      "208/208 [==============================] - 0s 595us/step - loss: 0.0977 - acc: 0.9760 - val_loss: 1.1670 - val_acc: 0.6731\n",
      "Epoch 58/61\n",
      "208/208 [==============================] - 0s 583us/step - loss: 0.0808 - acc: 0.9856 - val_loss: 1.1383 - val_acc: 0.7115\n",
      "Epoch 59/61\n",
      "208/208 [==============================] - 0s 595us/step - loss: 0.0824 - acc: 0.9712 - val_loss: 1.1207 - val_acc: 0.6923\n",
      "Epoch 60/61\n",
      "208/208 [==============================] - 0s 576us/step - loss: 0.1000 - acc: 0.9856 - val_loss: 1.0514 - val_acc: 0.7308\n",
      "Epoch 61/61\n",
      "208/208 [==============================] - 0s 595us/step - loss: 0.0715 - acc: 0.9808 - val_loss: 1.1378 - val_acc: 0.6538\n",
      "Train on 208 samples, validate on 52 samples\n",
      "Epoch 1/62\n",
      "208/208 [==============================] - 12s 55ms/step - loss: 3.2605 - acc: 0.0962 - val_loss: 2.3147 - val_acc: 0.1154\n",
      "Epoch 2/62\n",
      "208/208 [==============================] - 0s 596us/step - loss: 2.3406 - acc: 0.3029 - val_loss: 1.9256 - val_acc: 0.3269\n",
      "Epoch 3/62\n",
      "208/208 [==============================] - 0s 602us/step - loss: 1.7144 - acc: 0.3942 - val_loss: 1.6005 - val_acc: 0.5000\n",
      "Epoch 4/62\n",
      "208/208 [==============================] - 0s 586us/step - loss: 1.5453 - acc: 0.4279 - val_loss: 1.6269 - val_acc: 0.5385\n",
      "Epoch 5/62\n",
      "208/208 [==============================] - 0s 602us/step - loss: 1.5589 - acc: 0.5096 - val_loss: 1.4701 - val_acc: 0.5000\n",
      "Epoch 6/62\n",
      "208/208 [==============================] - 0s 618us/step - loss: 1.1923 - acc: 0.5817 - val_loss: 1.5850 - val_acc: 0.4423\n",
      "Epoch 7/62\n",
      "208/208 [==============================] - 0s 577us/step - loss: 1.3101 - acc: 0.5577 - val_loss: 1.3253 - val_acc: 0.5769\n",
      "Epoch 8/62\n",
      "208/208 [==============================] - 0s 596us/step - loss: 0.9788 - acc: 0.6346 - val_loss: 1.2279 - val_acc: 0.5577\n",
      "Epoch 9/62\n",
      "208/208 [==============================] - 0s 609us/step - loss: 0.9346 - acc: 0.6875 - val_loss: 1.4580 - val_acc: 0.5962\n",
      "Epoch 10/62\n",
      "208/208 [==============================] - 0s 583us/step - loss: 0.8187 - acc: 0.7740 - val_loss: 1.0723 - val_acc: 0.6346\n",
      "Epoch 11/62\n",
      "208/208 [==============================] - 0s 598us/step - loss: 0.7353 - acc: 0.7596 - val_loss: 0.9954 - val_acc: 0.6731\n",
      "Epoch 12/62\n",
      "208/208 [==============================] - 0s 593us/step - loss: 0.7850 - acc: 0.7356 - val_loss: 1.0725 - val_acc: 0.5769\n",
      "Epoch 13/62\n",
      "208/208 [==============================] - 0s 604us/step - loss: 0.5560 - acc: 0.7933 - val_loss: 1.0624 - val_acc: 0.6731\n",
      "Epoch 14/62\n",
      "208/208 [==============================] - 0s 593us/step - loss: 0.5528 - acc: 0.8269 - val_loss: 1.0404 - val_acc: 0.6923\n",
      "Epoch 15/62\n",
      "208/208 [==============================] - 0s 594us/step - loss: 0.5593 - acc: 0.7885 - val_loss: 1.0953 - val_acc: 0.6923\n",
      "Epoch 16/62\n",
      "208/208 [==============================] - 0s 588us/step - loss: 0.5367 - acc: 0.8029 - val_loss: 1.0774 - val_acc: 0.6538\n",
      "Epoch 17/62\n",
      "208/208 [==============================] - 0s 576us/step - loss: 0.5675 - acc: 0.7885 - val_loss: 1.1222 - val_acc: 0.5577\n",
      "Epoch 18/62\n",
      "208/208 [==============================] - 0s 595us/step - loss: 0.4930 - acc: 0.8221 - val_loss: 0.9414 - val_acc: 0.7308\n",
      "Epoch 19/62\n",
      "208/208 [==============================] - 0s 577us/step - loss: 0.3706 - acc: 0.8798 - val_loss: 1.1944 - val_acc: 0.5769\n",
      "Epoch 20/62\n",
      "208/208 [==============================] - 0s 599us/step - loss: 0.4193 - acc: 0.8654 - val_loss: 1.0358 - val_acc: 0.6731\n",
      "Epoch 21/62\n",
      "208/208 [==============================] - 0s 556us/step - loss: 0.3843 - acc: 0.8798 - val_loss: 1.0398 - val_acc: 0.6731\n",
      "Epoch 22/62\n",
      "208/208 [==============================] - 0s 568us/step - loss: 0.3499 - acc: 0.8846 - val_loss: 1.0967 - val_acc: 0.6538\n",
      "Epoch 23/62\n",
      "208/208 [==============================] - 0s 572us/step - loss: 0.3756 - acc: 0.8846 - val_loss: 1.0502 - val_acc: 0.6346\n",
      "Epoch 24/62\n",
      "208/208 [==============================] - 0s 567us/step - loss: 0.3208 - acc: 0.9038 - val_loss: 1.0037 - val_acc: 0.6538\n",
      "Epoch 25/62\n",
      "208/208 [==============================] - 0s 591us/step - loss: 0.3328 - acc: 0.9135 - val_loss: 0.9661 - val_acc: 0.6731\n",
      "Epoch 26/62\n",
      "208/208 [==============================] - 0s 573us/step - loss: 0.2630 - acc: 0.9135 - val_loss: 1.0296 - val_acc: 0.6346\n",
      "Epoch 27/62\n",
      "208/208 [==============================] - 0s 573us/step - loss: 0.3162 - acc: 0.9038 - val_loss: 1.1386 - val_acc: 0.5385\n",
      "Epoch 28/62\n",
      "208/208 [==============================] - 0s 563us/step - loss: 0.2284 - acc: 0.9519 - val_loss: 1.0425 - val_acc: 0.6346\n",
      "Epoch 29/62\n",
      "208/208 [==============================] - 0s 559us/step - loss: 0.2003 - acc: 0.9375 - val_loss: 1.1107 - val_acc: 0.6346\n",
      "Epoch 30/62\n",
      "208/208 [==============================] - 0s 587us/step - loss: 0.2084 - acc: 0.9471 - val_loss: 1.1170 - val_acc: 0.5962\n",
      "Epoch 31/62\n",
      "208/208 [==============================] - 0s 542us/step - loss: 0.2852 - acc: 0.9135 - val_loss: 1.0340 - val_acc: 0.6923\n",
      "Epoch 32/62\n",
      "208/208 [==============================] - 0s 578us/step - loss: 0.2169 - acc: 0.9423 - val_loss: 1.0292 - val_acc: 0.7115\n",
      "Epoch 33/62\n",
      "208/208 [==============================] - 0s 590us/step - loss: 0.2252 - acc: 0.9231 - val_loss: 1.0604 - val_acc: 0.7115\n",
      "Epoch 34/62\n",
      "208/208 [==============================] - 0s 572us/step - loss: 0.2510 - acc: 0.9135 - val_loss: 0.9785 - val_acc: 0.7115\n",
      "Epoch 35/62\n",
      "208/208 [==============================] - 0s 574us/step - loss: 0.2005 - acc: 0.9519 - val_loss: 0.9934 - val_acc: 0.6923\n",
      "Epoch 36/62\n",
      "208/208 [==============================] - 0s 594us/step - loss: 0.1707 - acc: 0.9471 - val_loss: 1.0380 - val_acc: 0.6923\n",
      "Epoch 37/62\n",
      "208/208 [==============================] - 0s 564us/step - loss: 0.1786 - acc: 0.9567 - val_loss: 1.0664 - val_acc: 0.6731\n",
      "Epoch 38/62\n",
      "208/208 [==============================] - 0s 575us/step - loss: 0.1787 - acc: 0.9471 - val_loss: 1.0043 - val_acc: 0.6923\n",
      "Epoch 39/62\n",
      "208/208 [==============================] - 0s 581us/step - loss: 0.1833 - acc: 0.9327 - val_loss: 1.0840 - val_acc: 0.6923\n",
      "Epoch 40/62\n",
      "208/208 [==============================] - 0s 588us/step - loss: 0.1597 - acc: 0.9615 - val_loss: 1.1222 - val_acc: 0.6346\n",
      "Epoch 41/62\n",
      "208/208 [==============================] - 0s 575us/step - loss: 0.1421 - acc: 0.9663 - val_loss: 0.9937 - val_acc: 0.7308\n",
      "Epoch 42/62\n",
      "208/208 [==============================] - 0s 556us/step - loss: 0.1031 - acc: 0.9952 - val_loss: 1.0519 - val_acc: 0.6731\n",
      "Epoch 43/62\n",
      "208/208 [==============================] - 0s 568us/step - loss: 0.1405 - acc: 0.9519 - val_loss: 0.9845 - val_acc: 0.7500\n",
      "Epoch 44/62\n",
      "208/208 [==============================] - 0s 588us/step - loss: 0.0987 - acc: 0.9760 - val_loss: 1.0334 - val_acc: 0.6923\n",
      "Epoch 45/62\n",
      "208/208 [==============================] - 0s 574us/step - loss: 0.1189 - acc: 0.9760 - val_loss: 0.9676 - val_acc: 0.7500\n",
      "Epoch 46/62\n",
      "208/208 [==============================] - 0s 582us/step - loss: 0.1202 - acc: 0.9567 - val_loss: 1.0481 - val_acc: 0.6923\n",
      "Epoch 47/62\n",
      "208/208 [==============================] - 0s 569us/step - loss: 0.1031 - acc: 0.9760 - val_loss: 1.0183 - val_acc: 0.7500\n",
      "Epoch 48/62\n",
      "208/208 [==============================] - 0s 586us/step - loss: 0.1080 - acc: 0.9663 - val_loss: 1.0136 - val_acc: 0.7115\n",
      "Epoch 49/62\n",
      "208/208 [==============================] - 0s 589us/step - loss: 0.0966 - acc: 0.9712 - val_loss: 1.0580 - val_acc: 0.7115\n",
      "Epoch 50/62\n",
      "208/208 [==============================] - 0s 566us/step - loss: 0.0871 - acc: 0.9760 - val_loss: 1.0382 - val_acc: 0.7308\n",
      "Epoch 51/62\n",
      "208/208 [==============================] - 0s 577us/step - loss: 0.1279 - acc: 0.9615 - val_loss: 1.2072 - val_acc: 0.6346\n",
      "Epoch 52/62\n",
      "208/208 [==============================] - 0s 591us/step - loss: 0.1962 - acc: 0.9423 - val_loss: 1.2390 - val_acc: 0.6538\n",
      "Epoch 53/62\n",
      "208/208 [==============================] - 0s 568us/step - loss: 0.0879 - acc: 0.9760 - val_loss: 1.1072 - val_acc: 0.7115\n",
      "Epoch 54/62\n",
      "208/208 [==============================] - 0s 586us/step - loss: 0.1078 - acc: 0.9712 - val_loss: 1.0592 - val_acc: 0.6731\n",
      "Epoch 55/62\n",
      "208/208 [==============================] - 0s 582us/step - loss: 0.1046 - acc: 0.9663 - val_loss: 1.0829 - val_acc: 0.6923\n",
      "Epoch 56/62\n",
      "208/208 [==============================] - 0s 574us/step - loss: 0.0979 - acc: 0.9808 - val_loss: 1.1285 - val_acc: 0.6731\n",
      "Epoch 57/62\n",
      "208/208 [==============================] - 0s 581us/step - loss: 0.0890 - acc: 0.9760 - val_loss: 1.1447 - val_acc: 0.6538\n",
      "Epoch 58/62\n",
      "208/208 [==============================] - 0s 589us/step - loss: 0.0754 - acc: 0.9808 - val_loss: 1.1138 - val_acc: 0.7115\n",
      "Epoch 59/62\n",
      "208/208 [==============================] - 0s 564us/step - loss: 0.0877 - acc: 0.9712 - val_loss: 1.1344 - val_acc: 0.6923\n",
      "Epoch 60/62\n",
      "208/208 [==============================] - 0s 596us/step - loss: 0.1130 - acc: 0.9760 - val_loss: 1.0577 - val_acc: 0.7308\n",
      "Epoch 61/62\n",
      "208/208 [==============================] - 0s 592us/step - loss: 0.0772 - acc: 0.9808 - val_loss: 1.1175 - val_acc: 0.6731\n",
      "Epoch 62/62\n",
      "208/208 [==============================] - 0s 580us/step - loss: 0.0726 - acc: 0.9712 - val_loss: 1.0738 - val_acc: 0.7308\n",
      "Train on 208 samples, validate on 52 samples\n",
      "Epoch 1/63\n",
      "208/208 [==============================] - 12s 55ms/step - loss: 3.2605 - acc: 0.0962 - val_loss: 2.3147 - val_acc: 0.1154\n",
      "Epoch 2/63\n",
      "208/208 [==============================] - 0s 577us/step - loss: 2.3406 - acc: 0.3029 - val_loss: 1.9256 - val_acc: 0.3269\n",
      "Epoch 3/63\n",
      "208/208 [==============================] - 0s 579us/step - loss: 1.7144 - acc: 0.3942 - val_loss: 1.6005 - val_acc: 0.5000\n",
      "Epoch 4/63\n",
      "208/208 [==============================] - 0s 575us/step - loss: 1.5453 - acc: 0.4279 - val_loss: 1.6269 - val_acc: 0.5385\n",
      "Epoch 5/63\n",
      "208/208 [==============================] - 0s 581us/step - loss: 1.5589 - acc: 0.5096 - val_loss: 1.4701 - val_acc: 0.5000\n",
      "Epoch 6/63\n",
      "208/208 [==============================] - 0s 598us/step - loss: 1.1923 - acc: 0.5817 - val_loss: 1.5850 - val_acc: 0.4423\n",
      "Epoch 7/63\n",
      "208/208 [==============================] - 0s 592us/step - loss: 1.3101 - acc: 0.5577 - val_loss: 1.3253 - val_acc: 0.5769\n",
      "Epoch 8/63\n",
      "208/208 [==============================] - 0s 618us/step - loss: 0.9788 - acc: 0.6346 - val_loss: 1.2279 - val_acc: 0.5577\n",
      "Epoch 9/63\n",
      "208/208 [==============================] - 0s 592us/step - loss: 0.9346 - acc: 0.6875 - val_loss: 1.4580 - val_acc: 0.5962\n",
      "Epoch 10/63\n",
      "208/208 [==============================] - 0s 602us/step - loss: 0.8187 - acc: 0.7740 - val_loss: 1.0723 - val_acc: 0.6346\n",
      "Epoch 11/63\n",
      "208/208 [==============================] - 0s 592us/step - loss: 0.7353 - acc: 0.7596 - val_loss: 0.9954 - val_acc: 0.6731\n",
      "Epoch 12/63\n",
      "208/208 [==============================] - 0s 591us/step - loss: 0.7850 - acc: 0.7356 - val_loss: 1.0725 - val_acc: 0.5769\n",
      "Epoch 13/63\n",
      "208/208 [==============================] - 0s 575us/step - loss: 0.5560 - acc: 0.7933 - val_loss: 1.0624 - val_acc: 0.6731\n",
      "Epoch 14/63\n",
      "208/208 [==============================] - 0s 597us/step - loss: 0.5528 - acc: 0.8269 - val_loss: 1.0404 - val_acc: 0.6923\n",
      "Epoch 15/63\n",
      "208/208 [==============================] - 0s 594us/step - loss: 0.5593 - acc: 0.7885 - val_loss: 1.0953 - val_acc: 0.6923\n",
      "Epoch 16/63\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "208/208 [==============================] - 0s 575us/step - loss: 0.5367 - acc: 0.8029 - val_loss: 1.0774 - val_acc: 0.6538\n",
      "Epoch 17/63\n",
      "208/208 [==============================] - 0s 589us/step - loss: 0.5675 - acc: 0.7885 - val_loss: 1.1222 - val_acc: 0.5577\n",
      "Epoch 18/63\n",
      "208/208 [==============================] - 0s 566us/step - loss: 0.4930 - acc: 0.8221 - val_loss: 0.9414 - val_acc: 0.7308\n",
      "Epoch 19/63\n",
      "208/208 [==============================] - 0s 568us/step - loss: 0.3706 - acc: 0.8798 - val_loss: 1.1944 - val_acc: 0.5769\n",
      "Epoch 20/63\n",
      "208/208 [==============================] - 0s 565us/step - loss: 0.4193 - acc: 0.8654 - val_loss: 1.0358 - val_acc: 0.6731\n",
      "Epoch 21/63\n",
      "208/208 [==============================] - 0s 558us/step - loss: 0.3843 - acc: 0.8798 - val_loss: 1.0398 - val_acc: 0.6731\n",
      "Epoch 22/63\n",
      "208/208 [==============================] - 0s 580us/step - loss: 0.3499 - acc: 0.8846 - val_loss: 1.0967 - val_acc: 0.6538\n",
      "Epoch 23/63\n",
      "208/208 [==============================] - 0s 570us/step - loss: 0.3756 - acc: 0.8846 - val_loss: 1.0502 - val_acc: 0.6346\n",
      "Epoch 24/63\n",
      "208/208 [==============================] - 0s 586us/step - loss: 0.3208 - acc: 0.9038 - val_loss: 1.0037 - val_acc: 0.6538\n",
      "Epoch 25/63\n",
      "208/208 [==============================] - 0s 578us/step - loss: 0.3328 - acc: 0.9135 - val_loss: 0.9661 - val_acc: 0.6731\n",
      "Epoch 26/63\n",
      "208/208 [==============================] - 0s 570us/step - loss: 0.2630 - acc: 0.9135 - val_loss: 1.0296 - val_acc: 0.6346\n",
      "Epoch 27/63\n",
      "208/208 [==============================] - 0s 548us/step - loss: 0.3162 - acc: 0.9038 - val_loss: 1.1386 - val_acc: 0.5385\n",
      "Epoch 28/63\n",
      "208/208 [==============================] - 0s 575us/step - loss: 0.2284 - acc: 0.9519 - val_loss: 1.0425 - val_acc: 0.6346\n",
      "Epoch 29/63\n",
      "208/208 [==============================] - 0s 568us/step - loss: 0.2003 - acc: 0.9375 - val_loss: 1.1107 - val_acc: 0.6346\n",
      "Epoch 30/63\n",
      "208/208 [==============================] - 0s 591us/step - loss: 0.2084 - acc: 0.9471 - val_loss: 1.1186 - val_acc: 0.5962\n",
      "Epoch 31/63\n",
      "208/208 [==============================] - 0s 567us/step - loss: 0.2855 - acc: 0.9135 - val_loss: 1.0348 - val_acc: 0.6923\n",
      "Epoch 32/63\n",
      "208/208 [==============================] - 0s 569us/step - loss: 0.2170 - acc: 0.9423 - val_loss: 1.0299 - val_acc: 0.7115\n",
      "Epoch 33/63\n",
      "208/208 [==============================] - 0s 582us/step - loss: 0.2253 - acc: 0.9231 - val_loss: 1.0596 - val_acc: 0.7115\n",
      "Epoch 34/63\n",
      "208/208 [==============================] - 0s 564us/step - loss: 0.2521 - acc: 0.9135 - val_loss: 0.9779 - val_acc: 0.6923\n",
      "Epoch 35/63\n",
      "208/208 [==============================] - 0s 572us/step - loss: 0.2007 - acc: 0.9471 - val_loss: 0.9877 - val_acc: 0.6923\n",
      "Epoch 36/63\n",
      "208/208 [==============================] - 0s 612us/step - loss: 0.1721 - acc: 0.9471 - val_loss: 1.0357 - val_acc: 0.6923\n",
      "Epoch 37/63\n",
      "208/208 [==============================] - 0s 589us/step - loss: 0.1801 - acc: 0.9519 - val_loss: 1.0596 - val_acc: 0.6731\n",
      "Epoch 38/63\n",
      "208/208 [==============================] - 0s 592us/step - loss: 0.1800 - acc: 0.9423 - val_loss: 0.9930 - val_acc: 0.7115\n",
      "Epoch 39/63\n",
      "208/208 [==============================] - 0s 603us/step - loss: 0.1833 - acc: 0.9279 - val_loss: 1.0589 - val_acc: 0.6923\n",
      "Epoch 40/63\n",
      "208/208 [==============================] - 0s 561us/step - loss: 0.1522 - acc: 0.9615 - val_loss: 1.1056 - val_acc: 0.6346\n",
      "Epoch 41/63\n",
      "208/208 [==============================] - 0s 580us/step - loss: 0.1401 - acc: 0.9712 - val_loss: 1.0008 - val_acc: 0.7308\n",
      "Epoch 42/63\n",
      "208/208 [==============================] - 0s 586us/step - loss: 0.1057 - acc: 0.9904 - val_loss: 1.0431 - val_acc: 0.6731\n",
      "Epoch 43/63\n",
      "208/208 [==============================] - 0s 574us/step - loss: 0.1394 - acc: 0.9615 - val_loss: 0.9956 - val_acc: 0.7500\n",
      "Epoch 44/63\n",
      "208/208 [==============================] - 0s 550us/step - loss: 0.0998 - acc: 0.9712 - val_loss: 1.0405 - val_acc: 0.6923\n",
      "Epoch 45/63\n",
      "208/208 [==============================] - 0s 576us/step - loss: 0.1209 - acc: 0.9760 - val_loss: 0.9757 - val_acc: 0.7500\n",
      "Epoch 46/63\n",
      "208/208 [==============================] - 0s 590us/step - loss: 0.1193 - acc: 0.9567 - val_loss: 1.0470 - val_acc: 0.7308\n",
      "Epoch 47/63\n",
      "208/208 [==============================] - 0s 582us/step - loss: 0.1024 - acc: 0.9808 - val_loss: 1.0289 - val_acc: 0.7500\n",
      "Epoch 48/63\n",
      "208/208 [==============================] - 0s 587us/step - loss: 0.1090 - acc: 0.9519 - val_loss: 1.0320 - val_acc: 0.7115\n",
      "Epoch 49/63\n",
      "208/208 [==============================] - 0s 579us/step - loss: 0.0996 - acc: 0.9615 - val_loss: 1.0715 - val_acc: 0.6731\n",
      "Epoch 50/63\n",
      "208/208 [==============================] - 0s 580us/step - loss: 0.0901 - acc: 0.9760 - val_loss: 1.0323 - val_acc: 0.7308\n",
      "Epoch 51/63\n",
      "208/208 [==============================] - 0s 598us/step - loss: 0.1292 - acc: 0.9615 - val_loss: 1.1976 - val_acc: 0.6538\n",
      "Epoch 52/63\n",
      "208/208 [==============================] - 0s 584us/step - loss: 0.1808 - acc: 0.9423 - val_loss: 1.2285 - val_acc: 0.6731\n",
      "Epoch 53/63\n",
      "208/208 [==============================] - 0s 584us/step - loss: 0.0865 - acc: 0.9808 - val_loss: 1.1320 - val_acc: 0.6923\n",
      "Epoch 54/63\n",
      "208/208 [==============================] - 0s 603us/step - loss: 0.1169 - acc: 0.9712 - val_loss: 1.0560 - val_acc: 0.6731\n",
      "Epoch 55/63\n",
      "208/208 [==============================] - 0s 586us/step - loss: 0.1129 - acc: 0.9615 - val_loss: 1.0929 - val_acc: 0.6923\n",
      "Epoch 56/63\n",
      "208/208 [==============================] - 0s 585us/step - loss: 0.1025 - acc: 0.9712 - val_loss: 1.0908 - val_acc: 0.6731\n",
      "Epoch 57/63\n",
      "208/208 [==============================] - 0s 586us/step - loss: 0.0902 - acc: 0.9760 - val_loss: 1.1451 - val_acc: 0.6731\n",
      "Epoch 58/63\n",
      "208/208 [==============================] - 0s 596us/step - loss: 0.0823 - acc: 0.9760 - val_loss: 1.1060 - val_acc: 0.7115\n",
      "Epoch 59/63\n",
      "208/208 [==============================] - 0s 590us/step - loss: 0.0823 - acc: 0.9712 - val_loss: 1.1091 - val_acc: 0.7115\n",
      "Epoch 60/63\n",
      "208/208 [==============================] - 0s 582us/step - loss: 0.1087 - acc: 0.9808 - val_loss: 1.0642 - val_acc: 0.7500\n",
      "Epoch 61/63\n",
      "208/208 [==============================] - 0s 597us/step - loss: 0.0754 - acc: 0.9808 - val_loss: 1.1975 - val_acc: 0.6346\n",
      "Epoch 62/63\n",
      "208/208 [==============================] - 0s 577us/step - loss: 0.0867 - acc: 0.9760 - val_loss: 1.0829 - val_acc: 0.7308\n",
      "Epoch 63/63\n",
      "208/208 [==============================] - 0s 560us/step - loss: 0.0714 - acc: 0.9856 - val_loss: 1.0734 - val_acc: 0.7115\n",
      "Train on 208 samples, validate on 52 samples\n",
      "Epoch 1/64\n",
      "208/208 [==============================] - 12s 59ms/step - loss: 3.2605 - acc: 0.0962 - val_loss: 2.3147 - val_acc: 0.1154\n",
      "Epoch 2/64\n",
      "208/208 [==============================] - 0s 680us/step - loss: 2.3406 - acc: 0.3029 - val_loss: 1.9256 - val_acc: 0.3269\n",
      "Epoch 3/64\n",
      "208/208 [==============================] - 0s 686us/step - loss: 1.7144 - acc: 0.3942 - val_loss: 1.6005 - val_acc: 0.5000\n",
      "Epoch 4/64\n",
      "208/208 [==============================] - 0s 752us/step - loss: 1.5453 - acc: 0.4279 - val_loss: 1.6269 - val_acc: 0.5385\n",
      "Epoch 5/64\n",
      "208/208 [==============================] - 0s 782us/step - loss: 1.5589 - acc: 0.5096 - val_loss: 1.4701 - val_acc: 0.5000\n",
      "Epoch 6/64\n",
      "208/208 [==============================] - 0s 787us/step - loss: 1.1923 - acc: 0.5817 - val_loss: 1.5850 - val_acc: 0.4423\n",
      "Epoch 7/64\n",
      "208/208 [==============================] - 0s 784us/step - loss: 1.3101 - acc: 0.5577 - val_loss: 1.3253 - val_acc: 0.5769\n",
      "Epoch 8/64\n",
      "208/208 [==============================] - 0s 711us/step - loss: 0.9788 - acc: 0.6346 - val_loss: 1.2279 - val_acc: 0.5577\n",
      "Epoch 9/64\n",
      "208/208 [==============================] - 0s 735us/step - loss: 0.9346 - acc: 0.6875 - val_loss: 1.4590 - val_acc: 0.5962\n",
      "Epoch 10/64\n",
      "208/208 [==============================] - 0s 723us/step - loss: 0.8189 - acc: 0.7692 - val_loss: 1.0730 - val_acc: 0.6346\n",
      "Epoch 11/64\n",
      "208/208 [==============================] - 0s 721us/step - loss: 0.7358 - acc: 0.7548 - val_loss: 1.0035 - val_acc: 0.6731\n",
      "Epoch 12/64\n",
      "208/208 [==============================] - 0s 701us/step - loss: 0.7894 - acc: 0.7212 - val_loss: 1.0824 - val_acc: 0.5962\n",
      "Epoch 13/64\n",
      "208/208 [==============================] - 0s 764us/step - loss: 0.5557 - acc: 0.7981 - val_loss: 1.0501 - val_acc: 0.6731\n",
      "Epoch 14/64\n",
      "208/208 [==============================] - 0s 831us/step - loss: 0.5531 - acc: 0.8462 - val_loss: 1.0481 - val_acc: 0.6923\n",
      "Epoch 15/64\n",
      "208/208 [==============================] - 0s 764us/step - loss: 0.5639 - acc: 0.7885 - val_loss: 1.1224 - val_acc: 0.6731\n",
      "Epoch 16/64\n",
      "208/208 [==============================] - 0s 864us/step - loss: 0.5447 - acc: 0.8077 - val_loss: 1.0596 - val_acc: 0.6731\n",
      "Epoch 17/64\n",
      "208/208 [==============================] - 0s 826us/step - loss: 0.5581 - acc: 0.7933 - val_loss: 1.1158 - val_acc: 0.5577\n",
      "Epoch 18/64\n",
      "208/208 [==============================] - 0s 814us/step - loss: 0.4813 - acc: 0.8510 - val_loss: 0.9361 - val_acc: 0.7308\n",
      "Epoch 19/64\n",
      "208/208 [==============================] - 0s 630us/step - loss: 0.3772 - acc: 0.8894 - val_loss: 1.2038 - val_acc: 0.5769\n",
      "Epoch 20/64\n",
      "208/208 [==============================] - 0s 577us/step - loss: 0.4102 - acc: 0.8654 - val_loss: 1.0361 - val_acc: 0.6731\n",
      "Epoch 21/64\n",
      "208/208 [==============================] - 0s 616us/step - loss: 0.3794 - acc: 0.8894 - val_loss: 1.0415 - val_acc: 0.6538\n",
      "Epoch 22/64\n",
      "208/208 [==============================] - 0s 631us/step - loss: 0.3568 - acc: 0.8798 - val_loss: 1.1230 - val_acc: 0.5962\n",
      "Epoch 23/64\n",
      "208/208 [==============================] - 0s 583us/step - loss: 0.3950 - acc: 0.8702 - val_loss: 1.0357 - val_acc: 0.6538\n",
      "Epoch 24/64\n",
      "208/208 [==============================] - 0s 593us/step - loss: 0.3309 - acc: 0.8990 - val_loss: 0.9969 - val_acc: 0.6346\n",
      "Epoch 25/64\n",
      "208/208 [==============================] - 0s 627us/step - loss: 0.3312 - acc: 0.9087 - val_loss: 0.9629 - val_acc: 0.6923\n",
      "Epoch 26/64\n",
      "208/208 [==============================] - 0s 598us/step - loss: 0.2630 - acc: 0.9087 - val_loss: 1.0236 - val_acc: 0.6154\n",
      "Epoch 27/64\n",
      "208/208 [==============================] - 0s 612us/step - loss: 0.3146 - acc: 0.8942 - val_loss: 1.1394 - val_acc: 0.5577\n",
      "Epoch 28/64\n",
      "208/208 [==============================] - 0s 580us/step - loss: 0.2323 - acc: 0.9231 - val_loss: 1.0360 - val_acc: 0.6346\n",
      "Epoch 29/64\n",
      "208/208 [==============================] - 0s 630us/step - loss: 0.1988 - acc: 0.9423 - val_loss: 1.0757 - val_acc: 0.6346\n",
      "Epoch 30/64\n",
      "208/208 [==============================] - 0s 586us/step - loss: 0.2053 - acc: 0.9471 - val_loss: 1.0947 - val_acc: 0.6346\n",
      "Epoch 31/64\n",
      "208/208 [==============================] - 0s 818us/step - loss: 0.2825 - acc: 0.9183 - val_loss: 1.0752 - val_acc: 0.6923\n",
      "Epoch 32/64\n",
      "208/208 [==============================] - 0s 895us/step - loss: 0.2238 - acc: 0.9279 - val_loss: 1.0256 - val_acc: 0.7115\n",
      "Epoch 33/64\n",
      "208/208 [==============================] - 0s 862us/step - loss: 0.2120 - acc: 0.9471 - val_loss: 1.0574 - val_acc: 0.6923\n",
      "Epoch 34/64\n",
      "208/208 [==============================] - 0s 852us/step - loss: 0.2484 - acc: 0.9087 - val_loss: 0.9773 - val_acc: 0.6923\n",
      "Epoch 35/64\n",
      "208/208 [==============================] - 0s 896us/step - loss: 0.1960 - acc: 0.9471 - val_loss: 0.9806 - val_acc: 0.7308\n",
      "Epoch 36/64\n",
      "208/208 [==============================] - 0s 698us/step - loss: 0.1712 - acc: 0.9519 - val_loss: 1.0396 - val_acc: 0.6731\n",
      "Epoch 37/64\n",
      "208/208 [==============================] - 0s 671us/step - loss: 0.1848 - acc: 0.9615 - val_loss: 1.0555 - val_acc: 0.6923\n",
      "Epoch 38/64\n",
      "208/208 [==============================] - 0s 679us/step - loss: 0.1798 - acc: 0.9519 - val_loss: 1.0075 - val_acc: 0.7308\n",
      "Epoch 39/64\n",
      "208/208 [==============================] - 0s 897us/step - loss: 0.1753 - acc: 0.9423 - val_loss: 1.1035 - val_acc: 0.6923\n",
      "Epoch 40/64\n",
      "208/208 [==============================] - 0s 840us/step - loss: 0.1569 - acc: 0.9567 - val_loss: 1.1099 - val_acc: 0.6538\n",
      "Epoch 41/64\n",
      "208/208 [==============================] - 0s 783us/step - loss: 0.1380 - acc: 0.9663 - val_loss: 0.9871 - val_acc: 0.7308\n",
      "Epoch 42/64\n",
      "208/208 [==============================] - 0s 719us/step - loss: 0.1076 - acc: 0.9904 - val_loss: 1.0376 - val_acc: 0.6923\n",
      "Epoch 43/64\n",
      "208/208 [==============================] - 0s 821us/step - loss: 0.1328 - acc: 0.9663 - val_loss: 0.9674 - val_acc: 0.7308\n",
      "Epoch 44/64\n",
      "208/208 [==============================] - 0s 884us/step - loss: 0.1096 - acc: 0.9663 - val_loss: 1.0436 - val_acc: 0.6923\n",
      "Epoch 45/64\n",
      "208/208 [==============================] - 0s 774us/step - loss: 0.1289 - acc: 0.9760 - val_loss: 0.9652 - val_acc: 0.7308\n",
      "Epoch 46/64\n",
      "208/208 [==============================] - 0s 741us/step - loss: 0.1276 - acc: 0.9519 - val_loss: 1.0634 - val_acc: 0.7115\n",
      "Epoch 47/64\n",
      "208/208 [==============================] - 0s 845us/step - loss: 0.1054 - acc: 0.9808 - val_loss: 1.0356 - val_acc: 0.7308\n",
      "Epoch 48/64\n",
      "208/208 [==============================] - 0s 885us/step - loss: 0.1104 - acc: 0.9519 - val_loss: 1.0255 - val_acc: 0.7115\n",
      "Epoch 49/64\n",
      "208/208 [==============================] - 0s 848us/step - loss: 0.1063 - acc: 0.9567 - val_loss: 1.0831 - val_acc: 0.6731\n",
      "Epoch 50/64\n",
      "208/208 [==============================] - 0s 860us/step - loss: 0.0905 - acc: 0.9712 - val_loss: 1.0552 - val_acc: 0.7500\n",
      "Epoch 51/64\n",
      "208/208 [==============================] - 0s 926us/step - loss: 0.1258 - acc: 0.9663 - val_loss: 1.1935 - val_acc: 0.6346\n",
      "Epoch 52/64\n",
      "208/208 [==============================] - 0s 779us/step - loss: 0.1782 - acc: 0.9519 - val_loss: 1.2594 - val_acc: 0.6346\n",
      "Epoch 53/64\n",
      "208/208 [==============================] - 0s 669us/step - loss: 0.0850 - acc: 0.9808 - val_loss: 1.1665 - val_acc: 0.6923\n",
      "Epoch 54/64\n",
      "208/208 [==============================] - 0s 854us/step - loss: 0.1240 - acc: 0.9712 - val_loss: 1.0959 - val_acc: 0.6731\n",
      "Epoch 55/64\n",
      "208/208 [==============================] - 0s 820us/step - loss: 0.1124 - acc: 0.9663 - val_loss: 1.1598 - val_acc: 0.6923\n",
      "Epoch 56/64\n",
      "208/208 [==============================] - 0s 781us/step - loss: 0.1061 - acc: 0.9663 - val_loss: 1.1835 - val_acc: 0.6731\n",
      "Epoch 57/64\n",
      "208/208 [==============================] - 0s 703us/step - loss: 0.0938 - acc: 0.9808 - val_loss: 1.2191 - val_acc: 0.6538\n",
      "Epoch 58/64\n",
      "208/208 [==============================] - 0s 778us/step - loss: 0.0801 - acc: 0.9856 - val_loss: 1.1495 - val_acc: 0.7115\n",
      "Epoch 59/64\n",
      "208/208 [==============================] - 0s 854us/step - loss: 0.0882 - acc: 0.9663 - val_loss: 1.0944 - val_acc: 0.7115\n",
      "Epoch 60/64\n",
      "208/208 [==============================] - 0s 766us/step - loss: 0.0948 - acc: 0.9856 - val_loss: 1.0337 - val_acc: 0.7308\n",
      "Epoch 61/64\n",
      "208/208 [==============================] - 0s 700us/step - loss: 0.0737 - acc: 0.9808 - val_loss: 1.1519 - val_acc: 0.6346\n",
      "Epoch 62/64\n",
      "208/208 [==============================] - 0s 889us/step - loss: 0.0681 - acc: 0.9808 - val_loss: 1.0800 - val_acc: 0.7308\n",
      "Epoch 63/64\n",
      "208/208 [==============================] - 0s 801us/step - loss: 0.0757 - acc: 0.9856 - val_loss: 1.0584 - val_acc: 0.7115\n",
      "Epoch 64/64\n",
      "208/208 [==============================] - 0s 765us/step - loss: 0.0709 - acc: 0.9856 - val_loss: 1.1562 - val_acc: 0.6538\n",
      "Train on 208 samples, validate on 52 samples\n",
      "Epoch 1/65\n",
      "208/208 [==============================] - 12s 56ms/step - loss: 3.2605 - acc: 0.0962 - val_loss: 2.3147 - val_acc: 0.1154\n",
      "Epoch 2/65\n",
      "208/208 [==============================] - 0s 618us/step - loss: 2.3406 - acc: 0.3029 - val_loss: 1.9256 - val_acc: 0.3269\n",
      "Epoch 3/65\n",
      "208/208 [==============================] - 0s 750us/step - loss: 1.7144 - acc: 0.3942 - val_loss: 1.6005 - val_acc: 0.5000\n",
      "Epoch 4/65\n",
      "208/208 [==============================] - 0s 741us/step - loss: 1.5453 - acc: 0.4279 - val_loss: 1.6269 - val_acc: 0.5385\n",
      "Epoch 5/65\n",
      "208/208 [==============================] - 0s 724us/step - loss: 1.5589 - acc: 0.5096 - val_loss: 1.4701 - val_acc: 0.5000\n",
      "Epoch 6/65\n",
      "208/208 [==============================] - 0s 723us/step - loss: 1.1923 - acc: 0.5817 - val_loss: 1.5850 - val_acc: 0.4423\n",
      "Epoch 7/65\n",
      "208/208 [==============================] - 0s 726us/step - loss: 1.3101 - acc: 0.5577 - val_loss: 1.3253 - val_acc: 0.5769\n",
      "Epoch 8/65\n",
      "208/208 [==============================] - 0s 719us/step - loss: 0.9788 - acc: 0.6346 - val_loss: 1.2279 - val_acc: 0.5577\n",
      "Epoch 9/65\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "208/208 [==============================] - 0s 693us/step - loss: 0.9346 - acc: 0.6875 - val_loss: 1.4580 - val_acc: 0.5962\n",
      "Epoch 10/65\n",
      "208/208 [==============================] - 0s 659us/step - loss: 0.8187 - acc: 0.7740 - val_loss: 1.0723 - val_acc: 0.6346\n",
      "Epoch 11/65\n",
      "208/208 [==============================] - 0s 574us/step - loss: 0.7353 - acc: 0.7596 - val_loss: 0.9954 - val_acc: 0.6731\n",
      "Epoch 12/65\n",
      "208/208 [==============================] - 0s 605us/step - loss: 0.7850 - acc: 0.7356 - val_loss: 1.0725 - val_acc: 0.5769\n",
      "Epoch 13/65\n",
      "208/208 [==============================] - 0s 606us/step - loss: 0.5560 - acc: 0.7933 - val_loss: 1.0624 - val_acc: 0.6731\n",
      "Epoch 14/65\n",
      "208/208 [==============================] - 0s 622us/step - loss: 0.5528 - acc: 0.8269 - val_loss: 1.0409 - val_acc: 0.6923\n",
      "Epoch 15/65\n",
      "208/208 [==============================] - 0s 601us/step - loss: 0.5607 - acc: 0.7933 - val_loss: 1.0993 - val_acc: 0.6923\n",
      "Epoch 16/65\n",
      "208/208 [==============================] - 0s 629us/step - loss: 0.5362 - acc: 0.8029 - val_loss: 1.0706 - val_acc: 0.6538\n",
      "Epoch 17/65\n",
      "208/208 [==============================] - 0s 616us/step - loss: 0.5674 - acc: 0.7788 - val_loss: 1.1236 - val_acc: 0.5769\n",
      "Epoch 18/65\n",
      "208/208 [==============================] - 0s 604us/step - loss: 0.4926 - acc: 0.8317 - val_loss: 0.9414 - val_acc: 0.7308\n",
      "Epoch 19/65\n",
      "208/208 [==============================] - 0s 604us/step - loss: 0.3709 - acc: 0.8798 - val_loss: 1.1883 - val_acc: 0.5962\n",
      "Epoch 20/65\n",
      "208/208 [==============================] - 0s 618us/step - loss: 0.4103 - acc: 0.8606 - val_loss: 1.0288 - val_acc: 0.6731\n",
      "Epoch 21/65\n",
      "208/208 [==============================] - 0s 599us/step - loss: 0.3859 - acc: 0.8798 - val_loss: 1.0356 - val_acc: 0.6538\n",
      "Epoch 22/65\n",
      "208/208 [==============================] - 0s 609us/step - loss: 0.3509 - acc: 0.8846 - val_loss: 1.1045 - val_acc: 0.6346\n",
      "Epoch 23/65\n",
      "208/208 [==============================] - 0s 614us/step - loss: 0.3833 - acc: 0.8894 - val_loss: 1.0498 - val_acc: 0.6346\n",
      "Epoch 24/65\n",
      "208/208 [==============================] - 0s 619us/step - loss: 0.3252 - acc: 0.8990 - val_loss: 0.9989 - val_acc: 0.6346\n",
      "Epoch 25/65\n",
      "208/208 [==============================] - 0s 619us/step - loss: 0.3252 - acc: 0.9183 - val_loss: 0.9632 - val_acc: 0.6731\n",
      "Epoch 26/65\n",
      "208/208 [==============================] - 0s 633us/step - loss: 0.2674 - acc: 0.9135 - val_loss: 1.0444 - val_acc: 0.6346\n",
      "Epoch 27/65\n",
      "208/208 [==============================] - 0s 611us/step - loss: 0.3170 - acc: 0.8894 - val_loss: 1.1402 - val_acc: 0.5577\n",
      "Epoch 28/65\n",
      "208/208 [==============================] - 0s 630us/step - loss: 0.2219 - acc: 0.9519 - val_loss: 1.0237 - val_acc: 0.6538\n",
      "Epoch 29/65\n",
      "208/208 [==============================] - 0s 614us/step - loss: 0.1952 - acc: 0.9519 - val_loss: 1.0998 - val_acc: 0.6346\n",
      "Epoch 30/65\n",
      "208/208 [==============================] - 0s 601us/step - loss: 0.2035 - acc: 0.9519 - val_loss: 1.1179 - val_acc: 0.5962\n",
      "Epoch 31/65\n",
      "208/208 [==============================] - 0s 633us/step - loss: 0.2881 - acc: 0.9087 - val_loss: 1.0341 - val_acc: 0.7115\n",
      "Epoch 32/65\n",
      "208/208 [==============================] - 0s 620us/step - loss: 0.2242 - acc: 0.9279 - val_loss: 1.0228 - val_acc: 0.6923\n",
      "Epoch 33/65\n",
      "208/208 [==============================] - 0s 584us/step - loss: 0.2177 - acc: 0.9279 - val_loss: 1.0326 - val_acc: 0.6731\n",
      "Epoch 34/65\n",
      "208/208 [==============================] - 0s 619us/step - loss: 0.2349 - acc: 0.9183 - val_loss: 0.9696 - val_acc: 0.6731\n",
      "Epoch 35/65\n",
      "208/208 [==============================] - 0s 619us/step - loss: 0.2007 - acc: 0.9567 - val_loss: 0.9849 - val_acc: 0.7115\n",
      "Epoch 36/65\n",
      "208/208 [==============================] - 0s 574us/step - loss: 0.1780 - acc: 0.9519 - val_loss: 1.0271 - val_acc: 0.6731\n",
      "Epoch 37/65\n",
      "208/208 [==============================] - 0s 651us/step - loss: 0.1785 - acc: 0.9567 - val_loss: 1.0586 - val_acc: 0.6731\n",
      "Epoch 38/65\n",
      "208/208 [==============================] - 0s 598us/step - loss: 0.1725 - acc: 0.9375 - val_loss: 1.0071 - val_acc: 0.7115\n",
      "Epoch 39/65\n",
      "208/208 [==============================] - 0s 632us/step - loss: 0.1824 - acc: 0.9375 - val_loss: 1.0654 - val_acc: 0.6923\n",
      "Epoch 40/65\n",
      "208/208 [==============================] - 0s 630us/step - loss: 0.1597 - acc: 0.9471 - val_loss: 1.1291 - val_acc: 0.6346\n",
      "Epoch 41/65\n",
      "208/208 [==============================] - 0s 613us/step - loss: 0.1463 - acc: 0.9663 - val_loss: 0.9936 - val_acc: 0.7308\n",
      "Epoch 42/65\n",
      "208/208 [==============================] - 0s 637us/step - loss: 0.1102 - acc: 0.9904 - val_loss: 1.0388 - val_acc: 0.6923\n",
      "Epoch 43/65\n",
      "208/208 [==============================] - 0s 586us/step - loss: 0.1342 - acc: 0.9615 - val_loss: 0.9936 - val_acc: 0.7500\n",
      "Epoch 44/65\n",
      "208/208 [==============================] - 0s 616us/step - loss: 0.1076 - acc: 0.9663 - val_loss: 1.0332 - val_acc: 0.6923\n",
      "Epoch 45/65\n",
      "208/208 [==============================] - 0s 597us/step - loss: 0.1219 - acc: 0.9760 - val_loss: 0.9663 - val_acc: 0.7500\n",
      "Epoch 46/65\n",
      "208/208 [==============================] - 0s 641us/step - loss: 0.1193 - acc: 0.9615 - val_loss: 1.0462 - val_acc: 0.7115\n",
      "Epoch 47/65\n",
      "208/208 [==============================] - 0s 639us/step - loss: 0.0994 - acc: 0.9856 - val_loss: 1.0151 - val_acc: 0.7500\n",
      "Epoch 48/65\n",
      "208/208 [==============================] - 0s 581us/step - loss: 0.1045 - acc: 0.9663 - val_loss: 1.0381 - val_acc: 0.7115\n",
      "Epoch 49/65\n",
      "208/208 [==============================] - 0s 622us/step - loss: 0.1081 - acc: 0.9712 - val_loss: 1.0736 - val_acc: 0.7115\n",
      "Epoch 50/65\n",
      "208/208 [==============================] - 0s 624us/step - loss: 0.0812 - acc: 0.9808 - val_loss: 1.0421 - val_acc: 0.7308\n",
      "Epoch 51/65\n",
      "208/208 [==============================] - 0s 635us/step - loss: 0.1258 - acc: 0.9567 - val_loss: 1.1892 - val_acc: 0.6538\n",
      "Epoch 52/65\n",
      "208/208 [==============================] - 0s 619us/step - loss: 0.1851 - acc: 0.9471 - val_loss: 1.1928 - val_acc: 0.6923\n",
      "Epoch 53/65\n",
      "208/208 [==============================] - 0s 621us/step - loss: 0.0872 - acc: 0.9808 - val_loss: 1.1199 - val_acc: 0.7115\n",
      "Epoch 54/65\n",
      "208/208 [==============================] - 0s 608us/step - loss: 0.1033 - acc: 0.9712 - val_loss: 1.0792 - val_acc: 0.6731\n",
      "Epoch 55/65\n",
      "208/208 [==============================] - 0s 643us/step - loss: 0.1081 - acc: 0.9567 - val_loss: 1.1014 - val_acc: 0.6731\n",
      "Epoch 56/65\n",
      "208/208 [==============================] - 0s 628us/step - loss: 0.1104 - acc: 0.9519 - val_loss: 1.1705 - val_acc: 0.6731\n",
      "Epoch 57/65\n",
      "208/208 [==============================] - 0s 599us/step - loss: 0.0967 - acc: 0.9808 - val_loss: 1.1758 - val_acc: 0.6538\n",
      "Epoch 58/65\n",
      "208/208 [==============================] - 0s 629us/step - loss: 0.0809 - acc: 0.9760 - val_loss: 1.1255 - val_acc: 0.6923\n",
      "Epoch 59/65\n",
      "208/208 [==============================] - 0s 618us/step - loss: 0.0868 - acc: 0.9712 - val_loss: 1.1094 - val_acc: 0.7115\n",
      "Epoch 60/65\n",
      "208/208 [==============================] - 0s 624us/step - loss: 0.1034 - acc: 0.9808 - val_loss: 1.0611 - val_acc: 0.7500\n",
      "Epoch 61/65\n",
      "208/208 [==============================] - 0s 591us/step - loss: 0.0756 - acc: 0.9760 - val_loss: 1.1586 - val_acc: 0.6346\n",
      "Epoch 62/65\n",
      "208/208 [==============================] - 0s 652us/step - loss: 0.0718 - acc: 0.9808 - val_loss: 1.0901 - val_acc: 0.7308\n",
      "Epoch 63/65\n",
      "208/208 [==============================] - 0s 584us/step - loss: 0.0724 - acc: 0.9856 - val_loss: 1.0550 - val_acc: 0.6923\n",
      "Epoch 64/65\n",
      "208/208 [==============================] - 0s 609us/step - loss: 0.0733 - acc: 0.9856 - val_loss: 1.1440 - val_acc: 0.6538\n",
      "Epoch 65/65\n",
      "208/208 [==============================] - 0s 623us/step - loss: 0.0919 - acc: 0.9712 - val_loss: 1.1110 - val_acc: 0.6731\n",
      "Train on 208 samples, validate on 52 samples\n",
      "Epoch 1/66\n",
      "208/208 [==============================] - 12s 56ms/step - loss: 3.2605 - acc: 0.0962 - val_loss: 2.3147 - val_acc: 0.1154\n",
      "Epoch 2/66\n",
      "208/208 [==============================] - 0s 602us/step - loss: 2.3406 - acc: 0.3029 - val_loss: 1.9256 - val_acc: 0.3269\n",
      "Epoch 3/66\n",
      "208/208 [==============================] - 0s 630us/step - loss: 1.7149 - acc: 0.3942 - val_loss: 1.6008 - val_acc: 0.5000\n",
      "Epoch 4/66\n",
      "208/208 [==============================] - 0s 602us/step - loss: 1.5492 - acc: 0.4231 - val_loss: 1.6585 - val_acc: 0.5000\n",
      "Epoch 5/66\n",
      "208/208 [==============================] - 0s 606us/step - loss: 1.5950 - acc: 0.5000 - val_loss: 1.5391 - val_acc: 0.4615\n",
      "Epoch 6/66\n",
      "208/208 [==============================] - 0s 601us/step - loss: 1.2285 - acc: 0.5433 - val_loss: 1.5358 - val_acc: 0.4808\n",
      "Epoch 7/66\n",
      "208/208 [==============================] - 0s 600us/step - loss: 1.2571 - acc: 0.5529 - val_loss: 1.4037 - val_acc: 0.5192\n",
      "Epoch 8/66\n",
      "208/208 [==============================] - 0s 572us/step - loss: 1.0289 - acc: 0.6154 - val_loss: 1.2664 - val_acc: 0.5192\n",
      "Epoch 9/66\n",
      "208/208 [==============================] - 0s 571us/step - loss: 0.9274 - acc: 0.6923 - val_loss: 1.3747 - val_acc: 0.5962\n",
      "Epoch 10/66\n",
      "208/208 [==============================] - 0s 562us/step - loss: 0.7684 - acc: 0.7452 - val_loss: 1.0606 - val_acc: 0.6731\n",
      "Epoch 11/66\n",
      "208/208 [==============================] - 0s 590us/step - loss: 0.7369 - acc: 0.7837 - val_loss: 0.9985 - val_acc: 0.6731\n",
      "Epoch 12/66\n",
      "208/208 [==============================] - 0s 569us/step - loss: 0.7456 - acc: 0.7404 - val_loss: 1.0393 - val_acc: 0.6154\n",
      "Epoch 13/66\n",
      "208/208 [==============================] - 0s 576us/step - loss: 0.5761 - acc: 0.8125 - val_loss: 1.0475 - val_acc: 0.5962\n",
      "Epoch 14/66\n",
      "208/208 [==============================] - 0s 603us/step - loss: 0.5802 - acc: 0.8221 - val_loss: 1.0090 - val_acc: 0.6731\n",
      "Epoch 15/66\n",
      "208/208 [==============================] - 0s 575us/step - loss: 0.5543 - acc: 0.8077 - val_loss: 1.1060 - val_acc: 0.6538\n",
      "Epoch 16/66\n",
      "208/208 [==============================] - 0s 588us/step - loss: 0.5533 - acc: 0.8173 - val_loss: 1.0599 - val_acc: 0.6731\n",
      "Epoch 17/66\n",
      "208/208 [==============================] - 0s 574us/step - loss: 0.5778 - acc: 0.7885 - val_loss: 1.1521 - val_acc: 0.5577\n",
      "Epoch 18/66\n",
      "208/208 [==============================] - 0s 589us/step - loss: 0.4858 - acc: 0.8221 - val_loss: 0.9423 - val_acc: 0.7308\n",
      "Epoch 19/66\n",
      "208/208 [==============================] - 0s 592us/step - loss: 0.3667 - acc: 0.8750 - val_loss: 1.2176 - val_acc: 0.5962\n",
      "Epoch 20/66\n",
      "208/208 [==============================] - 0s 570us/step - loss: 0.4188 - acc: 0.8558 - val_loss: 1.0571 - val_acc: 0.7115\n",
      "Epoch 21/66\n",
      "208/208 [==============================] - 0s 591us/step - loss: 0.3544 - acc: 0.8942 - val_loss: 1.0694 - val_acc: 0.6346\n",
      "Epoch 22/66\n",
      "208/208 [==============================] - 0s 591us/step - loss: 0.3503 - acc: 0.8894 - val_loss: 1.1553 - val_acc: 0.6154\n",
      "Epoch 23/66\n",
      "208/208 [==============================] - 0s 596us/step - loss: 0.3959 - acc: 0.8654 - val_loss: 1.0520 - val_acc: 0.6538\n",
      "Epoch 24/66\n",
      "208/208 [==============================] - 0s 581us/step - loss: 0.3414 - acc: 0.8894 - val_loss: 1.0496 - val_acc: 0.6154\n",
      "Epoch 25/66\n",
      "208/208 [==============================] - 0s 581us/step - loss: 0.3310 - acc: 0.8990 - val_loss: 0.9753 - val_acc: 0.6923\n",
      "Epoch 26/66\n",
      "208/208 [==============================] - 0s 592us/step - loss: 0.2627 - acc: 0.9183 - val_loss: 0.9796 - val_acc: 0.6923\n",
      "Epoch 27/66\n",
      "208/208 [==============================] - 0s 572us/step - loss: 0.2825 - acc: 0.9231 - val_loss: 1.1200 - val_acc: 0.5769\n",
      "Epoch 28/66\n",
      "208/208 [==============================] - 0s 588us/step - loss: 0.2135 - acc: 0.9423 - val_loss: 1.0090 - val_acc: 0.6538\n",
      "Epoch 29/66\n",
      "208/208 [==============================] - 0s 597us/step - loss: 0.2017 - acc: 0.9471 - val_loss: 1.1047 - val_acc: 0.6154\n",
      "Epoch 30/66\n",
      "208/208 [==============================] - 0s 598us/step - loss: 0.2115 - acc: 0.9375 - val_loss: 1.1359 - val_acc: 0.6154\n",
      "Epoch 31/66\n",
      "208/208 [==============================] - 0s 576us/step - loss: 0.2963 - acc: 0.8846 - val_loss: 1.0599 - val_acc: 0.6923\n",
      "Epoch 32/66\n",
      "208/208 [==============================] - 0s 586us/step - loss: 0.2228 - acc: 0.9327 - val_loss: 1.0463 - val_acc: 0.6538\n",
      "Epoch 33/66\n",
      "208/208 [==============================] - 0s 597us/step - loss: 0.2315 - acc: 0.9279 - val_loss: 1.0530 - val_acc: 0.7500\n",
      "Epoch 34/66\n",
      "208/208 [==============================] - 0s 589us/step - loss: 0.2328 - acc: 0.9135 - val_loss: 1.0239 - val_acc: 0.6923\n",
      "Epoch 35/66\n",
      "208/208 [==============================] - 0s 581us/step - loss: 0.1997 - acc: 0.9471 - val_loss: 0.9922 - val_acc: 0.7500\n",
      "Epoch 36/66\n",
      "208/208 [==============================] - 0s 574us/step - loss: 0.1562 - acc: 0.9663 - val_loss: 1.0452 - val_acc: 0.6923\n",
      "Epoch 37/66\n",
      "208/208 [==============================] - 0s 588us/step - loss: 0.1697 - acc: 0.9567 - val_loss: 1.0714 - val_acc: 0.6731\n",
      "Epoch 38/66\n",
      "208/208 [==============================] - 0s 593us/step - loss: 0.1733 - acc: 0.9423 - val_loss: 1.0072 - val_acc: 0.7500\n",
      "Epoch 39/66\n",
      "208/208 [==============================] - 0s 586us/step - loss: 0.1640 - acc: 0.9567 - val_loss: 1.1092 - val_acc: 0.7115\n",
      "Epoch 40/66\n",
      "208/208 [==============================] - 0s 599us/step - loss: 0.1642 - acc: 0.9471 - val_loss: 1.1305 - val_acc: 0.6346\n",
      "Epoch 41/66\n",
      "208/208 [==============================] - 0s 593us/step - loss: 0.1291 - acc: 0.9712 - val_loss: 1.0108 - val_acc: 0.7308\n",
      "Epoch 42/66\n",
      "208/208 [==============================] - 0s 591us/step - loss: 0.1074 - acc: 0.9856 - val_loss: 1.0725 - val_acc: 0.6923\n",
      "Epoch 43/66\n",
      "208/208 [==============================] - 0s 589us/step - loss: 0.1365 - acc: 0.9712 - val_loss: 1.0196 - val_acc: 0.7500\n",
      "Epoch 44/66\n",
      "208/208 [==============================] - 0s 590us/step - loss: 0.0964 - acc: 0.9760 - val_loss: 1.0522 - val_acc: 0.7308\n",
      "Epoch 45/66\n",
      "208/208 [==============================] - 0s 609us/step - loss: 0.1126 - acc: 0.9808 - val_loss: 1.0046 - val_acc: 0.7308\n",
      "Epoch 46/66\n",
      "208/208 [==============================] - 0s 585us/step - loss: 0.1179 - acc: 0.9567 - val_loss: 1.0673 - val_acc: 0.7500\n",
      "Epoch 47/66\n",
      "208/208 [==============================] - 0s 589us/step - loss: 0.1037 - acc: 0.9712 - val_loss: 1.0393 - val_acc: 0.7500\n",
      "Epoch 48/66\n",
      "208/208 [==============================] - 0s 597us/step - loss: 0.1225 - acc: 0.9471 - val_loss: 1.0167 - val_acc: 0.7308\n",
      "Epoch 49/66\n",
      "208/208 [==============================] - 0s 579us/step - loss: 0.0987 - acc: 0.9808 - val_loss: 1.1299 - val_acc: 0.6731\n",
      "Epoch 50/66\n",
      "208/208 [==============================] - 0s 597us/step - loss: 0.0813 - acc: 0.9808 - val_loss: 1.0676 - val_acc: 0.7692\n",
      "Epoch 51/66\n",
      "208/208 [==============================] - 0s 581us/step - loss: 0.1190 - acc: 0.9615 - val_loss: 1.2315 - val_acc: 0.6538\n",
      "Epoch 52/66\n",
      "208/208 [==============================] - 0s 594us/step - loss: 0.2128 - acc: 0.9327 - val_loss: 1.2862 - val_acc: 0.6538\n",
      "Epoch 53/66\n",
      "208/208 [==============================] - 0s 562us/step - loss: 0.1007 - acc: 0.9760 - val_loss: 1.1225 - val_acc: 0.6923\n",
      "Epoch 54/66\n",
      "208/208 [==============================] - 0s 588us/step - loss: 0.1070 - acc: 0.9760 - val_loss: 1.1044 - val_acc: 0.6923\n",
      "Epoch 55/66\n",
      "208/208 [==============================] - 0s 590us/step - loss: 0.1072 - acc: 0.9712 - val_loss: 1.1003 - val_acc: 0.6923\n",
      "Epoch 56/66\n",
      "208/208 [==============================] - 0s 602us/step - loss: 0.1096 - acc: 0.9712 - val_loss: 1.1901 - val_acc: 0.6923\n",
      "Epoch 57/66\n",
      "208/208 [==============================] - 0s 582us/step - loss: 0.0942 - acc: 0.9808 - val_loss: 1.1913 - val_acc: 0.6731\n",
      "Epoch 58/66\n",
      "208/208 [==============================] - 0s 565us/step - loss: 0.0934 - acc: 0.9808 - val_loss: 1.0994 - val_acc: 0.7115\n",
      "Epoch 59/66\n",
      "208/208 [==============================] - 0s 587us/step - loss: 0.0901 - acc: 0.9712 - val_loss: 1.1140 - val_acc: 0.7308\n",
      "Epoch 60/66\n",
      "208/208 [==============================] - 0s 589us/step - loss: 0.0986 - acc: 0.9808 - val_loss: 1.0623 - val_acc: 0.7115\n",
      "Epoch 61/66\n",
      "208/208 [==============================] - 0s 590us/step - loss: 0.0680 - acc: 0.9856 - val_loss: 1.2294 - val_acc: 0.6346\n",
      "Epoch 62/66\n",
      "208/208 [==============================] - 0s 578us/step - loss: 0.0695 - acc: 0.9808 - val_loss: 1.1267 - val_acc: 0.7115\n",
      "Epoch 63/66\n",
      "208/208 [==============================] - 0s 580us/step - loss: 0.0822 - acc: 0.9712 - val_loss: 1.1083 - val_acc: 0.7115\n",
      "Epoch 64/66\n",
      "208/208 [==============================] - 0s 595us/step - loss: 0.0866 - acc: 0.9808 - val_loss: 1.2439 - val_acc: 0.6346\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65/66\n",
      "208/208 [==============================] - 0s 596us/step - loss: 0.1019 - acc: 0.9663 - val_loss: 1.1216 - val_acc: 0.6923\n",
      "Epoch 66/66\n",
      "208/208 [==============================] - 0s 571us/step - loss: 0.1169 - acc: 0.9615 - val_loss: 1.1254 - val_acc: 0.6923\n",
      "Train on 208 samples, validate on 52 samples\n",
      "Epoch 1/67\n",
      "208/208 [==============================] - 12s 59ms/step - loss: 3.2605 - acc: 0.0962 - val_loss: 2.3147 - val_acc: 0.1154\n",
      "Epoch 2/67\n",
      "208/208 [==============================] - 0s 844us/step - loss: 2.3406 - acc: 0.3029 - val_loss: 1.9256 - val_acc: 0.3269\n",
      "Epoch 3/67\n",
      "208/208 [==============================] - 0s 747us/step - loss: 1.7144 - acc: 0.3942 - val_loss: 1.6005 - val_acc: 0.5000\n",
      "Epoch 4/67\n",
      "208/208 [==============================] - 0s 684us/step - loss: 1.5453 - acc: 0.4279 - val_loss: 1.6269 - val_acc: 0.5385\n",
      "Epoch 5/67\n",
      "208/208 [==============================] - 0s 790us/step - loss: 1.5589 - acc: 0.5096 - val_loss: 1.4701 - val_acc: 0.5000\n",
      "Epoch 6/67\n",
      "208/208 [==============================] - 0s 776us/step - loss: 1.1923 - acc: 0.5817 - val_loss: 1.5850 - val_acc: 0.4423\n",
      "Epoch 7/67\n",
      "208/208 [==============================] - 0s 621us/step - loss: 1.3101 - acc: 0.5577 - val_loss: 1.3253 - val_acc: 0.5769\n",
      "Epoch 8/67\n",
      "208/208 [==============================] - 0s 758us/step - loss: 0.9788 - acc: 0.6346 - val_loss: 1.2279 - val_acc: 0.5577\n",
      "Epoch 9/67\n",
      "208/208 [==============================] - 0s 830us/step - loss: 0.9346 - acc: 0.6875 - val_loss: 1.4580 - val_acc: 0.5962\n",
      "Epoch 10/67\n",
      "208/208 [==============================] - 0s 630us/step - loss: 0.8187 - acc: 0.7740 - val_loss: 1.0723 - val_acc: 0.6346\n",
      "Epoch 11/67\n",
      "208/208 [==============================] - 0s 668us/step - loss: 0.7353 - acc: 0.7596 - val_loss: 0.9954 - val_acc: 0.6731\n",
      "Epoch 12/67\n",
      "208/208 [==============================] - 0s 934us/step - loss: 0.7850 - acc: 0.7356 - val_loss: 1.0725 - val_acc: 0.5769\n",
      "Epoch 13/67\n",
      "208/208 [==============================] - 0s 727us/step - loss: 0.5560 - acc: 0.7933 - val_loss: 1.0624 - val_acc: 0.6731\n",
      "Epoch 14/67\n",
      "208/208 [==============================] - 0s 669us/step - loss: 0.5528 - acc: 0.8269 - val_loss: 1.0404 - val_acc: 0.6923\n",
      "Epoch 15/67\n",
      "208/208 [==============================] - 0s 896us/step - loss: 0.5593 - acc: 0.7885 - val_loss: 1.0953 - val_acc: 0.6923\n",
      "Epoch 16/67\n",
      "208/208 [==============================] - 0s 738us/step - loss: 0.5367 - acc: 0.8029 - val_loss: 1.0774 - val_acc: 0.6538\n",
      "Epoch 17/67\n",
      "208/208 [==============================] - 0s 672us/step - loss: 0.5675 - acc: 0.7885 - val_loss: 1.1222 - val_acc: 0.5577\n",
      "Epoch 18/67\n",
      "208/208 [==============================] - 0s 924us/step - loss: 0.4930 - acc: 0.8221 - val_loss: 0.9414 - val_acc: 0.7308\n",
      "Epoch 19/67\n",
      "208/208 [==============================] - 0s 767us/step - loss: 0.3706 - acc: 0.8798 - val_loss: 1.1944 - val_acc: 0.5769\n",
      "Epoch 20/67\n",
      "208/208 [==============================] - 0s 761us/step - loss: 0.4193 - acc: 0.8654 - val_loss: 1.0358 - val_acc: 0.6731\n",
      "Epoch 21/67\n",
      "208/208 [==============================] - 0s 977us/step - loss: 0.3843 - acc: 0.8798 - val_loss: 1.0398 - val_acc: 0.6731\n",
      "Epoch 22/67\n",
      "208/208 [==============================] - 0s 575us/step - loss: 0.3499 - acc: 0.8846 - val_loss: 1.0967 - val_acc: 0.6538\n",
      "Epoch 23/67\n",
      "208/208 [==============================] - 0s 783us/step - loss: 0.3756 - acc: 0.8846 - val_loss: 1.0502 - val_acc: 0.6346\n",
      "Epoch 24/67\n",
      "208/208 [==============================] - 0s 920us/step - loss: 0.3208 - acc: 0.9038 - val_loss: 1.0037 - val_acc: 0.6538\n",
      "Epoch 25/67\n",
      "208/208 [==============================] - 0s 695us/step - loss: 0.3328 - acc: 0.9135 - val_loss: 0.9661 - val_acc: 0.6731\n",
      "Epoch 26/67\n",
      "208/208 [==============================] - 0s 731us/step - loss: 0.2630 - acc: 0.9135 - val_loss: 1.0296 - val_acc: 0.6346\n",
      "Epoch 27/67\n",
      "208/208 [==============================] - 0s 593us/step - loss: 0.3162 - acc: 0.9038 - val_loss: 1.1386 - val_acc: 0.5385\n",
      "Epoch 28/67\n",
      "208/208 [==============================] - 0s 665us/step - loss: 0.2284 - acc: 0.9519 - val_loss: 1.0425 - val_acc: 0.6346\n",
      "Epoch 29/67\n",
      "208/208 [==============================] - 0s 674us/step - loss: 0.2003 - acc: 0.9375 - val_loss: 1.1107 - val_acc: 0.6346\n",
      "Epoch 30/67\n",
      "208/208 [==============================] - 0s 615us/step - loss: 0.2084 - acc: 0.9471 - val_loss: 1.1170 - val_acc: 0.5962\n",
      "Epoch 31/67\n",
      "208/208 [==============================] - 0s 657us/step - loss: 0.2852 - acc: 0.9135 - val_loss: 1.0340 - val_acc: 0.6923\n",
      "Epoch 32/67\n",
      "208/208 [==============================] - 0s 629us/step - loss: 0.2169 - acc: 0.9423 - val_loss: 1.0292 - val_acc: 0.7115\n",
      "Epoch 33/67\n",
      "208/208 [==============================] - 0s 627us/step - loss: 0.2252 - acc: 0.9231 - val_loss: 1.0604 - val_acc: 0.7115\n",
      "Epoch 34/67\n",
      "208/208 [==============================] - 0s 672us/step - loss: 0.2510 - acc: 0.9135 - val_loss: 0.9785 - val_acc: 0.7115\n",
      "Epoch 35/67\n",
      "208/208 [==============================] - 0s 913us/step - loss: 0.2005 - acc: 0.9519 - val_loss: 0.9934 - val_acc: 0.6923\n",
      "Epoch 36/67\n",
      "208/208 [==============================] - 0s 705us/step - loss: 0.1707 - acc: 0.9471 - val_loss: 1.0380 - val_acc: 0.6923\n",
      "Epoch 37/67\n",
      "208/208 [==============================] - 0s 753us/step - loss: 0.1786 - acc: 0.9567 - val_loss: 1.0664 - val_acc: 0.6731\n",
      "Epoch 38/67\n",
      "208/208 [==============================] - 0s 801us/step - loss: 0.1787 - acc: 0.9471 - val_loss: 1.0044 - val_acc: 0.6923\n",
      "Epoch 39/67\n",
      "208/208 [==============================] - 0s 731us/step - loss: 0.1831 - acc: 0.9327 - val_loss: 1.0838 - val_acc: 0.6923\n",
      "Epoch 40/67\n",
      "208/208 [==============================] - 0s 726us/step - loss: 0.1596 - acc: 0.9615 - val_loss: 1.1256 - val_acc: 0.6346\n",
      "Epoch 41/67\n",
      "208/208 [==============================] - 0s 637us/step - loss: 0.1425 - acc: 0.9663 - val_loss: 0.9934 - val_acc: 0.7308\n",
      "Epoch 42/67\n",
      "208/208 [==============================] - 0s 662us/step - loss: 0.1032 - acc: 0.9952 - val_loss: 1.0513 - val_acc: 0.6731\n",
      "Epoch 43/67\n",
      "208/208 [==============================] - 0s 809us/step - loss: 0.1405 - acc: 0.9519 - val_loss: 0.9834 - val_acc: 0.7500\n",
      "Epoch 44/67\n",
      "208/208 [==============================] - 0s 730us/step - loss: 0.0981 - acc: 0.9760 - val_loss: 1.0316 - val_acc: 0.6731\n",
      "Epoch 45/67\n",
      "208/208 [==============================] - 0s 842us/step - loss: 0.1186 - acc: 0.9760 - val_loss: 0.9661 - val_acc: 0.7500\n",
      "Epoch 46/67\n",
      "208/208 [==============================] - 0s 892us/step - loss: 0.1197 - acc: 0.9615 - val_loss: 1.0464 - val_acc: 0.6923\n",
      "Epoch 47/67\n",
      "208/208 [==============================] - 0s 770us/step - loss: 0.1035 - acc: 0.9760 - val_loss: 1.0184 - val_acc: 0.7500\n",
      "Epoch 48/67\n",
      "208/208 [==============================] - 0s 643us/step - loss: 0.1082 - acc: 0.9663 - val_loss: 1.0128 - val_acc: 0.7115\n",
      "Epoch 49/67\n",
      "208/208 [==============================] - 0s 706us/step - loss: 0.0956 - acc: 0.9712 - val_loss: 1.0631 - val_acc: 0.6923\n",
      "Epoch 50/67\n",
      "208/208 [==============================] - 0s 721us/step - loss: 0.0882 - acc: 0.9808 - val_loss: 1.0360 - val_acc: 0.7308\n",
      "Epoch 51/67\n",
      "208/208 [==============================] - 0s 759us/step - loss: 0.1273 - acc: 0.9615 - val_loss: 1.2166 - val_acc: 0.6154\n",
      "Epoch 52/67\n",
      "208/208 [==============================] - 0s 720us/step - loss: 0.1976 - acc: 0.9375 - val_loss: 1.2123 - val_acc: 0.6538\n",
      "Epoch 53/67\n",
      "208/208 [==============================] - 0s 741us/step - loss: 0.0876 - acc: 0.9760 - val_loss: 1.1073 - val_acc: 0.7115\n",
      "Epoch 54/67\n",
      "208/208 [==============================] - 0s 733us/step - loss: 0.1101 - acc: 0.9712 - val_loss: 1.0648 - val_acc: 0.6731\n",
      "Epoch 55/67\n",
      "208/208 [==============================] - 0s 828us/step - loss: 0.1029 - acc: 0.9615 - val_loss: 1.0824 - val_acc: 0.7115\n",
      "Epoch 56/67\n",
      "208/208 [==============================] - 0s 824us/step - loss: 0.1018 - acc: 0.9808 - val_loss: 1.1036 - val_acc: 0.6731\n",
      "Epoch 57/67\n",
      "208/208 [==============================] - 0s 714us/step - loss: 0.0929 - acc: 0.9712 - val_loss: 1.1383 - val_acc: 0.6731\n",
      "Epoch 58/67\n",
      "208/208 [==============================] - 0s 717us/step - loss: 0.0749 - acc: 0.9856 - val_loss: 1.1080 - val_acc: 0.7115\n",
      "Epoch 59/67\n",
      "208/208 [==============================] - 0s 757us/step - loss: 0.0856 - acc: 0.9712 - val_loss: 1.1155 - val_acc: 0.7115\n",
      "Epoch 60/67\n",
      "208/208 [==============================] - 0s 872us/step - loss: 0.1083 - acc: 0.9808 - val_loss: 1.0417 - val_acc: 0.7308\n",
      "Epoch 61/67\n",
      "208/208 [==============================] - 0s 729us/step - loss: 0.0746 - acc: 0.9808 - val_loss: 1.1322 - val_acc: 0.6538\n",
      "Epoch 62/67\n",
      "208/208 [==============================] - 0s 647us/step - loss: 0.0769 - acc: 0.9760 - val_loss: 1.0833 - val_acc: 0.7308\n",
      "Epoch 63/67\n",
      "208/208 [==============================] - 0s 735us/step - loss: 0.0747 - acc: 0.9856 - val_loss: 1.0773 - val_acc: 0.6923\n",
      "Epoch 64/67\n",
      "208/208 [==============================] - 0s 505us/step - loss: 0.0791 - acc: 0.9808 - val_loss: 1.1671 - val_acc: 0.6346\n",
      "Epoch 65/67\n",
      "208/208 [==============================] - 0s 505us/step - loss: 0.0966 - acc: 0.9760 - val_loss: 1.1254 - val_acc: 0.7115\n",
      "Epoch 66/67\n",
      "208/208 [==============================] - 0s 663us/step - loss: 0.1147 - acc: 0.9760 - val_loss: 1.0353 - val_acc: 0.7115\n",
      "Epoch 67/67\n",
      "208/208 [==============================] - 0s 662us/step - loss: 0.0747 - acc: 0.9712 - val_loss: 1.1812 - val_acc: 0.6923\n",
      "Train on 208 samples, validate on 52 samples\n",
      "Epoch 1/68\n",
      "208/208 [==============================] - 12s 57ms/step - loss: 3.2605 - acc: 0.0962 - val_loss: 2.3147 - val_acc: 0.1154\n",
      "Epoch 2/68\n",
      "208/208 [==============================] - 0s 649us/step - loss: 2.3406 - acc: 0.3029 - val_loss: 1.9256 - val_acc: 0.3269\n",
      "Epoch 3/68\n",
      "208/208 [==============================] - 0s 746us/step - loss: 1.7144 - acc: 0.3942 - val_loss: 1.6005 - val_acc: 0.5000\n",
      "Epoch 4/68\n",
      "208/208 [==============================] - 0s 728us/step - loss: 1.5453 - acc: 0.4279 - val_loss: 1.6269 - val_acc: 0.5385\n",
      "Epoch 5/68\n",
      "208/208 [==============================] - 0s 745us/step - loss: 1.5589 - acc: 0.5096 - val_loss: 1.4701 - val_acc: 0.5000\n",
      "Epoch 6/68\n",
      "208/208 [==============================] - 0s 720us/step - loss: 1.1923 - acc: 0.5817 - val_loss: 1.5850 - val_acc: 0.4423\n",
      "Epoch 7/68\n",
      "208/208 [==============================] - 0s 721us/step - loss: 1.3101 - acc: 0.5577 - val_loss: 1.3253 - val_acc: 0.5769\n",
      "Epoch 8/68\n",
      "208/208 [==============================] - 0s 725us/step - loss: 0.9788 - acc: 0.6346 - val_loss: 1.2279 - val_acc: 0.5577\n",
      "Epoch 9/68\n",
      "208/208 [==============================] - 0s 709us/step - loss: 0.9346 - acc: 0.6875 - val_loss: 1.4580 - val_acc: 0.5962\n",
      "Epoch 10/68\n",
      "208/208 [==============================] - 0s 647us/step - loss: 0.8186 - acc: 0.7740 - val_loss: 1.0742 - val_acc: 0.6346\n",
      "Epoch 11/68\n",
      "208/208 [==============================] - 0s 641us/step - loss: 0.7352 - acc: 0.7500 - val_loss: 0.9857 - val_acc: 0.6731\n",
      "Epoch 12/68\n",
      "208/208 [==============================] - 0s 739us/step - loss: 0.7763 - acc: 0.7308 - val_loss: 1.0605 - val_acc: 0.6346\n",
      "Epoch 13/68\n",
      "208/208 [==============================] - 0s 784us/step - loss: 0.5542 - acc: 0.7933 - val_loss: 1.0590 - val_acc: 0.6731\n",
      "Epoch 14/68\n",
      "208/208 [==============================] - 0s 699us/step - loss: 0.5553 - acc: 0.8269 - val_loss: 1.0272 - val_acc: 0.6923\n",
      "Epoch 15/68\n",
      "208/208 [==============================] - 0s 732us/step - loss: 0.5717 - acc: 0.7837 - val_loss: 1.1139 - val_acc: 0.6923\n",
      "Epoch 16/68\n",
      "208/208 [==============================] - 0s 730us/step - loss: 0.5356 - acc: 0.8029 - val_loss: 1.0745 - val_acc: 0.6731\n",
      "Epoch 17/68\n",
      "208/208 [==============================] - 0s 713us/step - loss: 0.5717 - acc: 0.8029 - val_loss: 1.0940 - val_acc: 0.5769\n",
      "Epoch 18/68\n",
      "208/208 [==============================] - 0s 711us/step - loss: 0.4842 - acc: 0.8413 - val_loss: 0.9500 - val_acc: 0.7308\n",
      "Epoch 19/68\n",
      "208/208 [==============================] - 0s 718us/step - loss: 0.3662 - acc: 0.8846 - val_loss: 1.2064 - val_acc: 0.5577\n",
      "Epoch 20/68\n",
      "208/208 [==============================] - 0s 730us/step - loss: 0.3979 - acc: 0.8894 - val_loss: 1.0106 - val_acc: 0.6731\n",
      "Epoch 21/68\n",
      "208/208 [==============================] - 0s 729us/step - loss: 0.3664 - acc: 0.8894 - val_loss: 1.0594 - val_acc: 0.6538\n",
      "Epoch 22/68\n",
      "208/208 [==============================] - 0s 719us/step - loss: 0.3406 - acc: 0.8942 - val_loss: 1.1148 - val_acc: 0.6346\n",
      "Epoch 23/68\n",
      "208/208 [==============================] - 0s 713us/step - loss: 0.3681 - acc: 0.8798 - val_loss: 1.0546 - val_acc: 0.6538\n",
      "Epoch 24/68\n",
      "208/208 [==============================] - 0s 732us/step - loss: 0.3250 - acc: 0.8990 - val_loss: 1.0177 - val_acc: 0.6538\n",
      "Epoch 25/68\n",
      "208/208 [==============================] - 0s 727us/step - loss: 0.3324 - acc: 0.8990 - val_loss: 0.9842 - val_acc: 0.7115\n",
      "Epoch 26/68\n",
      "208/208 [==============================] - 0s 723us/step - loss: 0.2678 - acc: 0.8942 - val_loss: 1.0501 - val_acc: 0.6538\n",
      "Epoch 27/68\n",
      "208/208 [==============================] - 0s 716us/step - loss: 0.3140 - acc: 0.8990 - val_loss: 1.1749 - val_acc: 0.5577\n",
      "Epoch 28/68\n",
      "208/208 [==============================] - 0s 727us/step - loss: 0.2257 - acc: 0.9375 - val_loss: 1.0647 - val_acc: 0.6346\n",
      "Epoch 29/68\n",
      "208/208 [==============================] - 0s 675us/step - loss: 0.2062 - acc: 0.9471 - val_loss: 1.0814 - val_acc: 0.6731\n",
      "Epoch 30/68\n",
      "208/208 [==============================] - 0s 648us/step - loss: 0.2162 - acc: 0.9375 - val_loss: 1.1297 - val_acc: 0.5962\n",
      "Epoch 31/68\n",
      "208/208 [==============================] - 0s 715us/step - loss: 0.2873 - acc: 0.9038 - val_loss: 1.0599 - val_acc: 0.6923\n",
      "Epoch 32/68\n",
      "208/208 [==============================] - 0s 736us/step - loss: 0.2222 - acc: 0.9423 - val_loss: 1.0286 - val_acc: 0.7115\n",
      "Epoch 33/68\n",
      "208/208 [==============================] - 0s 705us/step - loss: 0.2218 - acc: 0.9183 - val_loss: 1.0586 - val_acc: 0.6923\n",
      "Epoch 34/68\n",
      "208/208 [==============================] - 0s 721us/step - loss: 0.2628 - acc: 0.9087 - val_loss: 0.9615 - val_acc: 0.7115\n",
      "Epoch 35/68\n",
      "208/208 [==============================] - 0s 682us/step - loss: 0.2029 - acc: 0.9615 - val_loss: 0.9830 - val_acc: 0.7308\n",
      "Epoch 36/68\n",
      "208/208 [==============================] - 0s 772us/step - loss: 0.1630 - acc: 0.9615 - val_loss: 1.0181 - val_acc: 0.6923\n",
      "Epoch 37/68\n",
      "208/208 [==============================] - 0s 737us/step - loss: 0.1715 - acc: 0.9615 - val_loss: 1.0699 - val_acc: 0.6731\n",
      "Epoch 38/68\n",
      "208/208 [==============================] - 0s 695us/step - loss: 0.1729 - acc: 0.9375 - val_loss: 1.0179 - val_acc: 0.7308\n",
      "Epoch 39/68\n",
      "208/208 [==============================] - 0s 731us/step - loss: 0.2038 - acc: 0.9231 - val_loss: 1.1000 - val_acc: 0.6538\n",
      "Epoch 40/68\n",
      "208/208 [==============================] - 0s 747us/step - loss: 0.1626 - acc: 0.9615 - val_loss: 1.1636 - val_acc: 0.6346\n",
      "Epoch 41/68\n",
      "208/208 [==============================] - 0s 718us/step - loss: 0.1393 - acc: 0.9712 - val_loss: 0.9943 - val_acc: 0.7308\n",
      "Epoch 42/68\n",
      "208/208 [==============================] - 0s 668us/step - loss: 0.1013 - acc: 0.9904 - val_loss: 1.0690 - val_acc: 0.6923\n",
      "Epoch 43/68\n",
      "208/208 [==============================] - 0s 713us/step - loss: 0.1448 - acc: 0.9615 - val_loss: 0.9848 - val_acc: 0.7500\n",
      "Epoch 44/68\n",
      "208/208 [==============================] - 0s 738us/step - loss: 0.0984 - acc: 0.9760 - val_loss: 1.0396 - val_acc: 0.6923\n",
      "Epoch 45/68\n",
      "208/208 [==============================] - 0s 715us/step - loss: 0.1227 - acc: 0.9760 - val_loss: 0.9803 - val_acc: 0.7308\n",
      "Epoch 46/68\n",
      "208/208 [==============================] - 0s 697us/step - loss: 0.1231 - acc: 0.9615 - val_loss: 1.0595 - val_acc: 0.7500\n",
      "Epoch 47/68\n",
      "208/208 [==============================] - 0s 747us/step - loss: 0.0986 - acc: 0.9760 - val_loss: 1.0155 - val_acc: 0.7500\n",
      "Epoch 48/68\n",
      "208/208 [==============================] - 0s 743us/step - loss: 0.1051 - acc: 0.9663 - val_loss: 1.0126 - val_acc: 0.7115\n",
      "Epoch 49/68\n",
      "208/208 [==============================] - 0s 717us/step - loss: 0.0945 - acc: 0.9760 - val_loss: 1.0513 - val_acc: 0.7308\n",
      "Epoch 50/68\n",
      "208/208 [==============================] - 0s 741us/step - loss: 0.0810 - acc: 0.9808 - val_loss: 1.0501 - val_acc: 0.7500\n",
      "Epoch 51/68\n",
      "208/208 [==============================] - 0s 754us/step - loss: 0.1247 - acc: 0.9663 - val_loss: 1.2003 - val_acc: 0.6346\n",
      "Epoch 52/68\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "208/208 [==============================] - 0s 735us/step - loss: 0.1781 - acc: 0.9375 - val_loss: 1.2741 - val_acc: 0.6346\n",
      "Epoch 53/68\n",
      "208/208 [==============================] - 0s 645us/step - loss: 0.0826 - acc: 0.9808 - val_loss: 1.1386 - val_acc: 0.7308\n",
      "Epoch 54/68\n",
      "208/208 [==============================] - 0s 564us/step - loss: 0.1043 - acc: 0.9663 - val_loss: 1.1172 - val_acc: 0.6731\n",
      "Epoch 55/68\n",
      "208/208 [==============================] - 0s 599us/step - loss: 0.1058 - acc: 0.9615 - val_loss: 1.1613 - val_acc: 0.6731\n",
      "Epoch 56/68\n",
      "208/208 [==============================] - 0s 554us/step - loss: 0.0943 - acc: 0.9808 - val_loss: 1.1991 - val_acc: 0.6731\n",
      "Epoch 57/68\n",
      "208/208 [==============================] - 0s 628us/step - loss: 0.0959 - acc: 0.9712 - val_loss: 1.2080 - val_acc: 0.6538\n",
      "Epoch 58/68\n",
      "208/208 [==============================] - 0s 581us/step - loss: 0.0781 - acc: 0.9808 - val_loss: 1.1576 - val_acc: 0.7115\n",
      "Epoch 59/68\n",
      "208/208 [==============================] - 0s 610us/step - loss: 0.0864 - acc: 0.9760 - val_loss: 1.1544 - val_acc: 0.6923\n",
      "Epoch 60/68\n",
      "208/208 [==============================] - 0s 577us/step - loss: 0.1097 - acc: 0.9856 - val_loss: 1.0777 - val_acc: 0.7308\n",
      "Epoch 61/68\n",
      "208/208 [==============================] - 0s 617us/step - loss: 0.0712 - acc: 0.9760 - val_loss: 1.1351 - val_acc: 0.6923\n",
      "Epoch 62/68\n",
      "208/208 [==============================] - 0s 572us/step - loss: 0.0676 - acc: 0.9856 - val_loss: 1.0770 - val_acc: 0.7308\n",
      "Epoch 63/68\n",
      "208/208 [==============================] - 0s 620us/step - loss: 0.0755 - acc: 0.9904 - val_loss: 1.0688 - val_acc: 0.6923\n",
      "Epoch 64/68\n",
      "208/208 [==============================] - 0s 574us/step - loss: 0.0802 - acc: 0.9808 - val_loss: 1.1819 - val_acc: 0.6154\n",
      "Epoch 65/68\n",
      "208/208 [==============================] - 0s 613us/step - loss: 0.1027 - acc: 0.9712 - val_loss: 1.1400 - val_acc: 0.6538\n",
      "Epoch 66/68\n",
      "208/208 [==============================] - 0s 548us/step - loss: 0.1241 - acc: 0.9375 - val_loss: 1.0395 - val_acc: 0.6923\n",
      "Epoch 67/68\n",
      "208/208 [==============================] - 0s 640us/step - loss: 0.0691 - acc: 0.9808 - val_loss: 1.1928 - val_acc: 0.6731\n",
      "Epoch 68/68\n",
      "208/208 [==============================] - 0s 590us/step - loss: 0.0872 - acc: 0.9808 - val_loss: 1.0381 - val_acc: 0.7115\n",
      "Train on 208 samples, validate on 52 samples\n",
      "Epoch 1/69\n",
      "208/208 [==============================] - 12s 58ms/step - loss: 3.2605 - acc: 0.0962 - val_loss: 2.3147 - val_acc: 0.1154\n",
      "Epoch 2/69\n",
      "208/208 [==============================] - 0s 594us/step - loss: 2.3406 - acc: 0.3029 - val_loss: 1.9256 - val_acc: 0.3269\n",
      "Epoch 3/69\n",
      "208/208 [==============================] - 0s 569us/step - loss: 1.7144 - acc: 0.3942 - val_loss: 1.6005 - val_acc: 0.5000\n",
      "Epoch 4/69\n",
      "208/208 [==============================] - 0s 587us/step - loss: 1.5453 - acc: 0.4279 - val_loss: 1.6269 - val_acc: 0.5385\n",
      "Epoch 5/69\n",
      "208/208 [==============================] - 0s 556us/step - loss: 1.5589 - acc: 0.5096 - val_loss: 1.4701 - val_acc: 0.5000\n",
      "Epoch 6/69\n",
      "208/208 [==============================] - 0s 616us/step - loss: 1.1923 - acc: 0.5817 - val_loss: 1.5850 - val_acc: 0.4423\n",
      "Epoch 7/69\n",
      "208/208 [==============================] - 0s 577us/step - loss: 1.3101 - acc: 0.5577 - val_loss: 1.3253 - val_acc: 0.5769\n",
      "Epoch 8/69\n",
      "208/208 [==============================] - 0s 580us/step - loss: 0.9788 - acc: 0.6346 - val_loss: 1.2279 - val_acc: 0.5577\n",
      "Epoch 9/69\n",
      "208/208 [==============================] - 0s 595us/step - loss: 0.9346 - acc: 0.6875 - val_loss: 1.4580 - val_acc: 0.5962\n",
      "Epoch 10/69\n",
      "208/208 [==============================] - 0s 590us/step - loss: 0.8187 - acc: 0.7740 - val_loss: 1.0723 - val_acc: 0.6346\n",
      "Epoch 11/69\n",
      "208/208 [==============================] - 0s 595us/step - loss: 0.7353 - acc: 0.7596 - val_loss: 0.9954 - val_acc: 0.6731\n",
      "Epoch 12/69\n",
      "208/208 [==============================] - 0s 569us/step - loss: 0.7850 - acc: 0.7356 - val_loss: 1.0725 - val_acc: 0.5769\n",
      "Epoch 13/69\n",
      "208/208 [==============================] - 0s 580us/step - loss: 0.5560 - acc: 0.7933 - val_loss: 1.0624 - val_acc: 0.6731\n",
      "Epoch 14/69\n",
      "208/208 [==============================] - 0s 586us/step - loss: 0.5528 - acc: 0.8269 - val_loss: 1.0404 - val_acc: 0.6923\n",
      "Epoch 15/69\n",
      "208/208 [==============================] - 0s 575us/step - loss: 0.5593 - acc: 0.7885 - val_loss: 1.0953 - val_acc: 0.6923\n",
      "Epoch 16/69\n",
      "208/208 [==============================] - 0s 582us/step - loss: 0.5372 - acc: 0.8077 - val_loss: 1.0797 - val_acc: 0.6538\n",
      "Epoch 17/69\n",
      "208/208 [==============================] - 0s 585us/step - loss: 0.5707 - acc: 0.7837 - val_loss: 1.1215 - val_acc: 0.5769\n",
      "Epoch 18/69\n",
      "208/208 [==============================] - 0s 605us/step - loss: 0.4941 - acc: 0.8269 - val_loss: 0.9436 - val_acc: 0.7308\n",
      "Epoch 19/69\n",
      "208/208 [==============================] - 0s 567us/step - loss: 0.3673 - acc: 0.8798 - val_loss: 1.1999 - val_acc: 0.5769\n",
      "Epoch 20/69\n",
      "208/208 [==============================] - 0s 592us/step - loss: 0.4214 - acc: 0.8606 - val_loss: 1.0483 - val_acc: 0.6731\n",
      "Epoch 21/69\n",
      "208/208 [==============================] - 0s 590us/step - loss: 0.3866 - acc: 0.8750 - val_loss: 1.0482 - val_acc: 0.6538\n",
      "Epoch 22/69\n",
      "208/208 [==============================] - 0s 583us/step - loss: 0.3492 - acc: 0.8846 - val_loss: 1.0940 - val_acc: 0.6154\n",
      "Epoch 23/69\n",
      "208/208 [==============================] - 0s 572us/step - loss: 0.3835 - acc: 0.8798 - val_loss: 1.0830 - val_acc: 0.6346\n",
      "Epoch 24/69\n",
      "208/208 [==============================] - 0s 574us/step - loss: 0.3274 - acc: 0.8990 - val_loss: 1.0016 - val_acc: 0.6731\n",
      "Epoch 25/69\n",
      "208/208 [==============================] - 0s 589us/step - loss: 0.3359 - acc: 0.9087 - val_loss: 0.9687 - val_acc: 0.6731\n",
      "Epoch 26/69\n",
      "208/208 [==============================] - 0s 626us/step - loss: 0.2700 - acc: 0.9135 - val_loss: 1.0401 - val_acc: 0.6538\n",
      "Epoch 27/69\n",
      "208/208 [==============================] - 0s 585us/step - loss: 0.3228 - acc: 0.8894 - val_loss: 1.2089 - val_acc: 0.5577\n",
      "Epoch 28/69\n",
      "208/208 [==============================] - 0s 563us/step - loss: 0.2251 - acc: 0.9375 - val_loss: 1.0333 - val_acc: 0.6346\n",
      "Epoch 29/69\n",
      "208/208 [==============================] - 0s 597us/step - loss: 0.1990 - acc: 0.9423 - val_loss: 1.1058 - val_acc: 0.6538\n",
      "Epoch 30/69\n",
      "208/208 [==============================] - 0s 575us/step - loss: 0.2012 - acc: 0.9519 - val_loss: 1.1265 - val_acc: 0.5962\n",
      "Epoch 31/69\n",
      "208/208 [==============================] - 0s 587us/step - loss: 0.2874 - acc: 0.9135 - val_loss: 1.0623 - val_acc: 0.6731\n",
      "Epoch 32/69\n",
      "208/208 [==============================] - 0s 595us/step - loss: 0.2194 - acc: 0.9279 - val_loss: 1.0430 - val_acc: 0.6923\n",
      "Epoch 33/69\n",
      "208/208 [==============================] - 0s 606us/step - loss: 0.2136 - acc: 0.9327 - val_loss: 1.0745 - val_acc: 0.6923\n",
      "Epoch 34/69\n",
      "208/208 [==============================] - 0s 592us/step - loss: 0.2561 - acc: 0.9183 - val_loss: 0.9798 - val_acc: 0.7115\n",
      "Epoch 35/69\n",
      "208/208 [==============================] - 0s 583us/step - loss: 0.1955 - acc: 0.9519 - val_loss: 1.0049 - val_acc: 0.7115\n",
      "Epoch 36/69\n",
      "208/208 [==============================] - 0s 592us/step - loss: 0.1727 - acc: 0.9471 - val_loss: 1.0481 - val_acc: 0.6731\n",
      "Epoch 37/69\n",
      "208/208 [==============================] - 0s 607us/step - loss: 0.1754 - acc: 0.9567 - val_loss: 1.0730 - val_acc: 0.6923\n",
      "Epoch 38/69\n",
      "208/208 [==============================] - 0s 593us/step - loss: 0.1785 - acc: 0.9471 - val_loss: 1.0173 - val_acc: 0.6923\n",
      "Epoch 39/69\n",
      "208/208 [==============================] - 0s 593us/step - loss: 0.1791 - acc: 0.9423 - val_loss: 1.0872 - val_acc: 0.6923\n",
      "Epoch 40/69\n",
      "208/208 [==============================] - 0s 601us/step - loss: 0.1539 - acc: 0.9663 - val_loss: 1.1202 - val_acc: 0.6346\n",
      "Epoch 41/69\n",
      "208/208 [==============================] - 0s 612us/step - loss: 0.1392 - acc: 0.9663 - val_loss: 0.9931 - val_acc: 0.7308\n",
      "Epoch 42/69\n",
      "208/208 [==============================] - 0s 584us/step - loss: 0.1084 - acc: 0.9856 - val_loss: 1.0603 - val_acc: 0.6923\n",
      "Epoch 43/69\n",
      "208/208 [==============================] - 0s 611us/step - loss: 0.1398 - acc: 0.9663 - val_loss: 0.9978 - val_acc: 0.7500\n",
      "Epoch 44/69\n",
      "208/208 [==============================] - 0s 596us/step - loss: 0.1032 - acc: 0.9663 - val_loss: 1.0481 - val_acc: 0.6923\n",
      "Epoch 45/69\n",
      "208/208 [==============================] - 0s 584us/step - loss: 0.1192 - acc: 0.9856 - val_loss: 0.9863 - val_acc: 0.7308\n",
      "Epoch 46/69\n",
      "208/208 [==============================] - 0s 568us/step - loss: 0.1130 - acc: 0.9663 - val_loss: 1.0525 - val_acc: 0.7115\n",
      "Epoch 47/69\n",
      "208/208 [==============================] - 0s 559us/step - loss: 0.1002 - acc: 0.9760 - val_loss: 1.0146 - val_acc: 0.7500\n",
      "Epoch 48/69\n",
      "208/208 [==============================] - 0s 581us/step - loss: 0.1050 - acc: 0.9567 - val_loss: 1.0194 - val_acc: 0.7115\n",
      "Epoch 49/69\n",
      "208/208 [==============================] - 0s 593us/step - loss: 0.0949 - acc: 0.9760 - val_loss: 1.0809 - val_acc: 0.7115\n",
      "Epoch 50/69\n",
      "208/208 [==============================] - 0s 549us/step - loss: 0.0903 - acc: 0.9808 - val_loss: 1.0490 - val_acc: 0.7692\n",
      "Epoch 51/69\n",
      "208/208 [==============================] - 0s 573us/step - loss: 0.1334 - acc: 0.9567 - val_loss: 1.1760 - val_acc: 0.6538\n",
      "Epoch 52/69\n",
      "208/208 [==============================] - 0s 572us/step - loss: 0.1794 - acc: 0.9375 - val_loss: 1.2420 - val_acc: 0.6731\n",
      "Epoch 53/69\n",
      "208/208 [==============================] - 0s 596us/step - loss: 0.0899 - acc: 0.9760 - val_loss: 1.1234 - val_acc: 0.6923\n",
      "Epoch 54/69\n",
      "208/208 [==============================] - 0s 580us/step - loss: 0.1064 - acc: 0.9663 - val_loss: 1.0878 - val_acc: 0.6731\n",
      "Epoch 55/69\n",
      "208/208 [==============================] - 0s 565us/step - loss: 0.1059 - acc: 0.9712 - val_loss: 1.1341 - val_acc: 0.6731\n",
      "Epoch 56/69\n",
      "208/208 [==============================] - 0s 570us/step - loss: 0.1058 - acc: 0.9615 - val_loss: 1.1442 - val_acc: 0.6731\n",
      "Epoch 57/69\n",
      "208/208 [==============================] - 0s 591us/step - loss: 0.0935 - acc: 0.9712 - val_loss: 1.2078 - val_acc: 0.6346\n",
      "Epoch 58/69\n",
      "208/208 [==============================] - 0s 575us/step - loss: 0.0807 - acc: 0.9808 - val_loss: 1.1465 - val_acc: 0.7115\n",
      "Epoch 59/69\n",
      "208/208 [==============================] - 0s 577us/step - loss: 0.0838 - acc: 0.9712 - val_loss: 1.1197 - val_acc: 0.6731\n",
      "Epoch 60/69\n",
      "208/208 [==============================] - 0s 611us/step - loss: 0.1007 - acc: 0.9760 - val_loss: 1.0778 - val_acc: 0.7115\n",
      "Epoch 61/69\n",
      "208/208 [==============================] - 0s 593us/step - loss: 0.0809 - acc: 0.9760 - val_loss: 1.1630 - val_acc: 0.6538\n",
      "Epoch 62/69\n",
      "208/208 [==============================] - 0s 588us/step - loss: 0.0720 - acc: 0.9856 - val_loss: 1.0868 - val_acc: 0.7308\n",
      "Epoch 63/69\n",
      "208/208 [==============================] - 0s 603us/step - loss: 0.0770 - acc: 0.9856 - val_loss: 1.0811 - val_acc: 0.6731\n",
      "Epoch 64/69\n",
      "208/208 [==============================] - 0s 577us/step - loss: 0.0900 - acc: 0.9760 - val_loss: 1.1431 - val_acc: 0.6538\n",
      "Epoch 65/69\n",
      "208/208 [==============================] - 0s 596us/step - loss: 0.0921 - acc: 0.9760 - val_loss: 1.1409 - val_acc: 0.6731\n",
      "Epoch 66/69\n",
      "208/208 [==============================] - 0s 577us/step - loss: 0.1264 - acc: 0.9519 - val_loss: 1.0759 - val_acc: 0.6731\n",
      "Epoch 67/69\n",
      "208/208 [==============================] - 0s 583us/step - loss: 0.0672 - acc: 0.9712 - val_loss: 1.2021 - val_acc: 0.6731\n",
      "Epoch 68/69\n",
      "208/208 [==============================] - 0s 553us/step - loss: 0.0907 - acc: 0.9760 - val_loss: 1.0420 - val_acc: 0.7115\n",
      "Epoch 69/69\n",
      "208/208 [==============================] - 0s 552us/step - loss: 0.0642 - acc: 0.9808 - val_loss: 1.0823 - val_acc: 0.7115\n",
      "Train on 208 samples, validate on 52 samples\n",
      "Epoch 1/70\n",
      "208/208 [==============================] - 12s 57ms/step - loss: 3.2605 - acc: 0.0962 - val_loss: 2.3147 - val_acc: 0.1154\n",
      "Epoch 2/70\n",
      "208/208 [==============================] - 0s 616us/step - loss: 2.3406 - acc: 0.3029 - val_loss: 1.9256 - val_acc: 0.3269\n",
      "Epoch 3/70\n",
      "208/208 [==============================] - 0s 579us/step - loss: 1.7144 - acc: 0.3942 - val_loss: 1.6005 - val_acc: 0.5000\n",
      "Epoch 4/70\n",
      "208/208 [==============================] - 0s 617us/step - loss: 1.5453 - acc: 0.4279 - val_loss: 1.6269 - val_acc: 0.5385\n",
      "Epoch 5/70\n",
      "208/208 [==============================] - 0s 589us/step - loss: 1.5589 - acc: 0.5096 - val_loss: 1.4701 - val_acc: 0.5000\n",
      "Epoch 6/70\n",
      "208/208 [==============================] - 0s 610us/step - loss: 1.1923 - acc: 0.5817 - val_loss: 1.5850 - val_acc: 0.4423\n",
      "Epoch 7/70\n",
      "208/208 [==============================] - 0s 597us/step - loss: 1.3101 - acc: 0.5577 - val_loss: 1.3253 - val_acc: 0.5769\n",
      "Epoch 8/70\n",
      "208/208 [==============================] - 0s 582us/step - loss: 0.9788 - acc: 0.6346 - val_loss: 1.2279 - val_acc: 0.5577\n",
      "Epoch 9/70\n",
      "208/208 [==============================] - 0s 579us/step - loss: 0.9346 - acc: 0.6875 - val_loss: 1.4580 - val_acc: 0.5962\n",
      "Epoch 10/70\n",
      "208/208 [==============================] - 0s 586us/step - loss: 0.8187 - acc: 0.7740 - val_loss: 1.0723 - val_acc: 0.6346\n",
      "Epoch 11/70\n",
      "208/208 [==============================] - 0s 593us/step - loss: 0.7353 - acc: 0.7596 - val_loss: 0.9954 - val_acc: 0.6731\n",
      "Epoch 12/70\n",
      "208/208 [==============================] - 0s 622us/step - loss: 0.7850 - acc: 0.7356 - val_loss: 1.0725 - val_acc: 0.5769\n",
      "Epoch 13/70\n",
      "208/208 [==============================] - 0s 603us/step - loss: 0.5560 - acc: 0.7933 - val_loss: 1.0624 - val_acc: 0.6731\n",
      "Epoch 14/70\n",
      "208/208 [==============================] - 0s 583us/step - loss: 0.5528 - acc: 0.8269 - val_loss: 1.0404 - val_acc: 0.6923\n",
      "Epoch 15/70\n",
      "208/208 [==============================] - 0s 582us/step - loss: 0.5593 - acc: 0.7885 - val_loss: 1.0953 - val_acc: 0.6923\n",
      "Epoch 16/70\n",
      "208/208 [==============================] - 0s 593us/step - loss: 0.5367 - acc: 0.8029 - val_loss: 1.0774 - val_acc: 0.6538\n",
      "Epoch 17/70\n",
      "208/208 [==============================] - 0s 606us/step - loss: 0.5675 - acc: 0.7885 - val_loss: 1.1222 - val_acc: 0.5577\n",
      "Epoch 18/70\n",
      "208/208 [==============================] - 0s 607us/step - loss: 0.4930 - acc: 0.8221 - val_loss: 0.9414 - val_acc: 0.7308\n",
      "Epoch 19/70\n",
      "208/208 [==============================] - 0s 600us/step - loss: 0.3706 - acc: 0.8798 - val_loss: 1.1944 - val_acc: 0.5769\n",
      "Epoch 20/70\n",
      "208/208 [==============================] - 0s 596us/step - loss: 0.4193 - acc: 0.8654 - val_loss: 1.0358 - val_acc: 0.6731\n",
      "Epoch 21/70\n",
      "208/208 [==============================] - 0s 594us/step - loss: 0.3843 - acc: 0.8798 - val_loss: 1.0398 - val_acc: 0.6731\n",
      "Epoch 22/70\n",
      "208/208 [==============================] - 0s 586us/step - loss: 0.3499 - acc: 0.8846 - val_loss: 1.0967 - val_acc: 0.6538\n",
      "Epoch 23/70\n",
      "208/208 [==============================] - 0s 586us/step - loss: 0.3756 - acc: 0.8846 - val_loss: 1.0502 - val_acc: 0.6346\n",
      "Epoch 24/70\n",
      "208/208 [==============================] - 0s 587us/step - loss: 0.3208 - acc: 0.9038 - val_loss: 1.0037 - val_acc: 0.6538\n",
      "Epoch 25/70\n",
      "208/208 [==============================] - 0s 604us/step - loss: 0.3328 - acc: 0.9135 - val_loss: 0.9666 - val_acc: 0.6731\n",
      "Epoch 26/70\n",
      "208/208 [==============================] - 0s 600us/step - loss: 0.2635 - acc: 0.9135 - val_loss: 1.0365 - val_acc: 0.6346\n",
      "Epoch 27/70\n",
      "208/208 [==============================] - 0s 597us/step - loss: 0.3176 - acc: 0.9038 - val_loss: 1.1373 - val_acc: 0.5577\n",
      "Epoch 28/70\n",
      "208/208 [==============================] - 0s 598us/step - loss: 0.2273 - acc: 0.9519 - val_loss: 1.0445 - val_acc: 0.6346\n",
      "Epoch 29/70\n",
      "208/208 [==============================] - 0s 582us/step - loss: 0.1995 - acc: 0.9375 - val_loss: 1.1178 - val_acc: 0.6154\n",
      "Epoch 30/70\n",
      "208/208 [==============================] - 0s 602us/step - loss: 0.2070 - acc: 0.9519 - val_loss: 1.1175 - val_acc: 0.5962\n",
      "Epoch 31/70\n",
      "208/208 [==============================] - 0s 614us/step - loss: 0.2875 - acc: 0.9183 - val_loss: 1.0393 - val_acc: 0.6731\n",
      "Epoch 32/70\n",
      "208/208 [==============================] - 0s 610us/step - loss: 0.2191 - acc: 0.9423 - val_loss: 1.0283 - val_acc: 0.7115\n",
      "Epoch 33/70\n",
      "208/208 [==============================] - 0s 601us/step - loss: 0.2246 - acc: 0.9231 - val_loss: 1.0657 - val_acc: 0.6731\n",
      "Epoch 34/70\n",
      "208/208 [==============================] - 0s 576us/step - loss: 0.2483 - acc: 0.9231 - val_loss: 0.9972 - val_acc: 0.7115\n",
      "Epoch 35/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "208/208 [==============================] - 0s 598us/step - loss: 0.1995 - acc: 0.9423 - val_loss: 0.9929 - val_acc: 0.7115\n",
      "Epoch 36/70\n",
      "208/208 [==============================] - 0s 584us/step - loss: 0.1758 - acc: 0.9423 - val_loss: 1.0475 - val_acc: 0.6731\n",
      "Epoch 37/70\n",
      "208/208 [==============================] - 0s 585us/step - loss: 0.1786 - acc: 0.9519 - val_loss: 1.0619 - val_acc: 0.6731\n",
      "Epoch 38/70\n",
      "208/208 [==============================] - 0s 557us/step - loss: 0.1822 - acc: 0.9375 - val_loss: 0.9994 - val_acc: 0.7308\n",
      "Epoch 39/70\n",
      "208/208 [==============================] - 0s 557us/step - loss: 0.1802 - acc: 0.9375 - val_loss: 1.0730 - val_acc: 0.6923\n",
      "Epoch 40/70\n",
      "208/208 [==============================] - 0s 588us/step - loss: 0.1563 - acc: 0.9663 - val_loss: 1.1041 - val_acc: 0.6538\n",
      "Epoch 41/70\n",
      "208/208 [==============================] - 0s 582us/step - loss: 0.1397 - acc: 0.9712 - val_loss: 0.9852 - val_acc: 0.7308\n",
      "Epoch 42/70\n",
      "208/208 [==============================] - 0s 573us/step - loss: 0.1085 - acc: 0.9904 - val_loss: 1.0623 - val_acc: 0.6538\n",
      "Epoch 43/70\n",
      "208/208 [==============================] - 0s 609us/step - loss: 0.1415 - acc: 0.9712 - val_loss: 1.0095 - val_acc: 0.7500\n",
      "Epoch 44/70\n",
      "208/208 [==============================] - 0s 582us/step - loss: 0.1069 - acc: 0.9712 - val_loss: 1.0398 - val_acc: 0.6923\n",
      "Epoch 45/70\n",
      "208/208 [==============================] - 0s 584us/step - loss: 0.1214 - acc: 0.9712 - val_loss: 0.9860 - val_acc: 0.7308\n",
      "Epoch 46/70\n",
      "208/208 [==============================] - 0s 594us/step - loss: 0.1209 - acc: 0.9471 - val_loss: 1.0496 - val_acc: 0.7115\n",
      "Epoch 47/70\n",
      "208/208 [==============================] - 0s 601us/step - loss: 0.1043 - acc: 0.9808 - val_loss: 1.0209 - val_acc: 0.7308\n",
      "Epoch 48/70\n",
      "208/208 [==============================] - 0s 578us/step - loss: 0.1007 - acc: 0.9663 - val_loss: 1.0283 - val_acc: 0.7115\n",
      "Epoch 49/70\n",
      "208/208 [==============================] - 0s 570us/step - loss: 0.1057 - acc: 0.9760 - val_loss: 1.0719 - val_acc: 0.7115\n",
      "Epoch 50/70\n",
      "208/208 [==============================] - 0s 584us/step - loss: 0.0915 - acc: 0.9760 - val_loss: 1.0474 - val_acc: 0.7500\n",
      "Epoch 51/70\n",
      "208/208 [==============================] - 0s 603us/step - loss: 0.1279 - acc: 0.9615 - val_loss: 1.1846 - val_acc: 0.6538\n",
      "Epoch 52/70\n",
      "208/208 [==============================] - 0s 599us/step - loss: 0.1700 - acc: 0.9519 - val_loss: 1.1933 - val_acc: 0.6538\n",
      "Epoch 53/70\n",
      "208/208 [==============================] - 0s 588us/step - loss: 0.0851 - acc: 0.9808 - val_loss: 1.1109 - val_acc: 0.7308\n",
      "Epoch 54/70\n",
      "208/208 [==============================] - 0s 579us/step - loss: 0.1028 - acc: 0.9663 - val_loss: 1.0637 - val_acc: 0.6923\n",
      "Epoch 55/70\n",
      "208/208 [==============================] - 0s 567us/step - loss: 0.1128 - acc: 0.9567 - val_loss: 1.1073 - val_acc: 0.6731\n",
      "Epoch 56/70\n",
      "208/208 [==============================] - 0s 588us/step - loss: 0.1012 - acc: 0.9712 - val_loss: 1.1057 - val_acc: 0.6731\n",
      "Epoch 57/70\n",
      "208/208 [==============================] - 0s 577us/step - loss: 0.0987 - acc: 0.9712 - val_loss: 1.1586 - val_acc: 0.6731\n",
      "Epoch 58/70\n",
      "208/208 [==============================] - 0s 593us/step - loss: 0.0769 - acc: 0.9808 - val_loss: 1.0935 - val_acc: 0.7308\n",
      "Epoch 59/70\n",
      "208/208 [==============================] - 0s 584us/step - loss: 0.0862 - acc: 0.9712 - val_loss: 1.1035 - val_acc: 0.7308\n",
      "Epoch 60/70\n",
      "208/208 [==============================] - 0s 597us/step - loss: 0.0995 - acc: 0.9760 - val_loss: 1.0635 - val_acc: 0.7308\n",
      "Epoch 61/70\n",
      "208/208 [==============================] - 0s 590us/step - loss: 0.0707 - acc: 0.9856 - val_loss: 1.1508 - val_acc: 0.6346\n",
      "Epoch 62/70\n",
      "208/208 [==============================] - 0s 583us/step - loss: 0.0740 - acc: 0.9760 - val_loss: 1.0765 - val_acc: 0.7308\n",
      "Epoch 63/70\n",
      "208/208 [==============================] - 0s 576us/step - loss: 0.0741 - acc: 0.9856 - val_loss: 1.0664 - val_acc: 0.7115\n",
      "Epoch 64/70\n",
      "208/208 [==============================] - 0s 570us/step - loss: 0.0834 - acc: 0.9760 - val_loss: 1.1726 - val_acc: 0.6731\n",
      "Epoch 65/70\n",
      "208/208 [==============================] - 0s 587us/step - loss: 0.1034 - acc: 0.9663 - val_loss: 1.1748 - val_acc: 0.6731\n",
      "Epoch 66/70\n",
      "208/208 [==============================] - 0s 586us/step - loss: 0.1387 - acc: 0.9375 - val_loss: 1.0667 - val_acc: 0.7115\n",
      "Epoch 67/70\n",
      "208/208 [==============================] - 0s 582us/step - loss: 0.0792 - acc: 0.9760 - val_loss: 1.2027 - val_acc: 0.6923\n",
      "Epoch 68/70\n",
      "208/208 [==============================] - 0s 602us/step - loss: 0.0841 - acc: 0.9808 - val_loss: 1.0499 - val_acc: 0.7308\n",
      "Epoch 69/70\n",
      "208/208 [==============================] - 0s 624us/step - loss: 0.0680 - acc: 0.9760 - val_loss: 1.0799 - val_acc: 0.7308\n",
      "Epoch 70/70\n",
      "208/208 [==============================] - 0s 596us/step - loss: 0.0854 - acc: 0.9808 - val_loss: 1.0863 - val_acc: 0.6731\n"
     ]
    }
   ],
   "source": [
    "for step in np.arange(1,72,10)[1:]:\n",
    "    weights_4=[]\n",
    "    weights_6=[]\n",
    "    for i in range(step-10,step):\n",
    "        \n",
    "        np.random.seed(seed)\n",
    "        \n",
    "        model=Sequential()\n",
    "        model.add(Conv2D(64,kernel_size=(2,2),activation='tanh',input_shape=(20,11,1)))\n",
    "        model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "        model.add(Dropout(0.4))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(128,activation='relu'))\n",
    "        model.add(Dropout(0.4))\n",
    "        model.add(Dense(10,activation='softmax'))\n",
    "        model.compile(loss=keras.losses.categorical_crossentropy,optimizer=keras.optimizers.Adadelta(),metrics=['accuracy'])\n",
    "    \n",
    "        model.fit(X_train,y_train_hot,batch_size=128,epochs=i,verbose=1,validation_data=(X_test,y_test_hot))\n",
    "        \n",
    "        weights_4=np.append(weights_4,model.layers[4].get_weights()[0])\n",
    "        weights_6=np.append(weights_6,model.layers[6].get_weights()[0])\n",
    "    \n",
    "    diff_4=[]\n",
    "    diff_6=[]\n",
    "    for i in range(0,9):\n",
    "        diff4=np.absolute( weights_4[i+1]-weights_4[i])\n",
    "        diff6=np.absolute(weights_6[i+1]-weights_6[i])\n",
    "        \n",
    "        diff_4=np.append(diff_4,diff4)\n",
    "        diff_6=np.append(diff_6,diff6)\n",
    "    if step==11:\n",
    "        diff_mat_4=np.average(diff_4)\n",
    "        diff_mat_6=np.average(diff_6)\n",
    "    else:\n",
    "        diff_mat_4=np.append(diff_mat_4,np.average(diff_4))\n",
    "        diff_mat_6=np.append(diff_mat_6,np.average(diff_6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('Average_Diff_mat_4.npy',diff_mat_4)\n",
    "np.save('Average_Diff_mat_6.npy',diff_mat_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_140 (Conv2D)          (None, 19, 10, 64)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_140 (MaxPoolin (None, 9, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_279 (Dropout)        (None, 9, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_140 (Flatten)        (None, 2880)              0         \n",
      "_________________________________________________________________\n",
      "dense_279 (Dense)            (None, 128)               368768    \n",
      "_________________________________________________________________\n",
      "dropout_280 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_280 (Dense)            (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 370,378\n",
      "Trainable params: 370,378\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_4=np.load('Average_Diff_mat_4.npy')\n",
    "mat_6=np.load('Average_Diff_mat_6.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "epoch_number=np.arange(1,71,10)\n",
    "#plt.figure(figsize=(10,4))\n",
    "plt.bar(epoch_number,mat_4,width=8.5)\n",
    "plt.xlabel('Epoch Number')\n",
    "plt.ylabel('Average Difference')\n",
    "plt.xticks(epoch_number,('1-10','11-20','21-30','31-40','41-50','51-60','61-70'))\n",
    "plt.title('Dense_53 layer')\n",
    "plt.savefig('./Graphs/weights_variation_53_seed.svg',format='svg',dpi=1200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "epoch_number=np.arange(1,71,10)\n",
    "#plt.figure(figsize=(10,4))\n",
    "plt.bar(epoch_number,mat_6,width=8.5)\n",
    "plt.xlabel('Epoch Number')\n",
    "plt.ylabel('Average Value')\n",
    "plt.xticks(epoch_number,('1-10','11-20','21-30','31-40','41-50','51-60','61-70'))\n",
    "plt.title('Dense_54 layer')\n",
    "plt.savefig('./Graphs/weights_variation_54_seed.svg',format='svg',dpi=1200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
